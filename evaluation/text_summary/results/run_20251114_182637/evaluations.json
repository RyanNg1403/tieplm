{
  "run_info": {
    "run_id": "run_20251114_182637",
    "timestamp": "20251114_182637",
    "total_questions": 50,
    "successful_evaluations": 50,
    "failed_evaluations": 0,
    "evaluation_model": "gpt-5-mini",
    "threshold": 0.5,
    "n_questions": 10
  },
  "statistics": {
    "overall": {
      "mean": 0.7204146744075994,
      "min": 0.3,
      "max": 1.0,
      "median": 0.75,
      "std": 0.1521813462402018
    },
    "coverage": {
      "mean": 0.7959999999999999,
      "min": 0.3,
      "max": 1.0
    },
    "alignment": {
      "mean": 0.7920121741244961,
      "min": 0.4375,
      "max": 1.0
    },
    "cosine_similarity": {
      "mean": 0.26843212195900834,
      "min": 0.1845401223610763,
      "max": 0.33782683453198087,
      "median": 0.272356930796557,
      "std": 0.034239553008328365
    }
  },
  "scores": [
    {
      "question_id": "sum_001",
      "query": "Transformer Architecture",
      "score": 0.8260869565217391,
      "coverage_score": 1.0,
      "alignment_score": 0.8260869565217391,
      "success": true,
      "reason": "The score is 0.83 because the summary correctly captures the source’s core points (encoder/decoder modularity, self-attention, residual connections, and that BERT/GPT are self-supervised foundation models), but it adds four unsupported claims absent from the original: that residual connections specifically “help stabilize training and enable very deep networks,” that every layer always includes a feed‑forward component, that BERT/GPT are applied via “fine‑tuning,” and that they have a “large advantage in pretraining and transfer learning.” These extra, unstated assertions reduce fidelity slightly despite overall accuracy.",
      "summary_chars": 2916,
      "original_text_chars": 8522,
      "evaluation_time_seconds": 121.81090600000002,
      "cosine_similarity": 0.2656
    },
    {
      "question_id": "sum_002",
      "query": "Attention Mechanism",
      "score": 0.75,
      "coverage_score": 0.9,
      "alignment_score": 0.75,
      "success": true,
      "reason": "The score is 0.75 because the summary captures the main points (attention is costly; BigBird reduces computation using mixed attention) but introduces several unstated claims (saying full/global attention scales quadratically, explicitly naming the third BigBird attention as “random,” asserting attention directly enables long‑term dependency learning, and implying modern models’ gains are solely due to attention) and adds terminology not present in the original. It also fails to state an original-text fact the reader could ask about (whether LSTM is mentioned as an ANN variant). These extra assertions and the omission lower fidelity despite overall reasonable coverage.",
      "summary_chars": 3390,
      "original_text_chars": 8370,
      "evaluation_time_seconds": 123.68956599999999,
      "cosine_similarity": 0.2831
    },
    {
      "question_id": "sum_003",
      "query": "Self-Attention",
      "score": 0.8,
      "coverage_score": 1.0,
      "alignment_score": 0.8,
      "success": true,
      "reason": "The score is 0.80 because the summary captures the core ideas (Transformer uses multi-head self-attention and per-layer parallel computation contrasted with RNN sequentiality) with no direct contradictions, but it introduces several unstated inferences: that multi-head attention explicitly \"divides attention into multiple heads\" to learn diverse relationships and \"enables parallel computation and richer representations,\" that later-layer values depend on earlier layers, that this yields speedups on GPUs/TPUs, and that multi-head attention \"helps capture multiple types of contextual relationships.\" These added claims go beyond the original text, lowering strict fidelity while leaving the overall gist mostly accurate.",
      "summary_chars": 2967,
      "original_text_chars": 7745,
      "evaluation_time_seconds": 96.99009799999999,
      "cosine_similarity": 0.3212
    },
    {
      "question_id": "sum_004",
      "query": "Multi-Head Self-Attention",
      "score": 0.76,
      "coverage_score": 0.9,
      "alignment_score": 0.76,
      "success": true,
      "reason": "The score is 0.76 because the summary is mostly faithful but has important issues: it directly contradicts the original by stating attention cost is O(T^2·D) while the source explicitly gives O(T^2) (excluding D); it injects unsupported details (e.g., that heads’ outputs are concatenated then linearly projected and specific negative consequences of sinusoidal positional encodings) that do not appear in the original; and it omits an answerable point the original covers (whether the decoder output uses positional embeddings). These factual contradiction and added assumptions lower the fidelity despite overall reasonable coverage.",
      "summary_chars": 3226,
      "original_text_chars": 9026,
      "evaluation_time_seconds": 90.949984,
      "cosine_similarity": 0.3111
    },
    {
      "question_id": "sum_005",
      "query": "Query, Key, and Value (QKV) Vectors",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9565217391304348,
      "success": true,
      "reason": "The score is 0.90 because the summary accurately captures the main points (attention highlights relevant inputs and multi-head attention captures multiple relations) and is largely faithful to the original, but it adds an extra claim that QKV+attention allow the model to learn long-term dependencies (which the original did not state) and it omits clarifying whether the RNN/attention review treats hidden states S1..SN as Values; these are minor overreach and omission, hence a small deduction from perfect.",
      "summary_chars": 2628,
      "original_text_chars": 8210,
      "evaluation_time_seconds": 95.10803200000001,
      "cosine_similarity": 0.3248
    },
    {
      "question_id": "sum_006",
      "query": "Attention Score Calculation",
      "score": 1.0,
      "coverage_score": 1.0,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 1.00 because the summary perfectly matches the original text — it is accurate, complete, concise, and faithful with no contradictions or added information.",
      "summary_chars": 2840,
      "original_text_chars": 8821,
      "evaluation_time_seconds": 74.268523,
      "cosine_similarity": 0.2777
    },
    {
      "question_id": "sum_007",
      "query": "Attention Distribution (Softmax)",
      "score": 0.6470588235294118,
      "coverage_score": 1.0,
      "alignment_score": 0.6470588235294118,
      "success": true,
      "reason": "The score is 0.65 because the summary correctly captures the core mechanics (scores as q·k, α = softmax(R), vectorized Output = softmax(QK^T)V, and that queries/keys/values come from x via linear maps) but also injects unsupported details: it introduces the attention matrix label “A,” asserts the mechanism “can compare with itself,” names the model “Transformer,” labels the summary as “short” or “comprehensive,” and cites specific example tokens — additions not present in the original. Overall largely accurate but contains extra, unsupported phrasing, so fidelity is moderate.",
      "summary_chars": 2415,
      "original_text_chars": 9005,
      "evaluation_time_seconds": 97.02719199999999,
      "cosine_similarity": 0.2769
    },
    {
      "question_id": "sum_008",
      "query": "Attention Output/Context Vector",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 0.8214285714285714,
      "success": true,
      "reason": "The score is 0.70 because the summary is largely accurate on core attention concepts (no direct contradictions) but adds several unsupported specifics and omits some concrete details the original provided. Unsupported additions include: an extra decoder bias term in the softmax, the claim that attention ‘solves’ the encoder’s fixed-memory limit, an explicit O(N) cost statement for computing scores, naming application domains like machine translation/text generation, and conflating cell-attention use with Transformer vectorization. The summary also fails to report examples and background that the original gives (the ‘sua’ token attention example, the review of RNN/LSTM usage before Transformers, and explicit mention of bidirectional encoding). These extra/missing elements justify a moderately high but imperfect score.",
      "summary_chars": 2850,
      "original_text_chars": 8523,
      "evaluation_time_seconds": 122.36146400000001,
      "cosine_similarity": 0.263
    },
    {
      "question_id": "sum_009",
      "query": "Cross-Attention (Encoder-Decoder Attention)",
      "score": 0.55,
      "coverage_score": 1.0,
      "alignment_score": 0.55,
      "success": true,
      "reason": "The score is 0.55 because the summary keeps key concepts (masked multi‑head attention, parallelization, encoder–decoder cross‑attention, add & norm and feedforward blocks) but introduces several unsupported specifics and omissions that reduce fidelity: it asserts implementation details (Q/K/V splitting for cross‑attention and ‘‘many interaction types’’), an explicit ordering of masked self‑attention before cross‑attention, a final linear/projection to logits, claims that masked attention both prevents peeking and enables GPU parallelization in the same breath, and extra statements about cross‑attention computational cost and example applications that the original did not state. These added or overstated details lower the summary’s accuracy despite preserving the main ideas.",
      "summary_chars": 2885,
      "original_text_chars": 8465,
      "evaluation_time_seconds": 115.823411,
      "cosine_similarity": 0.2825
    },
    {
      "question_id": "sum_010",
      "query": "Masked Multi-Head Self-Attention",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9047619047619048,
      "success": true,
      "reason": "The score is 0.90 because the summary is largely faithful and succinctly captures the core mechanisms (linear projections, multi‑head attention, and sinusoidal positional encodings), but it includes two unsupported assertions (that heads are explicitly concatenated and then projected by a final linear matrix; and that the fixed sinusoidal encoding is a weakness) and it omits an answerable detail about the decoder—namely that its two distinguishing features are masked multi‑head attention and cross‑attention. These minor additions and one omission explain a high but not perfect score.",
      "summary_chars": 2679,
      "original_text_chars": 8903,
      "evaluation_time_seconds": 114.569491,
      "cosine_similarity": 0.3178
    },
    {
      "question_id": "sum_011",
      "query": "Transformer Encoder Architecture",
      "score": 0.75,
      "coverage_score": 1.0,
      "alignment_score": 0.75,
      "success": true,
      "reason": "The score is 0.75 because the summary correctly captures the main transformer points (encoder–decoder cross‑attention, attention uses queries/keys/values, self‑attention as a primary encoder module, encoder outputs used by the decoder, and that Transformers enable parallel processing) but introduces several unsupported specifics: it claims queries come from the decoder while keys/values come from the encoder; asserts a basic encoder block includes a subsequent nonlinear feed‑forward or other layers; makes hardware-level claims about GPUs and ‘‘leveraging parallel hardware’’; and presents encoder outputs in an explicit sequence notation (s1, s2, ..., st). These plausible but unreferenced additions lower fidelity, so the summary is mostly accurate but not fully faithful.",
      "summary_chars": 2845,
      "original_text_chars": 8660,
      "evaluation_time_seconds": 105.30460000000001,
      "cosine_similarity": 0.3075
    },
    {
      "question_id": "sum_012",
      "query": "Transformer Decoder Architecture",
      "score": 0.72,
      "coverage_score": 0.8,
      "alignment_score": 0.72,
      "success": true,
      "reason": "The score is 0.72 because the summary correctly captures many core Transformer/GPT points (so it is broadly faithful) but includes multiple unsupported technical claims (explicit decoder layer counts, calling Next-Word pretraining ‘‘autoregressive’’/masking, describing the feed‑forward sublayer as position‑wise nonlinear, and asserting decoder self‑attention details) that are not present in the original, reducing fidelity. It also omits answers the original could provide (questions about an encoder ‘shareattention’ module and whether Transformer depth can vary widely), which further lowers completeness.",
      "summary_chars": 2968,
      "original_text_chars": 8824,
      "evaluation_time_seconds": 102.51634100000001,
      "cosine_similarity": 0.2499
    },
    {
      "question_id": "sum_013",
      "query": "Positional Encoding/Embedding",
      "score": 0.4,
      "coverage_score": 0.4,
      "alignment_score": 0.7391304347826086,
      "success": false,
      "reason": "The score is 0.40 because the summary gets core facts right (fixed sinusoidal PE, 10k scale, unlikely repeats) but includes several unsupported or assertive additions—e.g., that self‑attention is order‑agnostic so PE must ‘give’ token order, that PE is necessarily added before q/k/v projection, that fixed PE does not increase learnable parameters, and that it does not address relative positions—which are not stated in the original. Those extra claims plus the omission of several architectural details the original does provide (decoder multi‑head/cross‑attention, feedforward and add&norm layers, quadratic self‑attention cost, final projection) reduce fidelity and justify the low score.",
      "summary_chars": 2487,
      "original_text_chars": 9082,
      "evaluation_time_seconds": 126.77703200000002,
      "cosine_similarity": 0.274
    },
    {
      "question_id": "sum_014",
      "query": "Feed-Forward Networks in Transformer",
      "score": 0.5,
      "coverage_score": 0.5,
      "alignment_score": 0.6,
      "success": true,
      "reason": "The score is 0.50 because the summary includes several unsupported additions (claims about the document title, an explicit MLP formula and biases, an implicit softmax in the decoder, a per-position FFN statement, and assertions about increased computational cost/parameter count) while failing to convey answers the original did provide (whether attention is scaled by sqrt(dk), that Transformer allows parallel token processing, that RNNs process sequentially and can lose early information, that the decoder uses embeddings and positional embeddings, and that decoding is autoregressive). There are no direct contradictions and core facts are mostly preserved, but the unsupported extras and omitted answers reduce the summary's fidelity.",
      "summary_chars": 2040,
      "original_text_chars": 8048,
      "evaluation_time_seconds": 91.343245,
      "cosine_similarity": 0.2361
    },
    {
      "question_id": "sum_015",
      "query": "BERT Model Architecture",
      "score": 0.4,
      "coverage_score": 0.4,
      "alignment_score": 0.8947368421052632,
      "success": false,
      "reason": "The score is 0.40 because the summary adds unsupported claims about BERT (calling its architecture a ‘stack of encoders’ and saying it ‘leverages attention in the encoder’) that the original does not state, and it omits several concrete facts present in the source (whether BERT and GPT use self-supervised learning; CNN uses softmax activation and the ADAM optimizer; RNN/LSTM uses padding for sequences; the softmax regression example uses 4 output classes and reports 12 total parameters), making the summary unfaithful and incomplete, though it contains no direct contradictions to the original.",
      "summary_chars": 2329,
      "original_text_chars": 7908,
      "evaluation_time_seconds": 82.924022,
      "cosine_similarity": 0.255
    },
    {
      "question_id": "sum_016",
      "query": "GPT Model Architecture",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.8421052631578947,
      "success": true,
      "reason": "The score is 0.80 because the summary is mostly faithful and contains no contradictions, but it omits and adds implementation-level details not present in the original. Specifically, the summary introduces decoder-only stacking with causal masks, an explicit loss formulation (e.g., maximum likelihood/cross-entropy), and the claim that GPT makes \"prefix-only\" contextual embeddings—none of which the original text stated. It also fails to answer two factual questions the original does support: whether the 'T' in ChatGPT/GPT-4 stands for Transformer, and whether the ADAM optimizer is mentioned/used for configuring a CNN. Given accuracy on main points but notable omissions/added specifics, a 0.80 rating is appropriate.",
      "summary_chars": 2245,
      "original_text_chars": 9255,
      "evaluation_time_seconds": 86.960389,
      "cosine_similarity": 0.3234
    },
    {
      "question_id": "sum_017",
      "query": "Vanishing Gradient Problem",
      "score": 0.72,
      "coverage_score": 1.0,
      "alignment_score": 0.72,
      "success": true,
      "reason": "The score is 0.72 because the summary preserves the main points (that sigmoid tends to cause vanishing gradients and that tanh, ReLU, and skip connections can help enable deeper nets) but introduces several unsupported specifics: it asserts tanh's derivative bound as the reason, gives an explicit recommendation to \"avoid sigmoid\" or that tanh \"improves slightly,\" makes unsupported direct comparisons between ReLU and tanh, claims an RNN decoder can be extended to ~8 layers, lists LSTM disadvantages, and describes skip connections as \"simple\" while implying other undisclosed drawbacks. These extra/unjustified details reduce fidelity despite overall reasonable coverage.",
      "summary_chars": 3163,
      "original_text_chars": 9010,
      "evaluation_time_seconds": 102.440776,
      "cosine_similarity": 0.274
    },
    {
      "question_id": "sum_018",
      "query": "Computational Cost of Self-Attention",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 0.8333333333333334,
      "success": true,
      "reason": "The score is 0.70 because the summary is largely faithful (no direct contradictions) but adds unsupported claims and omits answerable points from the original. Specifically, it claims memory grows as O(T^2·D) while the original only stated computational cost scales as O(T^2) with a factor D and did not mention memory; it also adds that self-attention provides “flexible representations,” which the original did not state. The summary also fails to include several points the original can answer: whether absolute position is unimportant but relative position can be important; that attention during decoding is a query-based lookup/aggregation of encoder values; and that decoding is theoretically sequential and cannot be parallelized. These unsupported additions and omitted details explain the moderately high but imperfect score.",
      "summary_chars": 1585,
      "original_text_chars": 8295,
      "evaluation_time_seconds": 112.50131999999999,
      "cosine_similarity": 0.2628
    },
    {
      "question_id": "sum_019",
      "query": "Recurrent Neural Networks (RNN) Architecture",
      "score": 0.9047619047619048,
      "coverage_score": 1.0,
      "alignment_score": 0.9047619047619048,
      "success": true,
      "reason": "The score is 0.90 because the summary faithfully conveys the main points (Transformer enables parallel processing and reduces long‑term information loss; Keras modules include Embedding, Dense and RNN/cell with LSTM variants) but adds two unwarranted specifics: it equates the original’s vague ‘cell extension’ mechanism with ‘self‑attention’ and explicitly names ‘SimpleRNN’ though the source only mentioned RNN/cell and LSTM. These minor extra details slightly reduce fidelity, but overall the summary is accurate and clear.",
      "summary_chars": 2778,
      "original_text_chars": 8784,
      "evaluation_time_seconds": 107.50290100000001,
      "cosine_similarity": 0.2889
    },
    {
      "question_id": "sum_020",
      "query": "Long Short-Term Memory (LSTM) Architecture",
      "score": 0.8888888888888888,
      "coverage_score": 0.9,
      "alignment_score": 0.8888888888888888,
      "success": true,
      "reason": "The score is 0.89 because the summary correctly captures the main ideas — RNNs’ vanishing-gradient/long-term dependency issues, LSTM’s historical role, and the later rise of attention/Transformers — but it adds extra, stronger claims not present in the original (e.g., that LSTM definitively “resolves” those problems or is categorically better than vanilla RNNs). It also omits a small factual detail the original states (whether encoder hidden states are represented as vectors). These minor overstatements and the omitted detail explain the slight deduction from a perfect score.",
      "summary_chars": 2469,
      "original_text_chars": 8021,
      "evaluation_time_seconds": 105.935913,
      "cosine_similarity": 0.3378
    },
    {
      "question_id": "sum_021",
      "query": "LSTM Gates (Forget, Input, Output)",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.8235294117647058,
      "success": true,
      "reason": "The score is 0.80 because the summary preserves the main LSTM ideas (forget gate, sigmoid, cell updates, and vanishing-gradient motivation) but contains inaccuracies and omissions: it incorrectly states the forget gate applies sigmoid to C_{t-1} rather than depending on previous hidden/state and current input; it adds unsupported claims that all gates use sigmoid and that gates+addition are explicitly presented as the primary long-term-memory mechanism; and it omits answerable details the original text contains (that Attention assigns weights to words by relevance and that Deep Stacked RNN is listed). These errors and extra assertions reduce faithfulness though the core points remain correct.",
      "summary_chars": 2116,
      "original_text_chars": 8782,
      "evaluation_time_seconds": 106.265243,
      "cosine_similarity": 0.2989
    },
    {
      "question_id": "sum_022",
      "query": "Context Cell/State in LSTM",
      "score": 0.8,
      "coverage_score": 0.9,
      "alignment_score": 0.8,
      "success": true,
      "reason": "The score is 0.80 because the summary is mostly faithful and clear but introduces several unsupported assertions and omits one answerable detail. Unsupported additions: it labels the context cell explicitly as \"long-term memory\" and distinct from a short-term hidden state; it generalizes gate activations (implying tanh is commonly used for gates) beyond the original which only mentions sigmoid for the output gate; and it claims the context cell specifically maintains long-range context across long sequences. Omitted detail: the summary did not state whether the original text indicates outputs are represented as sequences (the original can answer this: it does present outputs in sequence form). Overall the summary is accurate in many core points, hence a relatively high but not perfect score.",
      "summary_chars": 2591,
      "original_text_chars": 8789,
      "evaluation_time_seconds": 119.148739,
      "cosine_similarity": 0.3062
    },
    {
      "question_id": "sum_023",
      "query": "Bidirectional RNN (BiRNN)",
      "score": 0.9523809523809523,
      "coverage_score": 1.0,
      "alignment_score": 0.9523809523809523,
      "success": true,
      "reason": "The score is 0.95 because the summary is highly faithful to the original (no contradictions) and only introduces a minor unsupported detail about combining hidden vectors (mentioning summing/other methods versus the original's concatenation). This extra, nonessential detail slightly lowers fidelity but does not alter the core meaning.",
      "summary_chars": 2652,
      "original_text_chars": 9320,
      "evaluation_time_seconds": 79.4769,
      "cosine_similarity": 0.2566
    },
    {
      "question_id": "sum_024",
      "query": "Deep Stacked/Multi-layer RNN",
      "score": 0.75,
      "coverage_score": 0.9,
      "alignment_score": 0.75,
      "success": true,
      "reason": "The score is 0.75 because the summary correctly reflects core content (stacked RNNs learning from low- to high-level representations and listing Keras components and padding) but adds several inferred claims not present in the original (that Deep Stacked RNN’s explicit goal is to overcome single-layer limits; labeling single-layer RNNs as ‘low-level’ or ‘simple and limited’; asserting the text omits DeepStack disadvantages; and calling the implementation ‘straightforward’). It also omits a specific detail the original does mention (the use of cross-entropy and softmax). Overall the summary is mostly accurate but contains unwarranted inferences and a notable omission, justifying a 0.75 score.",
      "summary_chars": 2726,
      "original_text_chars": 8237,
      "evaluation_time_seconds": 103.352179,
      "cosine_similarity": 0.2923
    },
    {
      "question_id": "sum_025",
      "query": "Sequence-to-Sequence (Seq2Seq) Model",
      "score": 0.7619047619047619,
      "coverage_score": 0.9,
      "alignment_score": 0.7619047619047619,
      "success": true,
      "reason": "The score is 0.76 because the summary retains many core points but introduces multiple unsupported claims and omits one answerable detail. It ascribes purposes to listed variants (e.g., improving memory/representations) and presents an attention mechanism and its decoder-selection role—none of which the original text states; it also says the video introduces attention and that RNN/LSTM layers provide padding support, whereas the original only mentions a Sequence utility for padding. The summary further implies variants are required or guaranteed to handle long-range dependencies, which is not claimed. It also fails to state whether the original discusses using a pretrained model when dataset labels overlap, a question the original can answer. These extra/omitted elements reduce fidelity, but many correct elements remain, so the score is moderate.",
      "summary_chars": 2660,
      "original_text_chars": 8385,
      "evaluation_time_seconds": 103.72410800000002,
      "cosine_similarity": 0.237
    },
    {
      "question_id": "sum_026",
      "query": "Encoder-Decoder Architecture",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 0.7222222222222222,
      "success": true,
      "reason": "The score is 0.70 because the summary captures the main topics (encoder outputs s1..st, decoder inputs h1..ht, Q/K/V roles and the search/attention analogy) but introduces multiple unsupported specifics: it claims an encoder→decoder transformation explicitly governed by attention; states the attention mechanism computes a weighted sum of values; asserts self-attention explicitly lets each position reference other positions; and describes attention as a learned internal operation with weights — none of which the original text actually states. Additionally, the summary omits details the original could answer (e.g., presence of CS431 Chapter 10 video titles, use of “transformer architecture” as a search keyword, and that some computations across layers are performed in parallel). Overall, the summary is reasonably faithful to core ideas but overextends with extra, unjustified claims, so a 0.70 rating is appropriate.",
      "summary_chars": 2706,
      "original_text_chars": 2284,
      "evaluation_time_seconds": 76.31630199999998,
      "cosine_similarity": 0.2519
    },
    {
      "question_id": "sum_027",
      "query": "RNN Handling of Variable Length Sequences",
      "score": 0.7368421052631579,
      "coverage_score": 0.8,
      "alignment_score": 0.7368421052631579,
      "success": true,
      "reason": "The score is 0.74 because the summary is mostly faithful (no direct contradictions) but introduces several unsupported claims and omits some answerable details. Unsupported additions include stating the Model itself can load trained modules (instead of separate helper loaders), asserting post‑padding is the usual choice, implying RNN/LSTM are broadly used beyond the NLP contexts the original only discussed, and calling components ‘‘easy to integrate.’’ The summary also fails to mention specifics the original did (e.g., Keras and layers like Embedding and Dense, and that RNNs were widely used in early NLP), reducing completeness and accuracy despite overall correctness.",
      "summary_chars": 2586,
      "original_text_chars": 8597,
      "evaluation_time_seconds": 66.786202,
      "cosine_similarity": 0.2969
    },
    {
      "question_id": "sum_028",
      "query": "Skip Connection (Residual Module)",
      "score": 0.875,
      "coverage_score": 0.9,
      "alignment_score": 0.875,
      "success": true,
      "reason": "The score is 0.88 because the summary is largely faithful and contains no direct contradictions, but it adds extra specifics not present in the source (generalizing ResNet’s practical depth to \"tens to hundreds of layers\", framing ResNet explicitly as for classification, and broadly claiming improved \"training quality\") and fails to address the numeric question about the 214,000 value; these are modest overstatements/omissions, so the summary is high-quality but not perfect.",
      "summary_chars": 2921,
      "original_text_chars": 9431,
      "evaluation_time_seconds": 80.619597,
      "cosine_similarity": 0.2779
    },
    {
      "question_id": "sum_029",
      "query": "Convolutional Neural Networks (CNN) Introduction",
      "score": 0.8214285714285714,
      "coverage_score": 0.9,
      "alignment_score": 0.8214285714285714,
      "success": true,
      "reason": "The score is 0.82 because the summary remains largely faithful to the original and captures the main ideas (weight sharing, local connectivity, pooling, filters, example datasets/architectures), but it introduces several unsupported assertions and omits one explicit factual detail. Unsupported additions include claims that weight sharing means the same filter is applied across the entire image and that this yields translation invariance; statements of pooling’s specific purposes (reducing computation cost and ‘keeping important information’); a claim that the mechanism is explicitly described as ‘suitable’ for image data; an explicit hierarchical representation claim from edges to complex features; and an assertion that the Enix dataset was used to train LeNet. The summary also fails to state the original text’s explicit point that input color images often have depth 3. These extra/missing points reduce accuracy but do not completely undermine the summary’s overall correctness.",
      "summary_chars": 2939,
      "original_text_chars": 7451,
      "evaluation_time_seconds": 81.21251699999999,
      "cosine_similarity": 0.2505
    },
    {
      "question_id": "sum_030",
      "query": "Convolution Operation (Tích Chập)",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.95,
      "success": true,
      "reason": "The score is 0.90 because the summary accurately conveys the original's main points with no contradictions and is generally clear and faithful; however it adds one extra detail—explicitly defining convolution as an inner product between the local region and the filter—that was not present in the original, and it fails to answer whether LeNet emphasizes local connections and weight sharing to reduce parameter count, which the original could address. These minor issues justify the slight deduction from a perfect score.",
      "summary_chars": 2522,
      "original_text_chars": 9169,
      "evaluation_time_seconds": 63.27866999999999,
      "cosine_similarity": 0.2707
    },
    {
      "question_id": "sum_031",
      "query": "Filter/Kernel in CNNs",
      "score": 0.6,
      "coverage_score": 0.6,
      "alignment_score": 0.8421052631578947,
      "success": true,
      "reason": "The score is 0.60 because the summary captures some original points but includes extra, unsupported claims (implying the 28→14→7 reduction mechanism, asserting texture/hierarchical feature formation from filters, and stating training/data/overfitting drawbacks) that the original did not state, while also omitting several specific, answerable details the original provided (the example model’s activation choice, the ≈100,000 parameter count, the learned linear regression theta values, and the note about ANN computation/parallelism). There are no direct contradictions, but these additions and omissions reduce fidelity.",
      "summary_chars": 2698,
      "original_text_chars": 7395,
      "evaluation_time_seconds": 75.598777,
      "cosine_similarity": 0.2333
    },
    {
      "question_id": "sum_032",
      "query": "Feature Maps (Tensor Output)",
      "score": 0.8333333333333334,
      "coverage_score": 1.0,
      "alignment_score": 0.8333333333333334,
      "success": true,
      "reason": "The score is 0.83 because the summary is largely faithful (no direct contradictions) and preserves key points like pooling reducing spatial size and FC parameters and that two 3×3 convolutions give an effective 5×5 receptive field, but it adds unsupported or overgeneralized claims: it says pooling increases small translation invariance and reduces computational size, claims stacking small convolutions always yields fewer parameters and introduces extra nonlinearities, and adds classification/segmentation as example tasks—none of which are stated in the original. Overall accurate but contains extra, unstated assertions, so a moderately high score is warranted.",
      "summary_chars": 3073,
      "original_text_chars": 9406,
      "evaluation_time_seconds": 86.41799599999999,
      "cosine_similarity": 0.2862
    },
    {
      "question_id": "sum_033",
      "query": "Pooling Layer (Max Pooling/Average Pooling)",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 0.70 because the summary is generally faithful (no contradictions or added information) but lacks important factual details from the original: it omits whether convolutional layers share weights to reduce parameters, the final fully‑connected layer sizes (120, 84, 10), and that deep‑learning frameworks can infer input depth so users only specify filter width/height—these omissions reduce completeness.",
      "summary_chars": 2324,
      "original_text_chars": 9024,
      "evaluation_time_seconds": 84.14726300000001,
      "cosine_similarity": 0.2651
    },
    {
      "question_id": "sum_034",
      "query": "ReLU Activation Function",
      "score": 0.6,
      "coverage_score": 0.6,
      "alignment_score": 0.6923076923076923,
      "success": true,
      "reason": "The score is 0.60 because the summary is partly faithful but adds unsupported generalizations about ReLU (it asserts ReLU acts for z ≥ 0 rather than >0, and elevates AlexNet’s example into claims that ReLU is widely applied/popular/favored in practice) while not introducing direct contradictions. The summary also omits explicit details that the original text contains (that the four main CNN transformations are convolution, activation, pooling, and fully connected; that flattening is done before the fully connected layer; the example input tensor of size 3×3×2; and that the example dataset has 10 classes). These extra, unsupported claims plus omitted factual details reduce fidelity and completeness, justifying a middling 0.60 score.",
      "summary_chars": 1482,
      "original_text_chars": 8066,
      "evaluation_time_seconds": 61.83874800000001,
      "cosine_similarity": 0.2594
    },
    {
      "question_id": "sum_035",
      "query": "Sigmoid/Tanh Activation Functions",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 0.875,
      "success": true,
      "reason": "The score is 0.70 because the summary is largely accurate and contains no direct contradictions, but it adds unsupported claims (calling the document a “short and comprehensive summary” and implying sigmoid is never used for multi-class) and omits specific, answerable details present in the original (the size‑reduction benefits of reducing overfitting and speeding training, that the dataset has 10 classes, and use of the ADAM optimizer). These extra assertions and missing concrete facts lower fidelity from excellent to moderate.",
      "summary_chars": 2125,
      "original_text_chars": 8681,
      "evaluation_time_seconds": 62.569824999999994,
      "cosine_similarity": 0.2537
    },
    {
      "question_id": "sum_036",
      "query": "Fully Connected (Dense) Layer",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.8076923076923077,
      "success": true,
      "reason": "The score is 0.80 because the summary is largely accurate and clear (no direct contradictions) but it introduces several unstated specifics and generalizations beyond the original text—e.g., asserting the linear-combination-then-activation formulation for every output, giving a general dense-layer parameter formula, presenting Dense(...) argument signatures, and making explicit claims about convolutional kernels (locality, weight sharing, spatial preservation) and that FCs always have more parameters than convolutions. It also omits answers to two concrete implementation points the original did cover (whether pooling with stride=2 halves spatial dimensions, and that Keras RNN/LSTM examples use Embedding + Dense). These added inferences and omitted details reduce perfect fidelity, so 0.80 is appropriate.",
      "summary_chars": 2907,
      "original_text_chars": 8142,
      "evaluation_time_seconds": 78.62506400000001,
      "cosine_similarity": 0.229
    },
    {
      "question_id": "sum_037",
      "query": "Weight Sharing in CNNs",
      "score": 0.6,
      "coverage_score": 0.6,
      "alignment_score": 0.6428571428571429,
      "success": true,
      "reason": "The score is 0.60 because the summary includes several unsupported additions (e.g., implying the 4 million parameter count was before weight sharing, claiming weight sharing directly saves memory/compute, and showing an exact API call like model.layers[i].get_weights()) while omitting multiple concrete details present in the original (use of categorical cross-entropy, sigmoid activation in the CNN example, fully connected layer sizes 120 and 84, and the reported RNN/LSTM loss ≈0.7 with accuracy ≈51–52%), lowering fidelity even though there are no outright contradictions.",
      "summary_chars": 1932,
      "original_text_chars": 7694,
      "evaluation_time_seconds": 51.857004,
      "cosine_similarity": 0.3022
    },
    {
      "question_id": "sum_038",
      "query": "Local Connectivity in CNNs",
      "score": 0.5,
      "coverage_score": 0.5,
      "alignment_score": 0.8571428571428571,
      "success": true,
      "reason": "The score is 0.50 because the summary partially reflects the original (DELF/CNN produce dense local-region features) but adds unsupported claims — e.g., calling the document a “concise and comprehensive summary” and asserting explicit downstream applications (classification, image retrieval, or ‘‘compare/locate content’’) that the original does not state. The summary also omits concrete details present in the original that it could have reported: use of sigmoid activation, loading data via keras.datasets and mnist.load_data, logistic-regression output as a single sigmoid node, mentions of RNN/LSTM architectures, and training metrics around loss ≈0.7 and accuracy ≈51–52%, reducing fidelity and completeness.",
      "summary_chars": 2523,
      "original_text_chars": 7637,
      "evaluation_time_seconds": 73.85914199999999,
      "cosine_similarity": 0.2234
    },
    {
      "question_id": "sum_039",
      "query": "Overfitting Mitigation",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.8333333333333334,
      "success": true,
      "reason": "The score is 0.80 because the summary is mostly faithful but introduces several unsupported claims and omits some details: it overstates parameter reduction as the primary fix for overfitting (the original presented it alongside other strategies), implies AlexNet used augmentation and that hardware/architectural speedups directly translate to improved real‑world performance (the original only noted AlexNet ran on TPU with ~50× faster training and discussed augmentation separately), and adds a recommendation to choose an ‘appropriate combination’ by data/task that the original did not explicitly state. It also fails to report two points the original did: whether architectures primarily address overfitting/vanishing gradients and that AlexNet was adapted to TPU yielding about 50× faster training.",
      "summary_chars": 2469,
      "original_text_chars": 8845,
      "evaluation_time_seconds": 65.941018,
      "cosine_similarity": 0.2906
    },
    {
      "question_id": "sum_040",
      "query": "Data Augmentation",
      "score": 0.3,
      "coverage_score": 0.3,
      "alignment_score": 0.6666666666666666,
      "success": false,
      "reason": "The score is 0.30 because the summary adds several unsupported claims about augmentation (that it makes models invariant to transformations; a general rule to apply augmentation only when training data is small; and statements about when/ how augmentation is applied and combined with other improvements) and overgeneralizes AlexNet’s usage, while failing to include many concrete facts the original text did provide (guidance on freezing feature layers vs training whole network, use of keras.datasets.load_data for MNIST, that logistic regression used a sigmoid activation and 2‑D input features, the WebFace dataset description, and that ReLU helps reduce vanishing gradients and speeds training). These extra assertions and omissions reduce fidelity and completeness, justifying the low score.",
      "summary_chars": 1514,
      "original_text_chars": 9039,
      "evaluation_time_seconds": 65.783776,
      "cosine_similarity": 0.2144
    },
    {
      "question_id": "sum_041",
      "query": "ResNet Architecture",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.85,
      "success": true,
      "reason": "The score is 0.80 because the summary is mostly faithful (no direct contradictions) and preserves core points—residual/skip connections, deeper networks, and ResNet as a CV backbone—but it includes unwarranted extra specifics (claims a specific residual-block ordering: “conv → ReLU → conv → ReLU”; implies deeper configurations necessarily yield lower training error; and lists tasks like detection/classification that the original did not explicitly enumerate). It also failed to include facts the original could answer (whether ResNet won the 2015 contest and that prior architectures like AlexNet/VGG/Inception initially showed depth improved accuracy). These added specifics and omissions reduce accuracy but not severely, justifying a 0.80 score.",
      "summary_chars": 2736,
      "original_text_chars": 10466,
      "evaluation_time_seconds": 85.509511,
      "cosine_similarity": 0.2748
    },
    {
      "question_id": "sum_042",
      "query": "MobileNet Architecture",
      "score": 0.75,
      "coverage_score": 0.9,
      "alignment_score": 0.75,
      "success": true,
      "reason": "The score is 0.75 because the summary is largely faithful in portraying MobileNet as lightweight and computationally efficient, but it includes several unsupported additions: it compares depthwise separable convolution (DSC) to the Inception/Google bottleneck (not mentioned in the original), claims DSC increases derivative magnitude and thus reduces the vanishing gradient (the original attributes vanishing-gradient reduction to replacing sigmoid with ReLU), and implies there are no other MobileNet drawbacks (not specified). The summary also omitted a verifiable detail present in the original — that AlexNet replaced sigmoid with ReLU to help reduce the vanishing-gradient problem. No direct contradictions were found.",
      "summary_chars": 2073,
      "original_text_chars": 5543,
      "evaluation_time_seconds": 58.633883,
      "cosine_similarity": 0.2303
    },
    {
      "question_id": "sum_043",
      "query": "Depthwise Separable Convolution",
      "score": 0.6,
      "coverage_score": 0.6,
      "alignment_score": 0.625,
      "success": true,
      "reason": "The score is 0.60 because the summary roughly captures the main ideas (DSC described as depthwise followed by pointwise and MobileNet uses DSC to reduce computation) but adds several specific claims not present in the original (e.g., that depthwise uses one 3×3 filter per input channel, that pointwise’s role is explicitly to “mix” channels, likening DSC to Google’s “bottleneck”, that DSC increases gradient magnitudes, and that MobileNet is intended for mobile/low-resource devices). The summary also omits explicit answers to factual points the original did state or could answer (whether the example image has 3 RGB channels, that Softmax outputs probabilities summing to 1, that stride-2 pooling halves spatial dims, and that pooling acts independently per channel). There are no direct contradictions, but the added unsupported specifics and omitted explicit answers reduce fidelity, so a mid-range score is appropriate.",
      "summary_chars": 2027,
      "original_text_chars": 8887,
      "evaluation_time_seconds": 61.123926,
      "cosine_similarity": 0.1845
    },
    {
      "question_id": "sum_044",
      "query": "CNN Visualization Techniques",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 0.70 because the summary correctly reflects the main points without contradictions or added content, but it omits specific technical details present in the original — it fails to state that input images have depth 3 (three color channels), that pooling with stride S = 2 halves the feature-map width and height, and that CNNs are applied to object-detection tasks such as those used in autonomous vehicles — reducing completeness for technical readers.",
      "summary_chars": 2180,
      "original_text_chars": 8782,
      "evaluation_time_seconds": 81.71971200000002,
      "cosine_similarity": 0.3003
    },
    {
      "question_id": "sum_045",
      "query": "Object Detection (YOLO/R-CNN)",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 0.9,
      "success": true,
      "reason": "The score is 0.70 because the summary is mostly faithful (no direct contradictions) and preserves core points, but it introduces unsupported specifics about two-stage methods—claiming a two-step RPN+classifier workflow and explicitly stating two-stage approaches combine an RPN and classifier—which were not present in the original. It also omits several factual details the original did provide (YOLO version status by 2024; that CNNs are used for localization, detection, and semantic segmentation; and the stated accuracy gap of Faster R-CNN vs YOLO), reducing completeness. Overall accurate in tone but slightly over-specific and missing some original facts.",
      "summary_chars": 2581,
      "original_text_chars": 9027,
      "evaluation_time_seconds": 55.558324,
      "cosine_similarity": 0.2318
    },
    {
      "question_id": "sum_046",
      "query": "Semantic Segmentation (U-Net)",
      "score": 0.7241379310344828,
      "coverage_score": 0.8,
      "alignment_score": 0.7241379310344828,
      "success": true,
      "reason": "The score is 0.72 because the summary preserves the main distinctions (classification, detection, semantic vs. instance segmentation, and U-Net as an encoder–decoder) so it is mostly faithful, but it adds several unsupported claims and overstatements and omits some original details. Extra unsupported additions include labeling the document as “concise and comprehensive” about U‑Net, asserting CNN classification is only a binary (yes/no) task, explicitly phrasing instance segmentation as ‘per‑instance’ pixel separation and as the highest localization level, claiming semantic segmentation inherently won’t distinguish instances without an instance module, elaborating the encoder’s role as multiscale feature extraction beyond the original wording, and applying semantic segmentation directly to pixel‑level face localization and saying detection is inherently faster/more suitable than segmentation. The summary also fails to include points the original did cover: that Word2Vec represents each word by a vector (a row in matrix W) and that face recognition can use embeddings compared via cosine or distance. There are no direct contradictions, so overall the summary is largely accurate but weakened by these added assertions and omissions, hence a moderate–high score.",
      "summary_chars": 3134,
      "original_text_chars": 7471,
      "evaluation_time_seconds": 83.318259,
      "cosine_similarity": 0.2899
    },
    {
      "question_id": "sum_047",
      "query": "Gradient Descent Optimization",
      "score": 0.9130434782608695,
      "coverage_score": 1.0,
      "alignment_score": 0.9130434782608695,
      "success": true,
      "reason": "The score is 0.91 because the summary accurately and concisely captures the original's main points and is mostly faithful; its only faults are two small additions not present in the source: it adds an evaluative claim that GD is generally \"effective\" and \"simple and common,\" and it mentions a 'fit' call/workflow beyond the original's explicit compile/auto-diff discussion. These minor extrapolations justify a slightly less-than-perfect score.",
      "summary_chars": 2557,
      "original_text_chars": 9315,
      "evaluation_time_seconds": 56.70183800000001,
      "cosine_similarity": 0.2191
    },
    {
      "question_id": "sum_048",
      "query": "Adam Optimizer",
      "score": 0.47058823529411764,
      "coverage_score": 0.6,
      "alignment_score": 0.47058823529411764,
      "success": false,
      "reason": "The score is 0.47 because the summary adds several unsupported claims (e.g., labeling Adam a \"trick/technique\" or saying people commonly pick Adam first, recommending it as a default with little tuning, advising default/reference hyperparameters, implying metrics are combined in model.compile, and asserting applicability to all model types) that are not present in the original, while also omitting specific factual details the original does provide or can answer (e.g., whether the output neuron count is 10, whether accuracy is used as the metric, whether to call cell.model.compile to integrate the optimizer, and whether sigmoid is used for binary classification). There are no direct contradictions, but these extra assertions and misses lower the summary’s fidelity, justifying the middling score.",
      "summary_chars": 2316,
      "original_text_chars": 8739,
      "evaluation_time_seconds": 56.968175,
      "cosine_similarity": 0.2175
    },
    {
      "question_id": "sum_049",
      "query": "Binary Cross Entropy Loss",
      "score": 0.7777777777777778,
      "coverage_score": 1.0,
      "alignment_score": 0.7777777777777778,
      "success": true,
      "reason": "The score is 0.78 because the summary is mostly accurate but contains moderate errors: it wrongly frames large gradients from very wrong predictions as an advantage (the original flagged large log values/large gradients as a numerical disadvantage), and it adds unsupported details—claiming BCE is used for MLP/CNN with a single sigmoid output, implying implementations should be vectorized for efficiency, and referencing 'CS431 lectures'—none of which the original text explicitly states; these inaccuracies reduce fidelity but do not completely undermine the summary.",
      "summary_chars": 1879,
      "original_text_chars": 7838,
      "evaluation_time_seconds": 76.003391,
      "cosine_similarity": 0.2148
    },
    {
      "question_id": "sum_050",
      "query": "Categorical Cross Entropy Loss",
      "score": 0.4375,
      "coverage_score": 0.6,
      "alignment_score": 0.4375,
      "success": false,
      "reason": "The score is 0.44 because the summary misrepresents key math and adds unsupported claims: it asserts a '-log' / loss_sample = -∑_i y_i log p_i formulation that contradicts the original, which (incorrectly) described cross-entropy by multiplying y_i with ŷ_i and summing. The summary also inserts extra details not present in the source (claims about being a concise summary, the exact Keras loss string 'categorical_crossentropy', causal statements about replacing MSE being ‘more appropriate’, extending categorical cross-entropy to RNN/LSTM, and explicit mean-formula expressions). Additionally, the summary omits concrete implementation details the original contains (e.g., use of ADAM, momentum=0.9, embedding length, training for 3 epochs), reducing fidelity—hence a below‑average score.",
      "summary_chars": 1767,
      "original_text_chars": 7755,
      "evaluation_time_seconds": 70.976572,
      "cosine_similarity": 0.2291
    }
  ]
}