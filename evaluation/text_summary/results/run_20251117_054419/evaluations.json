{
  "run_info": {
    "run_id": "run_20251117_054419",
    "timestamp": "20251117_054419",
    "total_questions": 50,
    "successful_evaluations": 50,
    "failed_evaluations": 0,
    "evaluation_model": "gpt-5-mini",
    "threshold": 0.5,
    "n_questions": 10
  },
  "statistics": {
    "overall": {
      "mean": 0.700934981913586,
      "min": 0.25,
      "max": 1.0,
      "median": 0.7368421052631579,
      "std": 0.16137754808671573
    },
    "coverage": {
      "mean": 0.784,
      "min": 0.4,
      "max": 1.0
    },
    "alignment": {
      "mean": 0.7851764737085104,
      "min": 0.25,
      "max": 1.0
    }
  },
  "scores": [
    {
      "question_id": "sum_001",
      "query": "Transformer Architecture",
      "score": 0.7619047619047619,
      "coverage_score": 0.9,
      "alignment_score": 0.7619047619047619,
      "success": true,
      "reason": "The score is 0.76 because the summary is largely faithful (no direct contradictions) but adds several unsupported claims and overstatements—e.g., that Transformers were developed specifically to replace RNNs and to primarily reduce vanishing gradients, that increasing layers necessarily demands many more parameters/resources, and explicit functional claims about residual connections and model roles (BERT encoder‑only, GPT decoder‑only) not stated in the original. It also omits a concrete, answerable detail from the original (whether residual connections add the layer input to its output). These extra assertions and the omission reduce precision, so the summary is good but not fully accurate or complete.",
      "summary_chars": 2753,
      "original_text_chars": 8293,
      "evaluation_time_seconds": 94.333642
    },
    {
      "question_id": "sum_002",
      "query": "Attention Mechanism",
      "score": 0.7727272727272727,
      "coverage_score": 0.9,
      "alignment_score": 0.7727272727272727,
      "success": true,
      "reason": "The score is 0.77 because the summary accurately captures core attention mechanics (dot‑product scores, normalization, weighted sum, cross/self‑attention, alleviating encoder–decoder bottleneck, role in Transformers) but introduces several unsupported claims (that the context vector is combined with h_t to form outputs; that attention explicitly ‘supports long‑range dependency learning’ by weighting; that self‑attention is inherently ‘efficient for whole‑sequence processing’; and broad claims about attention’s use across many tasks). The summary also omits some source details (e.g., mention of ANN variants such as LSTM and bidirectional networks). There are no direct contradictions, but these extra/unwarranted generalizations and omissions reduce faithfulness, justifying a moderately high but not perfect score.",
      "summary_chars": 3487,
      "original_text_chars": 8156,
      "evaluation_time_seconds": 95.23238699999999
    },
    {
      "question_id": "sum_003",
      "query": "Self-Attention",
      "score": 0.7894736842105263,
      "coverage_score": 1.0,
      "alignment_score": 0.7894736842105263,
      "success": true,
      "reason": "The score is 0.79 because the summary preserves the core ideas (self-attention computed in parallel within a layer, layers are sequential, and multi-head self-attention is used) and contains no major factual contradictions, but it includes several unsupported additions that lower fidelity—claiming the summary is “concise/comprehensive,” implying queries/keys/values are explicitly taken from the previous layer, asserting multi-heads split representations to learn different interactions, and invoking RNN comparisons—all details not stated in the original. Overall accurate but slightly over-assertive, hence a high but not perfect score.",
      "summary_chars": 2915,
      "original_text_chars": 7832,
      "evaluation_time_seconds": 103.68709600000001
    },
    {
      "question_id": "sum_004",
      "query": "Multi-Head Self-Attention",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9090909090909091,
      "success": true,
      "reason": "The score is 0.90 because the summary largely matches the original and is accurate overall (good fidelity), but contains minor unsupported additions — it frames fixed sinusoidal positional encodings as a weakness and asserts specific applications (machine translation/generation) that the original did not state — and it omits an explicit confirmation of whether the decoder output still uses token and positional embeddings, leaving that question unanswered by the summary.",
      "summary_chars": 2719,
      "original_text_chars": 8822,
      "evaluation_time_seconds": 104.214018
    },
    {
      "question_id": "sum_005",
      "query": "Query, Key, and Value (QKV) Vectors",
      "score": 0.8260869565217391,
      "coverage_score": 1.0,
      "alignment_score": 0.8260869565217391,
      "success": true,
      "reason": "The score is 0.83 because the summary correctly conveys the main ideas (no direct contradictions) but includes several details not supported by the original—asserting per-head W_Q/W_K/W_V matrices, explicitly stating heads’ outputs are concatenated then projected, adding evaluative language about attention being ‘flexible and powerful,’ and claiming many heads increase parameter count—so faithfulness is good but diluted by those unsupported additions.",
      "summary_chars": 2434,
      "original_text_chars": 8277,
      "evaluation_time_seconds": 110.819975
    },
    {
      "question_id": "sum_006",
      "query": "Attention Score Calculation",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9,
      "success": true,
      "reason": "The score is 0.90 because the summary correctly reflects the original’s equations, masking, and that multi‑head attention enables parallelization and GPU efficiency (no contradictions), but it adds an unsupported inference—that Q/K/V are split into multiple heads specifically to learn diverse similarity patterns—which the original did not explicitly state. The summary also omits an example the original gives (whether the word 'sua' can have the largest influence on the next prediction). These minor unsupported claims and the missed example slightly lower fidelity, though overall the summary is accurate and concise.",
      "summary_chars": 2528,
      "original_text_chars": 9017,
      "evaluation_time_seconds": 74.069011
    },
    {
      "question_id": "sum_007",
      "query": "Attention Distribution (Softmax)",
      "score": 1.0,
      "coverage_score": 1.0,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 1.00 because the summary perfectly reflects the original text: it contains no contradictions or added details and accurately and concisely conveys the original content.",
      "summary_chars": 2550,
      "original_text_chars": 8480,
      "evaluation_time_seconds": 89.582629
    },
    {
      "question_id": "sum_008",
      "query": "Attention Output/Context Vector",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9545454545454546,
      "success": true,
      "reason": "The score is 0.90 because the summary is largely faithful and concise, preserving the original's main points, but it introduced an extra unsupported claim that attention \"improves\" translation/long-range dependency handling (not stated in the original) and omitted mention that the work used bidirectional encoding (left-to-right and right-to-left) and an LSTM cell—small omissions, hence a high but not perfect score.",
      "summary_chars": 2036,
      "original_text_chars": 8523,
      "evaluation_time_seconds": 110.504319
    },
    {
      "question_id": "sum_009",
      "query": "Cross-Attention (Encoder-Decoder Attention)",
      "score": 0.5789473684210527,
      "coverage_score": 0.8,
      "alignment_score": 0.5789473684210527,
      "success": true,
      "reason": "The score is 0.58 because the summary adds several unsupported claims (e.g., that cross‑attention is implemented as multi‑head, a specific decoder block ordering including the final linear/output embedding, whether cross‑attention is masked, that attention reduces overfitting, that cross‑attention specifically enables parallelization, and that cross‑attention is ‘mandatory’ or that disadvantages were omitted) which are not in the source, while also failing to confirm source facts the original does provide (notably whether positional embeddings were mentioned and whether self‑attention enables parallel/parallelized computation), reducing fidelity and completeness.",
      "summary_chars": 2762,
      "original_text_chars": 8654,
      "evaluation_time_seconds": 130.284826
    },
    {
      "question_id": "sum_010",
      "query": "Masked Multi-Head Self-Attention",
      "score": 0.8181818181818182,
      "coverage_score": 1.0,
      "alignment_score": 0.8181818181818182,
      "success": true,
      "reason": "The score is 0.82 because the summary accurately captures most of the model structure and contains no direct contradictions with the original, but it introduces several unsupported specifics: it claims the final linear matrix is d×d, it asserts an explicit 'Add & Norm → cross‑attention → Add & Norm' sequencing, it states that projections necessarily increase parameter and compute cost, and it labels masked MHA as the definitive main component and always preceding cross‑attention. These added assumptions reduce strict faithfulness, so the summary is largely good but not fully supported by the original.",
      "summary_chars": 2793,
      "original_text_chars": 8771,
      "evaluation_time_seconds": 193.772764
    },
    {
      "question_id": "sum_011",
      "query": "Transformer Encoder Architecture",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9047619047619048,
      "success": true,
      "reason": "The score is 0.90 because the summary is largely faithful and concise, capturing the core model flow (input embedding → self‑attention → stacked encoder layers) and the computational cost, with no contradictions; however it adds two unsupported specifics—presenting 'addition, normalization, feed‑forward' as the enumerated main flow steps and claiming stacking/dimensional increases ‘require many parameters’ (the original only noted stacking and higher compute/memory O(T^2), not parameter counts)—and it omits that BERT and GPT are trained self‑supervised without labeled data. Overall the summary is clear and mostly accurate.",
      "summary_chars": 3058,
      "original_text_chars": 8990,
      "evaluation_time_seconds": 91.78499800000002
    },
    {
      "question_id": "sum_012",
      "query": "Transformer Decoder Architecture",
      "score": 0.5,
      "coverage_score": 0.5,
      "alignment_score": 0.85,
      "success": true,
      "reason": "The score is 0.50 because the summary contains several unsupported additions (it claims the decoder uses both encoder-and self-attention results, calls a Decoder Transformer “easy to integrate” into generative models, and labels the document a “concise, comprehensive summary” and CS431) while omitting multiple details the original did provide (whether the encoder’s first module is named “shareattention,” BERT’s full name, that BERT and GPT are Transformer-based and self-supervised, and that pre-Transformer NLP used RNNs/LSTMs). There are no direct contradictions, which is a positive.",
      "summary_chars": 2675,
      "original_text_chars": 8327,
      "evaluation_time_seconds": 96.755289
    },
    {
      "question_id": "sum_013",
      "query": "Positional Encoding/Embedding",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 0.76,
      "success": true,
      "reason": "The score is 0.70 because the summary correctly captures the high-level idea (sinusoidal positional encodings and self-attention) and contains no contradictions, but it adds several specifics not present in the original (explicit even/odd formulas P_{2i}(y)=sin(y/10000^{2i/D}) and P_{2i+1}(y)=cos(...), the exact D/2 sin–cos pairing, explicit claims that the method is ‘simple’ and parameter-free, mentions replacing sinusoid with other functions, and implies effects on overall computational cost). It also fails to answer some architecture questions the original could address (whether the decoder has feedforward+add-norm; whether multihead attention is applied multiple times to capture different relations; whether a linear layer projects features to output labels). Overall the summary is faithful at a high level but over-specific and omits some practical details, justifying a moderate score.",
      "summary_chars": 2814,
      "original_text_chars": 8908,
      "evaluation_time_seconds": 231.23615999999998
    },
    {
      "question_id": "sum_014",
      "query": "Feed-Forward Networks in Transformer",
      "score": 0.5,
      "coverage_score": 0.5,
      "alignment_score": 0.75,
      "success": true,
      "reason": "The score is 0.50 because the summary contains several unsupported additions (e.g., asserting FFNs appear in both encoder and decoder, claiming a specific Attention → Add & Norm → FFN → Add & Norm ordering, and noting the absence of a document title) that the original does not state, while also omitting multiple answerable details (decoder embeddings and positional embeddings, presence of multi‑head and cross attention, use of scaled dot‑product + softmax, concatenation of head outputs, and sinusoidal positional encoding). There are no direct contradictions, but the extra ungrounded claims and missing details reduce the summary’s fidelity and completeness.",
      "summary_chars": 2144,
      "original_text_chars": 7591,
      "evaluation_time_seconds": 195.761234
    },
    {
      "question_id": "sum_015",
      "query": "BERT Model Architecture",
      "score": 0.5,
      "coverage_score": 0.5,
      "alignment_score": 0.8181818181818182,
      "success": true,
      "reason": "The score is 0.50 because the summary adds several evaluative/scope claims about BERT (e.g., calling the document a “brief and comprehensive summary,” asserting bidirectionality directly yields “strong and effective” representations, framing the masked‑LM objective as not optimizing downstream tasks, and saying fine‑tuning is “easy”) that are not stated in the original, while also omitting concrete factual details the original contains (that BERT/GPT are self‑supervised, that the CNN example uses softmax for multi‑class classification, the Word2Vec embedding matrix size ≈1M×300, the CNN has 10 output classes, and use of the ADAM optimizer); it does not, however, introduce direct contradictions with the source.",
      "summary_chars": 2209,
      "original_text_chars": 8419,
      "evaluation_time_seconds": 89.39317299999999
    },
    {
      "question_id": "sum_016",
      "query": "GPT Model Architecture",
      "score": 0.88,
      "coverage_score": 1.0,
      "alignment_score": 0.88,
      "success": true,
      "reason": "The score is 0.88 because the summary is largely accurate and contains no contradictions, but it adds unsupported details—claiming there are “2 ways” to exploit foundation models and implying a second approach that the original does not describe, and introducing computational-cost as a disadvantage of start/end tokens and sequential decoding that the original did not mention—warranting a small penalty.",
      "summary_chars": 2587,
      "original_text_chars": 8354,
      "evaluation_time_seconds": 91.795281
    },
    {
      "question_id": "sum_017",
      "query": "Vanishing Gradient Problem",
      "score": 0.85,
      "coverage_score": 1.0,
      "alignment_score": 0.85,
      "success": true,
      "reason": "The score is 0.85 because the summary is largely faithful with no direct contradictions, but it introduces three unsupported extrapolations: that skip connections are applied to stacked RNNs, that Transformers were explicitly designed to avoid transmitting gradients sequentially through many timesteps, and that fully remedying vanishing gradients requires combining many techniques. These plausible but unverified claims reduce fidelity slightly.",
      "summary_chars": 3025,
      "original_text_chars": 8379,
      "evaluation_time_seconds": 78.475639
    },
    {
      "question_id": "sum_018",
      "query": "Computational Cost of Self-Attention",
      "score": 0.7692307692307693,
      "coverage_score": 0.8,
      "alignment_score": 0.7692307692307693,
      "success": true,
      "reason": "The score is 0.77 because the summary correctly conveys the core strengths and weaknesses of self-attention (parallelizability, GPU efficiency, computational cost, and positional representation issues) but introduces several unsupported or speculative claims and omits some supported points. Specifically, it adds unverified statements about whether masking still allows full parallel execution in the decoder, whether multi-head attention changes the O(T^2) scaling, and that self-attention is unsuitable for very long sequences unless optimizations are applied—none of which the original text asserted. It also fails to mention original-supported details about the importance of relative positional information and that Shaw et al. (2018) showed modeling relative position can improve accuracy. These extra/unverified assertions and omissions lower fidelity, yielding a high-but-not-perfect score.",
      "summary_chars": 1622,
      "original_text_chars": 8734,
      "evaluation_time_seconds": 68.18831
    },
    {
      "question_id": "sum_019",
      "query": "Recurrent Neural Networks (RNN) Architecture",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.85,
      "success": true,
      "reason": "The score is 0.80 because the summary is mostly faithful—covering RNN topics, NMT/encoder–decoder structure and sequence data—yet it adds three unsupported claims (calling the document a ‘short/comprehensive’ summary, and listing language modeling and time‑series as applications not stated in the original) and omits details the original did provide (that classical models like linear regression are presented as simpler building blocks and that MT examples include conversions such as English↔French). These extra assertions and omissions lower accuracy but do not fatally undermine the summary.",
      "summary_chars": 2371,
      "original_text_chars": 8807,
      "evaluation_time_seconds": 92.638043
    },
    {
      "question_id": "sum_020",
      "query": "Long Short-Term Memory (LSTM) Architecture",
      "score": 0.65,
      "coverage_score": 1.0,
      "alignment_score": 0.65,
      "success": true,
      "reason": "The score is 0.65 because the summary generally aligns with the source (no direct contradictions) but includes several unsupported additions and inferences not present in the original: precise dates for LSTM/Transformer, explicit claims that LSTM was designed to fix vanishing gradients/long‑term dependencies and that it empirically handles longer dependencies better, that stacking LSTM layers is specifically to increase sequence representation, and that Transformers replaced many LSTM roles because of pure attention. These extra, unstated assertions reduce faithfulness even though the core points match, so the summary is useful but not fully faithful.",
      "summary_chars": 2464,
      "original_text_chars": 8080,
      "evaluation_time_seconds": 85.085799
    },
    {
      "question_id": "sum_021",
      "query": "LSTM Gates (Forget, Input, Output)",
      "score": 0.6086956521739131,
      "coverage_score": 0.8,
      "alignment_score": 0.6086956521739131,
      "success": true,
      "reason": "The score is 0.61 because the summary captures core facts from the original (that LSTMs have Forget, Input, and Output gates and mentions sigmoid/vanishing-gradient context) but adds several specifics not present in the source (e.g., judging the summary as “short and comprehensive,” claiming gates ‘‘usually’’ use sigmoid to produce 0..1 coefficients, detailed read/write/selective-update mechanics for the Input Gate, and explicit output-control wording for the Output Gate, plus claims about gates maintaining gradients). The summary also omits some concrete points the original did answer (whether Attention output is used to compute decoder outputs and that RNN/LSTM outputs are sequences). Those extra/unjustified details and the omissions lower fidelity, producing a moderate score.",
      "summary_chars": 2815,
      "original_text_chars": 8832,
      "evaluation_time_seconds": 105.56453000000002
    },
    {
      "question_id": "sum_022",
      "query": "Context Cell/State in LSTM",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.9629629629629629,
      "success": true,
      "reason": "The score is 0.80 because the summary is largely faithful and contains no contradictions (good), but it introduces an unsupported explicit claim that the context cell is the ‘main path’ for gradients across many time steps—information not present in the original—and it omits answerable details about whether LSTM cells are processed sequentially like ANN cells and whether the text mentions bidirectional encoding; these additions and omissions reduce fidelity though they do not severely distort the original.",
      "summary_chars": 3219,
      "original_text_chars": 8425,
      "evaluation_time_seconds": 86.051365
    },
    {
      "question_id": "sum_023",
      "query": "Bidirectional RNN (BiRNN)",
      "score": 0.5,
      "coverage_score": 0.8,
      "alignment_score": 0.5,
      "success": true,
      "reason": "The score is 0.50 because the summary mixes some accurate points (correctly describing bidirectional reading and that BiRNNs aren’t suitable for next-token prediction) with many unsupported additions and overstatements not present in the original (e.g., specific implementation claims like two independent RNNs, concatenation of directional hidden states, explicit naming such as ‘BiLSTM’ or ‘BiRNN + attention’, that BiRNN+LSTM was commonly used to fix vanishing gradients, decoder unidirectionality, increased computational cost, and extra listed applications like NER). It also fails to include some facts the original did state (e.g., explicit machine-translation language examples and that attention will be discussed). Those extra, unstated claims harm faithfulness and completeness, producing a middling score.",
      "summary_chars": 3137,
      "original_text_chars": 8711,
      "evaluation_time_seconds": 205.293885
    },
    {
      "question_id": "sum_024",
      "query": "Deep Stacked/Multi-layer RNN",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 0.80 because the summary is generally accurate, concise, and faithful to the original with no contradictions or added claims; however it omits two factual points present in the source — that RNNs were widely used in early NLP and that machine translation and attention mechanisms will be studied — which reduces completeness.",
      "summary_chars": 2805,
      "original_text_chars": 8005,
      "evaluation_time_seconds": 108.991659
    },
    {
      "question_id": "sum_025",
      "query": "Sequence-to-Sequence (Seq2Seq) Model",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 0.8518518518518519,
      "success": true,
      "reason": "The score is 0.70 because the summary correctly conveys core Seq2Seq ideas but adds unsupported specifics (claims it is a “short, complete summary” of Seq2Seq; asserts the encoder’s final hidden state is passed as the decoder initial state; states each generated token/embedding is fed back as the next input; and even gives a specific decoded token sequence 'NE → SUI → PA → N(end)' not found in the source), while also omitting answerable details that the original includes (softmax for multi-class, Adam optimizer, ResNet50 as a pretrained extractor), so fidelity and completeness are only moderate.",
      "summary_chars": 3242,
      "original_text_chars": 8743,
      "evaluation_time_seconds": 84.78111100000001
    },
    {
      "question_id": "sum_026",
      "query": "Encoder-Decoder Architecture",
      "score": 0.5625,
      "coverage_score": 0.8,
      "alignment_score": 0.5625,
      "success": true,
      "reason": "The score is 0.56 because the summary mixes partly accurate points with several extra or overstated claims not present in the source (e.g., labeling self‑attention and the decoder as explicitly “central”; asserting the cross‑attention rule that queries come from the decoder and keys/values from the encoder as if directly stated; equating K/Q/V to static metadata rather than internal representations; presenting ‘‘advantages’’ as a listed claim; and rephrasing the search example in ways the source does not). The summary does correct a key/query confusion but still omits a clear procedural description of cross‑attention and fails to mention some specific source details that were present (references to CS431 - Chương 10 videos and multiple occurrences of the word “video”). These added, sometimes misleading details plus those omissions lower fidelity despite some correct material, justifying a middling score.",
      "summary_chars": 2385,
      "original_text_chars": 2284,
      "evaluation_time_seconds": 101.015952
    },
    {
      "question_id": "sum_027",
      "query": "RNN Handling of Variable Length Sequences",
      "score": 0.6190476190476191,
      "coverage_score": 0.9,
      "alignment_score": 0.6190476190476191,
      "success": true,
      "reason": "The score is 0.62 because the summary adds many unsupported details and omits at least one simple point the original does provide: it introduces specifics not in the source (per-step outputs ŷ_t, per-step loss L_t and output-size K; a named “Sequence” module and truncation detail; statements about batch-size homogenization and masking; explicit LSTM cell/gates and vanishing-gradient mitigation; listing tasks like language modelling/speech/time‑series; and claims about increased computation and necessity of LSTM/attention), which reduces faithfulness and inflates content, while it also fails to state that RNN stands for Recurrent Neural Network even though the original does.",
      "summary_chars": 2877,
      "original_text_chars": 8445,
      "evaluation_time_seconds": 97.13379600000002
    },
    {
      "question_id": "sum_028",
      "query": "Skip Connection (Residual Module)",
      "score": 0.8333333333333334,
      "coverage_score": 0.9,
      "alignment_score": 0.8333333333333334,
      "success": true,
      "reason": "The score is 0.83 because the summary is largely faithful and contains no contradictions, but it adds specific details not present in the original (explicit ResNet layer counts 20/32/44/56/110; mentioning super-resolution as an application; claiming attention ‘reduces the bottleneck’ or directly ‘improves decoding’; and asserting skip connections improve accuracy across many tasks). It also fails to answer a question the original could (whether ResNet has ~214,000 citations). Overall accurate and useful, but slightly overconfident by introducing unsupported specifics.",
      "summary_chars": 2589,
      "original_text_chars": 9430,
      "evaluation_time_seconds": 81.258569
    },
    {
      "question_id": "sum_029",
      "query": "Convolutional Neural Networks (CNN) Introduction",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9583333333333334,
      "success": true,
      "reason": "The score is 0.90 because the summary is largely faithful and concise, with only a minor factual error—it incorrectly states the material does not explain how to use pretrained models when Lesson 4 explicitly covers that—and it omits a specific detail the original can answer (whether the example image has 3 RGB channels). Overall the summary remains accurate aside from that mistake and the missing detail.",
      "summary_chars": 3130,
      "original_text_chars": 9327,
      "evaluation_time_seconds": 94.53929100000002
    },
    {
      "question_id": "sum_030",
      "query": "Convolution Operation (Tích Chập)",
      "score": 0.6818181818181818,
      "coverage_score": 0.8,
      "alignment_score": 0.6818181818181818,
      "success": true,
      "reason": "The score is 0.68 because the summary preserves the core concepts (kernels, ReLU, skip connections, learned filters) but introduces several implementation details not stated in the original (describing convolution as a sliding-window multiply-add, claiming learning/updates occur via backpropagation, asserting ReLU’s derivative is 1 for positives, and that initial filters learn edges and deeper layers learn complex features). It also omits explicit confirmations the original could answer (that Softmax produces a probability distribution and that ReLU sets negatives to zero). No direct contradictions are present, so the summary is generally accurate but overstated in implementation specifics and incomplete on a few basic function behaviors.",
      "summary_chars": 2902,
      "original_text_chars": 9204,
      "evaluation_time_seconds": 101.24412799999999
    },
    {
      "question_id": "sum_031",
      "query": "Filter/Kernel in CNNs",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 0.8125,
      "success": true,
      "reason": "The score is 0.70 because the summary contains no direct contradictions but introduces several unverified or extra claims (it emphasizes that FC bias is stored separately while implying filter weights use the same parameter array, mentions a ‘build’ call not present in the original, and treats the ~100,000 parameter count ambiguously with respect to biases). It also omits details present in the original (use of sigmoid for some layers, FC sizes 120 and 84, and mentions of RNN/LSTM). These added ambiguities and omissions reduce fidelity but much of the core content remains correct, justifying a moderate score.",
      "summary_chars": 2112,
      "original_text_chars": 6675,
      "evaluation_time_seconds": 102.830565
    },
    {
      "question_id": "sum_032",
      "query": "Feature Maps (Tensor Output)",
      "score": 0.782608695652174,
      "coverage_score": 0.9,
      "alignment_score": 0.782608695652174,
      "success": true,
      "reason": "The score is 0.78 because the summary is mostly faithful (no direct contradictions) but introduces several specific claims not present in the original — e.g., a kernel/stride formula for spatial reduction, an explicit statement that atrous convolution \"increases receptive field without reducing spatial resolution,\" that residual connections transmit gradients/are the mechanism enabling very deep networks, that feature maps are the basis for classification/object detection/segmentation, and that deconvolution/dilated conv are used to \"recover or expand receptive fields\" and that skip connections definitively \"aid training\" — all of which the source did not state. It also omits an answerable detail the original contains (whether the example uses a 3‑channel RGB input). These unsupported additions and the omission reduce faithfulness, but the summary remains largely accurate, justifying the moderately high score.",
      "summary_chars": 3220,
      "original_text_chars": 9669,
      "evaluation_time_seconds": 101.471338
    },
    {
      "question_id": "sum_033",
      "query": "Pooling Layer (Max Pooling/Average Pooling)",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.8260869565217391,
      "success": true,
      "reason": "The score is 0.80 because the summary is largely faithful but contains important inaccuracies and omissions: it incorrectly attributes parameter-count and overfitting reduction to pooling rather than to weight-sharing in convolutional layers (contradiction), and it adds unmentioned claims about pooling being repeatedly applied across layers and about AveragePooling2D/stride defaults (extra information). It also omits stating that filters share weights to reduce parameters and that CNN inputs can be RGB or grayscale (points the original could answer but the summary left out).",
      "summary_chars": 2084,
      "original_text_chars": 8091,
      "evaluation_time_seconds": 92.504354
    },
    {
      "question_id": "sum_034",
      "query": "ReLU Activation Function",
      "score": 0.4,
      "coverage_score": 0.4,
      "alignment_score": 0.7142857142857143,
      "success": false,
      "reason": "The score is 0.40 because the summary omits and distorts key details from the original: it introduces unsupported claims (a video reference and a specific course exercise), overstates ReLU behavior at z=0, and inaccurately frames historical usage and training-speed reasons for sigmoid/tanh vs. ReLU. It also fails to preserve many concrete facts the original contained (CNN layer types, flattening before fully connected layers, pooling reducing spatial size, use of softmax for multiclass output, ADAM optimizer, and an example with 10 output classes), so fidelity and completeness are low.",
      "summary_chars": 1636,
      "original_text_chars": 8339,
      "evaluation_time_seconds": 95.982957
    },
    {
      "question_id": "sum_035",
      "query": "Sigmoid/Tanh Activation Functions",
      "score": 0.6,
      "coverage_score": 0.6,
      "alignment_score": 0.6666666666666666,
      "success": true,
      "reason": "The score is 0.60 because the summary captures core points (use of sigmoid/tanh, tanh range, activations applied elementwise) but weakens fidelity by adding unsupported details (claims tanh was used in the logistic-regression example, states sigmoid’s numeric range [0,1] and zero-centered rationale for tanh, and implies tanh was explicitly described as elementwise) and by omitting several specific, answerable details from the original (LeNet pooling, input feature dimensionality, number of output labels, and optimizer choice), making it partially accurate but incomplete.",
      "summary_chars": 1944,
      "original_text_chars": 8437,
      "evaluation_time_seconds": 100.61188
    },
    {
      "question_id": "sum_036",
      "query": "Fully Connected (Dense) Layer",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 0.70 because the summary is generally accurate and contains no contradictions or extraneous information, but it omits key implementation details present in the original: whether an RNN and LSTM are implemented, mention of Embedding and Dense layers, and the use of red and blue points in the logistic regression example—these omissions reduce completeness.",
      "summary_chars": 2720,
      "original_text_chars": 7959,
      "evaluation_time_seconds": 99.28224399999999
    },
    {
      "question_id": "sum_037",
      "query": "Weight Sharing in CNNs",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 0.80 because the summary is generally accurate (no contradictions or added facts) but omits specific verifiable technical details present in the original: it does not state whether a pooling layer (average pooling) is mentioned and whether the linear regression reported theta values matching 7.7 and 2.9, reducing completeness.",
      "summary_chars": 2316,
      "original_text_chars": 7836,
      "evaluation_time_seconds": 58.748861
    },
    {
      "question_id": "sum_038",
      "query": "Local Connectivity in CNNs",
      "score": 0.5,
      "coverage_score": 0.5,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 0.50 because the summary captures general topics but omits important implementation details and leaves several concrete questions unanswered: whether bias is stored in a separate array; whether fully‑connected layer parameters include bias; whether RNN/LSTM architectures are discussed; whether logistic regression uses a single output node with a sigmoid; and whether the linear regression implementation prints theta0 and theta1. There are no direct contradictions or extra invented facts, but these omissions reduce the summary's fidelity.",
      "summary_chars": 2528,
      "original_text_chars": 6768,
      "evaluation_time_seconds": 72.604321
    },
    {
      "question_id": "sum_039",
      "query": "Overfitting Mitigation",
      "score": 0.6666666666666666,
      "coverage_score": 1.0,
      "alignment_score": 0.6666666666666666,
      "success": true,
      "reason": "The score is 0.67 because the summary correctly highlights many core techniques (augmentation, architectural changes, skip connections, normalization, activations) but also introduces multiple unsupported or overgeneralized claims: it includes a document title not present in the original; asserts generated augmented variants ‘preserve labels’ (not stated); generalizes the activation-change recommendation beyond the original sigmoid→ReLU example to tanh; extrapolates a reported 50× TPU speedup to GPUs and to enabling more experiments; adds an unmentioned downside that excessive parameter reduction can harm representational power; claims the need for task-specific augmentation design (not stated); and states that residual connections/layer normalization add structural or computational overhead (not mentioned). Despite these extra assertions, the summary captures the main techniques, which justifies a moderate score.",
      "summary_chars": 3107,
      "original_text_chars": 8772,
      "evaluation_time_seconds": 114.31166899999998
    },
    {
      "question_id": "sum_040",
      "query": "Data Augmentation",
      "score": 0.25,
      "coverage_score": 0.4,
      "alignment_score": 0.25,
      "success": false,
      "reason": "The score is 0.25 because, while the summary makes no direct contradictions, it adds many unsupported inferences beyond the original (e.g., defining data augmentation as creating many labeled variants, asserting labels are preserved, claiming increased size/diversity and better generalization, stating multiple independent transformations per image, claiming augmentation avoids new labels, and linking augmentation explicitly to specific datasets or to simultaneous use with ReLU/TPU). It also fails to preserve several factual details the original did include or could answer (TPU speedup for AlexNet, ReLU reducing vanishing gradients, when to freeze vs fine-tune pretrained layers, logistic regression input dimensionality, and RNN parallelism limits), so the summary is incomplete and overconfident.",
      "summary_chars": 1474,
      "original_text_chars": 9303,
      "evaluation_time_seconds": 100.756206
    },
    {
      "question_id": "sum_041",
      "query": "ResNet Architecture",
      "score": 0.875,
      "coverage_score": 1.0,
      "alignment_score": 0.875,
      "success": true,
      "reason": "The score is 0.88 because the summary correctly captures ResNet’s main points (residual modules enable training deeper networks and usefulness as pretrained backbones) but introduces moderate inaccuracies: it overgeneralizes experimental results by implying deeper models (e.g., 20, 32, 44, 56, 110) uniformly achieved lower error when the original notes a 20-layer network had lower error than some deeper variants, and it asserts that residual modules consistently improve performance for “tens to hundreds” of layers (including very deep, hundreds-of-layers gains) without direct evidence in the original. These errors are significant but limited, so the summary is mostly faithful with some overclaims.",
      "summary_chars": 2475,
      "original_text_chars": 10527,
      "evaluation_time_seconds": 87.16528
    },
    {
      "question_id": "sum_042",
      "query": "MobileNet Architecture",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.8,
      "success": true,
      "reason": "The score is 0.80 because the summary correctly conveys core results (≈9× parameter/computation reduction, less overfitting, faster mobile computation) but adds unsupported inferences and omits some specific original facts. It incorrectly or prematurely attributes improved gradient flow/vanishing-gradient benefits to MobileNet (the original only discusses derivative increases and convolutional derivatives in a more general lecture context) and labels MobileNet as 'famous' despite the text only giving a citation count. The summary also fails to mention verifiable points the original does state (e.g., AlexNet’s replacement of sigmoid with ReLU and that pooling reduces computation/parameter count). These extra claims and omissions reduce fidelity, though most main findings remain accurate.",
      "summary_chars": 1630,
      "original_text_chars": 5543,
      "evaluation_time_seconds": 95.262102
    },
    {
      "question_id": "sum_043",
      "query": "Depthwise Separable Convolution",
      "score": 0.5,
      "coverage_score": 0.5,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 0.50 because the summary is broadly accurate (no contradictions or added information), but it omits several concrete technical details present in the original: it does not state that convolution is described as a linear transformation used to extract image features, that feature maps are flattened before being passed to fully connected layers, that the Softmax layer converts the final vector into a probability distribution with values in [0,1] that sum to one, that using ReLU helps reduce the vanishing gradient problem, or that setting padding='same' keeps input and output spatial sizes equal — these omissions materially reduce the summary's usefulness.",
      "summary_chars": 2422,
      "original_text_chars": 9375,
      "evaluation_time_seconds": 69.574842
    },
    {
      "question_id": "sum_044",
      "query": "CNN Visualization Techniques",
      "score": 0.47368421052631576,
      "coverage_score": 0.7,
      "alignment_score": 0.47368421052631576,
      "success": false,
      "reason": "The score is 0.47 because the summary adds many unsupported specifics that reduce faithfulness (e.g., it explicitly names ReLU though the original only said ‘activation’, asserts image-retrieval applications, claims early-layer filters are edge/color detectors and deeper layers represent abstract concepts, states visualization demonstrates scale invariance, and presents visualization as a debugging/transfer-evaluation tool and as improving face-recognition losses), while omitting a few concrete facts the original did state (that an input image can have depth 3/color channels, that pooling reduces feature/map size, and that the Softmax outputs probabilities summing to one). The summary still conveys the high-level purpose of visualizing CNN feature maps, but the extra unsupported claims justify the below‑average score.",
      "summary_chars": 2637,
      "original_text_chars": 9028,
      "evaluation_time_seconds": 106.09128500000001
    },
    {
      "question_id": "sum_045",
      "query": "Object Detection (YOLO/R-CNN)",
      "score": 0.88,
      "coverage_score": 1.0,
      "alignment_score": 0.88,
      "success": true,
      "reason": "The score is 0.88 because the summary is largely faithful with no contradictions but includes extra, specific technical details not stated in the original (explicit two-stage internals like RPN + classifier/bbox regression, per-grid-cell outputs such as confidence and class distributions, and an expanded applications list including tracking). These are plausible extensions rather than outright errors, so the summary is accurate overall but slightly over-informative.",
      "summary_chars": 2818,
      "original_text_chars": 9027,
      "evaluation_time_seconds": 95.148528
    },
    {
      "question_id": "sum_046",
      "query": "Semantic Segmentation (U-Net)",
      "score": 0.68,
      "coverage_score": 0.8,
      "alignment_score": 0.68,
      "success": true,
      "reason": "The score is 0.68 because the summary largely reflects the original but introduces several unsupported additions and omits some directly answerable points. Extra claims include ‘face segmentation’, that the encoder specifically uses convolution+pooling to reduce resolution and the decoder explicitly up-samples back to original resolution, concrete examples like faces/types of vehicles for segmentation, a specific definition of instance segmentation as distinguishing multiple same‑class objects at the pixel level, assertions that semantic/instance segmentation are necessarily more complex or accurate, the suggestion that U‑Net is typically used instead of raw feature‑map thresholding, and that U‑Net variants are currently a popular choice — none of which the original text explicitly stated. The summary also fails to state two facts the original did: that CNNs are used for classification tasks such as face recognition and that Word2Vec represents each word as a vector corresponding to a row in matrix W. There are no direct contradictions.",
      "summary_chars": 2785,
      "original_text_chars": 7471,
      "evaluation_time_seconds": 98.715788
    },
    {
      "question_id": "sum_047",
      "query": "Gradient Descent Optimization",
      "score": 0.7368421052631579,
      "coverage_score": 0.8,
      "alignment_score": 0.7368421052631579,
      "success": true,
      "reason": "The score is 0.74 because the summary is largely faithful but has a notable contradiction and several unsupported additions. It incorrectly states GD updates θ to “decrease the gradient” instead of using the negative gradient to decrease the loss. It also introduces extra claims not in the original (calling GD ‘effective/popular’; asserting concrete failure modes for too-large/too-small learning rates; naming and even giving the cross-entropy formula and recommending it for logistic regression; and overstating links between initialization/loss choice and particular failure modes). Finally, the summary omits answers to two specific points the original can address: that θ in networks are the weights and whether L1 has a larger slope (hence larger derivative) than L2. These issues explain a moderately high but imperfect score.",
      "summary_chars": 2536,
      "original_text_chars": 9307,
      "evaluation_time_seconds": 91.89219699999998
    },
    {
      "question_id": "sum_048",
      "query": "Adam Optimizer",
      "score": 0.6,
      "coverage_score": 0.6,
      "alignment_score": 0.7142857142857143,
      "success": true,
      "reason": "The score is 0.60 because the summary is largely consistent with the source (no direct contradictions) but adds several unsupported details about Adam—claiming it averages gradients, uses per-parameter learning-rate adjustments/dynamic learning rates, is generally faster, and helps escape poor minima—which the original text did not state. The summary also omitted concrete implementation details the source did provide (answers about output neurons=10 for 10 classes, using sigmoid for binary classification, packaging model into cell.model, and retrieving a layer's weights via get weight), reducing fidelity.",
      "summary_chars": 1774,
      "original_text_chars": 8589,
      "evaluation_time_seconds": 107.203255
    },
    {
      "question_id": "sum_049",
      "query": "Binary Cross Entropy Loss",
      "score": 0.4,
      "coverage_score": 0.4,
      "alignment_score": 0.7894736842105263,
      "success": false,
      "reason": "The score is 0.40 because the summary introduces unsupported claims (e.g., that BCE updates faster than MSE and that a 0.9 momentum recommendation applies to SGD) which are not stated in the original, while omitting several factual details the original does provide (optimizer was Adam; embedding length 300; dictionary size ≈900k; ANN hidden size 64; the RNN/LSTM example was fit for 3 epochs; reported loss ≈0.7 and accuracy ≈51–52%). There are no direct contradictions and the summary is generally coherent, but the added/unverified assertions and missing concrete facts justify the low score.",
      "summary_chars": 2064,
      "original_text_chars": 7740,
      "evaluation_time_seconds": 100.764027
    },
    {
      "question_id": "sum_050",
      "query": "Categorical Cross Entropy Loss",
      "score": 0.6,
      "coverage_score": 0.6,
      "alignment_score": 0.6190476190476191,
      "success": true,
      "reason": "The score is 0.60 because the summary adds several specific technical claims that are not present in the original (e.g., giving the negative-log form -Σ y·log p, defining p_{n,i} as softmax probabilities, asserting softmax outputs sum to 1, and noting numerically-stable combined softmax+CCE implementations), which reduces fidelity. The summary also fails to report concrete example details the original does provide (momentum=0.9, RNN/LSTM hidden size=64, a sigmoid single-output for binary classification, and explicit calls to cell.model.fit), so it omits verifiable details. There are no direct contradictions between the texts, but the extra unsupported specifics and omitted example parameters justify a moderate score.",
      "summary_chars": 2158,
      "original_text_chars": 7394,
      "evaluation_time_seconds": 79.08929
    }
  ]
}