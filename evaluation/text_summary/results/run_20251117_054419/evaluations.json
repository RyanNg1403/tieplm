{
  "run_info": {
    "run_id": "run_20251117_054419",
    "timestamp": "20251117_054419",
    "total_questions": 29,
    "successful_evaluations": 29,
    "failed_evaluations": 0,
    "evaluation_model": "gpt-5-mini",
    "threshold": 0.5,
    "n_questions": 10
  },
  "statistics": {
    "overall": {
      "mean": 0.7455216977845796,
      "min": 0.5,
      "max": 1.0,
      "median": 0.7894736842105263,
      "std": 0.143276652244126
    },
    "coverage": {
      "mean": 0.8413793103448277,
      "min": 0.5,
      "max": 1.0
    },
    "alignment": {
      "mean": 0.8030985334648635,
      "min": 0.5,
      "max": 1.0
    }
  },
  "scores": [
    {
      "question_id": "sum_001",
      "query": "Transformer Architecture",
      "score": 0.7619047619047619,
      "coverage_score": 0.9,
      "alignment_score": 0.7619047619047619,
      "success": true,
      "reason": "The score is 0.76 because the summary is largely faithful (no direct contradictions) but adds several unsupported claims and overstatements—e.g., that Transformers were developed specifically to replace RNNs and to primarily reduce vanishing gradients, that increasing layers necessarily demands many more parameters/resources, and explicit functional claims about residual connections and model roles (BERT encoder‑only, GPT decoder‑only) not stated in the original. It also omits a concrete, answerable detail from the original (whether residual connections add the layer input to its output). These extra assertions and the omission reduce precision, so the summary is good but not fully accurate or complete.",
      "summary_chars": 2753,
      "original_text_chars": 8293,
      "evaluation_time_seconds": 94.333642
    },
    {
      "question_id": "sum_002",
      "query": "Attention Mechanism",
      "score": 0.7727272727272727,
      "coverage_score": 0.9,
      "alignment_score": 0.7727272727272727,
      "success": true,
      "reason": "The score is 0.77 because the summary accurately captures core attention mechanics (dot‑product scores, normalization, weighted sum, cross/self‑attention, alleviating encoder–decoder bottleneck, role in Transformers) but introduces several unsupported claims (that the context vector is combined with h_t to form outputs; that attention explicitly ‘supports long‑range dependency learning’ by weighting; that self‑attention is inherently ‘efficient for whole‑sequence processing’; and broad claims about attention’s use across many tasks). The summary also omits some source details (e.g., mention of ANN variants such as LSTM and bidirectional networks). There are no direct contradictions, but these extra/unwarranted generalizations and omissions reduce faithfulness, justifying a moderately high but not perfect score.",
      "summary_chars": 3487,
      "original_text_chars": 8156,
      "evaluation_time_seconds": 95.23238699999999
    },
    {
      "question_id": "sum_003",
      "query": "Self-Attention",
      "score": 0.7894736842105263,
      "coverage_score": 1.0,
      "alignment_score": 0.7894736842105263,
      "success": true,
      "reason": "The score is 0.79 because the summary preserves the core ideas (self-attention computed in parallel within a layer, layers are sequential, and multi-head self-attention is used) and contains no major factual contradictions, but it includes several unsupported additions that lower fidelity—claiming the summary is “concise/comprehensive,” implying queries/keys/values are explicitly taken from the previous layer, asserting multi-heads split representations to learn different interactions, and invoking RNN comparisons—all details not stated in the original. Overall accurate but slightly over-assertive, hence a high but not perfect score.",
      "summary_chars": 2915,
      "original_text_chars": 7832,
      "evaluation_time_seconds": 103.68709600000001
    },
    {
      "question_id": "sum_004",
      "query": "Multi-Head Self-Attention",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9090909090909091,
      "success": true,
      "reason": "The score is 0.90 because the summary largely matches the original and is accurate overall (good fidelity), but contains minor unsupported additions — it frames fixed sinusoidal positional encodings as a weakness and asserts specific applications (machine translation/generation) that the original did not state — and it omits an explicit confirmation of whether the decoder output still uses token and positional embeddings, leaving that question unanswered by the summary.",
      "summary_chars": 2719,
      "original_text_chars": 8822,
      "evaluation_time_seconds": 104.214018
    },
    {
      "question_id": "sum_005",
      "query": "Query, Key, and Value (QKV) Vectors",
      "score": 0.8260869565217391,
      "coverage_score": 1.0,
      "alignment_score": 0.8260869565217391,
      "success": true,
      "reason": "The score is 0.83 because the summary correctly conveys the main ideas (no direct contradictions) but includes several details not supported by the original—asserting per-head W_Q/W_K/W_V matrices, explicitly stating heads’ outputs are concatenated then projected, adding evaluative language about attention being ‘flexible and powerful,’ and claiming many heads increase parameter count—so faithfulness is good but diluted by those unsupported additions.",
      "summary_chars": 2434,
      "original_text_chars": 8277,
      "evaluation_time_seconds": 110.819975
    },
    {
      "question_id": "sum_006",
      "query": "Attention Score Calculation",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9,
      "success": true,
      "reason": "The score is 0.90 because the summary correctly reflects the original’s equations, masking, and that multi‑head attention enables parallelization and GPU efficiency (no contradictions), but it adds an unsupported inference—that Q/K/V are split into multiple heads specifically to learn diverse similarity patterns—which the original did not explicitly state. The summary also omits an example the original gives (whether the word 'sua' can have the largest influence on the next prediction). These minor unsupported claims and the missed example slightly lower fidelity, though overall the summary is accurate and concise.",
      "summary_chars": 2528,
      "original_text_chars": 9017,
      "evaluation_time_seconds": 74.069011
    },
    {
      "question_id": "sum_007",
      "query": "Attention Distribution (Softmax)",
      "score": 1.0,
      "coverage_score": 1.0,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 1.00 because the summary perfectly reflects the original text: it contains no contradictions or added details and accurately and concisely conveys the original content.",
      "summary_chars": 2550,
      "original_text_chars": 8480,
      "evaluation_time_seconds": 89.582629
    },
    {
      "question_id": "sum_008",
      "query": "Attention Output/Context Vector",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9545454545454546,
      "success": true,
      "reason": "The score is 0.90 because the summary is largely faithful and concise, preserving the original's main points, but it introduced an extra unsupported claim that attention \"improves\" translation/long-range dependency handling (not stated in the original) and omitted mention that the work used bidirectional encoding (left-to-right and right-to-left) and an LSTM cell—small omissions, hence a high but not perfect score.",
      "summary_chars": 2036,
      "original_text_chars": 8523,
      "evaluation_time_seconds": 110.504319
    },
    {
      "question_id": "sum_009",
      "query": "Cross-Attention (Encoder-Decoder Attention)",
      "score": 0.5789473684210527,
      "coverage_score": 0.8,
      "alignment_score": 0.5789473684210527,
      "success": true,
      "reason": "The score is 0.58 because the summary adds several unsupported claims (e.g., that cross‑attention is implemented as multi‑head, a specific decoder block ordering including the final linear/output embedding, whether cross‑attention is masked, that attention reduces overfitting, that cross‑attention specifically enables parallelization, and that cross‑attention is ‘mandatory’ or that disadvantages were omitted) which are not in the source, while also failing to confirm source facts the original does provide (notably whether positional embeddings were mentioned and whether self‑attention enables parallel/parallelized computation), reducing fidelity and completeness.",
      "summary_chars": 2762,
      "original_text_chars": 8654,
      "evaluation_time_seconds": 130.284826
    },
    {
      "question_id": "sum_010",
      "query": "Masked Multi-Head Self-Attention",
      "score": 0.8181818181818182,
      "coverage_score": 1.0,
      "alignment_score": 0.8181818181818182,
      "success": true,
      "reason": "The score is 0.82 because the summary accurately captures most of the model structure and contains no direct contradictions with the original, but it introduces several unsupported specifics: it claims the final linear matrix is d×d, it asserts an explicit 'Add & Norm → cross‑attention → Add & Norm' sequencing, it states that projections necessarily increase parameter and compute cost, and it labels masked MHA as the definitive main component and always preceding cross‑attention. These added assumptions reduce strict faithfulness, so the summary is largely good but not fully supported by the original.",
      "summary_chars": 2793,
      "original_text_chars": 8771,
      "evaluation_time_seconds": 193.772764
    },
    {
      "question_id": "sum_011",
      "query": "Transformer Encoder Architecture",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9047619047619048,
      "success": true,
      "reason": "The score is 0.90 because the summary is largely faithful and concise, capturing the core model flow (input embedding → self‑attention → stacked encoder layers) and the computational cost, with no contradictions; however it adds two unsupported specifics—presenting 'addition, normalization, feed‑forward' as the enumerated main flow steps and claiming stacking/dimensional increases ‘require many parameters’ (the original only noted stacking and higher compute/memory O(T^2), not parameter counts)—and it omits that BERT and GPT are trained self‑supervised without labeled data. Overall the summary is clear and mostly accurate.",
      "summary_chars": 3058,
      "original_text_chars": 8990,
      "evaluation_time_seconds": 91.78499800000002
    },
    {
      "question_id": "sum_012",
      "query": "Transformer Decoder Architecture",
      "score": 0.5,
      "coverage_score": 0.5,
      "alignment_score": 0.85,
      "success": true,
      "reason": "The score is 0.50 because the summary contains several unsupported additions (it claims the decoder uses both encoder-and self-attention results, calls a Decoder Transformer “easy to integrate” into generative models, and labels the document a “concise, comprehensive summary” and CS431) while omitting multiple details the original did provide (whether the encoder’s first module is named “shareattention,” BERT’s full name, that BERT and GPT are Transformer-based and self-supervised, and that pre-Transformer NLP used RNNs/LSTMs). There are no direct contradictions, which is a positive.",
      "summary_chars": 2675,
      "original_text_chars": 8327,
      "evaluation_time_seconds": 96.755289
    },
    {
      "question_id": "sum_013",
      "query": "Positional Encoding/Embedding",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 0.76,
      "success": true,
      "reason": "The score is 0.70 because the summary correctly captures the high-level idea (sinusoidal positional encodings and self-attention) and contains no contradictions, but it adds several specifics not present in the original (explicit even/odd formulas P_{2i}(y)=sin(y/10000^{2i/D}) and P_{2i+1}(y)=cos(...), the exact D/2 sin–cos pairing, explicit claims that the method is ‘simple’ and parameter-free, mentions replacing sinusoid with other functions, and implies effects on overall computational cost). It also fails to answer some architecture questions the original could address (whether the decoder has feedforward+add-norm; whether multihead attention is applied multiple times to capture different relations; whether a linear layer projects features to output labels). Overall the summary is faithful at a high level but over-specific and omits some practical details, justifying a moderate score.",
      "summary_chars": 2814,
      "original_text_chars": 8908,
      "evaluation_time_seconds": 231.23615999999998
    },
    {
      "question_id": "sum_014",
      "query": "Feed-Forward Networks in Transformer",
      "score": 0.5,
      "coverage_score": 0.5,
      "alignment_score": 0.75,
      "success": true,
      "reason": "The score is 0.50 because the summary contains several unsupported additions (e.g., asserting FFNs appear in both encoder and decoder, claiming a specific Attention → Add & Norm → FFN → Add & Norm ordering, and noting the absence of a document title) that the original does not state, while also omitting multiple answerable details (decoder embeddings and positional embeddings, presence of multi‑head and cross attention, use of scaled dot‑product + softmax, concatenation of head outputs, and sinusoidal positional encoding). There are no direct contradictions, but the extra ungrounded claims and missing details reduce the summary’s fidelity and completeness.",
      "summary_chars": 2144,
      "original_text_chars": 7591,
      "evaluation_time_seconds": 195.761234
    },
    {
      "question_id": "sum_015",
      "query": "BERT Model Architecture",
      "score": 0.5,
      "coverage_score": 0.5,
      "alignment_score": 0.8181818181818182,
      "success": true,
      "reason": "The score is 0.50 because the summary adds several evaluative/scope claims about BERT (e.g., calling the document a “brief and comprehensive summary,” asserting bidirectionality directly yields “strong and effective” representations, framing the masked‑LM objective as not optimizing downstream tasks, and saying fine‑tuning is “easy”) that are not stated in the original, while also omitting concrete factual details the original contains (that BERT/GPT are self‑supervised, that the CNN example uses softmax for multi‑class classification, the Word2Vec embedding matrix size ≈1M×300, the CNN has 10 output classes, and use of the ADAM optimizer); it does not, however, introduce direct contradictions with the source.",
      "summary_chars": 2209,
      "original_text_chars": 8419,
      "evaluation_time_seconds": 89.39317299999999
    },
    {
      "question_id": "sum_016",
      "query": "GPT Model Architecture",
      "score": 0.88,
      "coverage_score": 1.0,
      "alignment_score": 0.88,
      "success": true,
      "reason": "The score is 0.88 because the summary is largely accurate and contains no contradictions, but it adds unsupported details—claiming there are “2 ways” to exploit foundation models and implying a second approach that the original does not describe, and introducing computational-cost as a disadvantage of start/end tokens and sequential decoding that the original did not mention—warranting a small penalty.",
      "summary_chars": 2587,
      "original_text_chars": 8354,
      "evaluation_time_seconds": 91.795281
    },
    {
      "question_id": "sum_017",
      "query": "Vanishing Gradient Problem",
      "score": 0.85,
      "coverage_score": 1.0,
      "alignment_score": 0.85,
      "success": true,
      "reason": "The score is 0.85 because the summary is largely faithful with no direct contradictions, but it introduces three unsupported extrapolations: that skip connections are applied to stacked RNNs, that Transformers were explicitly designed to avoid transmitting gradients sequentially through many timesteps, and that fully remedying vanishing gradients requires combining many techniques. These plausible but unverified claims reduce fidelity slightly.",
      "summary_chars": 3025,
      "original_text_chars": 8379,
      "evaluation_time_seconds": 78.475639
    },
    {
      "question_id": "sum_018",
      "query": "Computational Cost of Self-Attention",
      "score": 0.7692307692307693,
      "coverage_score": 0.8,
      "alignment_score": 0.7692307692307693,
      "success": true,
      "reason": "The score is 0.77 because the summary correctly conveys the core strengths and weaknesses of self-attention (parallelizability, GPU efficiency, computational cost, and positional representation issues) but introduces several unsupported or speculative claims and omits some supported points. Specifically, it adds unverified statements about whether masking still allows full parallel execution in the decoder, whether multi-head attention changes the O(T^2) scaling, and that self-attention is unsuitable for very long sequences unless optimizations are applied—none of which the original text asserted. It also fails to mention original-supported details about the importance of relative positional information and that Shaw et al. (2018) showed modeling relative position can improve accuracy. These extra/unverified assertions and omissions lower fidelity, yielding a high-but-not-perfect score.",
      "summary_chars": 1622,
      "original_text_chars": 8734,
      "evaluation_time_seconds": 68.18831
    },
    {
      "question_id": "sum_019",
      "query": "Recurrent Neural Networks (RNN) Architecture",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.85,
      "success": true,
      "reason": "The score is 0.80 because the summary is mostly faithful—covering RNN topics, NMT/encoder–decoder structure and sequence data—yet it adds three unsupported claims (calling the document a ‘short/comprehensive’ summary, and listing language modeling and time‑series as applications not stated in the original) and omits details the original did provide (that classical models like linear regression are presented as simpler building blocks and that MT examples include conversions such as English↔French). These extra assertions and omissions lower accuracy but do not fatally undermine the summary.",
      "summary_chars": 2371,
      "original_text_chars": 8807,
      "evaluation_time_seconds": 92.638043
    },
    {
      "question_id": "sum_020",
      "query": "Long Short-Term Memory (LSTM) Architecture",
      "score": 0.65,
      "coverage_score": 1.0,
      "alignment_score": 0.65,
      "success": true,
      "reason": "The score is 0.65 because the summary generally aligns with the source (no direct contradictions) but includes several unsupported additions and inferences not present in the original: precise dates for LSTM/Transformer, explicit claims that LSTM was designed to fix vanishing gradients/long‑term dependencies and that it empirically handles longer dependencies better, that stacking LSTM layers is specifically to increase sequence representation, and that Transformers replaced many LSTM roles because of pure attention. These extra, unstated assertions reduce faithfulness even though the core points match, so the summary is useful but not fully faithful.",
      "summary_chars": 2464,
      "original_text_chars": 8080,
      "evaluation_time_seconds": 85.085799
    },
    {
      "question_id": "sum_021",
      "query": "LSTM Gates (Forget, Input, Output)",
      "score": 0.6086956521739131,
      "coverage_score": 0.8,
      "alignment_score": 0.6086956521739131,
      "success": true,
      "reason": "The score is 0.61 because the summary captures core facts from the original (that LSTMs have Forget, Input, and Output gates and mentions sigmoid/vanishing-gradient context) but adds several specifics not present in the source (e.g., judging the summary as “short and comprehensive,” claiming gates ‘‘usually’’ use sigmoid to produce 0..1 coefficients, detailed read/write/selective-update mechanics for the Input Gate, and explicit output-control wording for the Output Gate, plus claims about gates maintaining gradients). The summary also omits some concrete points the original did answer (whether Attention output is used to compute decoder outputs and that RNN/LSTM outputs are sequences). Those extra/unjustified details and the omissions lower fidelity, producing a moderate score.",
      "summary_chars": 2815,
      "original_text_chars": 8832,
      "evaluation_time_seconds": 105.56453000000002
    },
    {
      "question_id": "sum_022",
      "query": "Context Cell/State in LSTM",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 0.9629629629629629,
      "success": true,
      "reason": "The score is 0.80 because the summary is largely faithful and contains no contradictions (good), but it introduces an unsupported explicit claim that the context cell is the ‘main path’ for gradients across many time steps—information not present in the original—and it omits answerable details about whether LSTM cells are processed sequentially like ANN cells and whether the text mentions bidirectional encoding; these additions and omissions reduce fidelity though they do not severely distort the original.",
      "summary_chars": 3219,
      "original_text_chars": 8425,
      "evaluation_time_seconds": 86.051365
    },
    {
      "question_id": "sum_023",
      "query": "Bidirectional RNN (BiRNN)",
      "score": 0.5,
      "coverage_score": 0.8,
      "alignment_score": 0.5,
      "success": true,
      "reason": "The score is 0.50 because the summary mixes some accurate points (correctly describing bidirectional reading and that BiRNNs aren’t suitable for next-token prediction) with many unsupported additions and overstatements not present in the original (e.g., specific implementation claims like two independent RNNs, concatenation of directional hidden states, explicit naming such as ‘BiLSTM’ or ‘BiRNN + attention’, that BiRNN+LSTM was commonly used to fix vanishing gradients, decoder unidirectionality, increased computational cost, and extra listed applications like NER). It also fails to include some facts the original did state (e.g., explicit machine-translation language examples and that attention will be discussed). Those extra, unstated claims harm faithfulness and completeness, producing a middling score.",
      "summary_chars": 3137,
      "original_text_chars": 8711,
      "evaluation_time_seconds": 205.293885
    },
    {
      "question_id": "sum_024",
      "query": "Deep Stacked/Multi-layer RNN",
      "score": 0.8,
      "coverage_score": 0.8,
      "alignment_score": 1.0,
      "success": true,
      "reason": "The score is 0.80 because the summary is generally accurate, concise, and faithful to the original with no contradictions or added claims; however it omits two factual points present in the source — that RNNs were widely used in early NLP and that machine translation and attention mechanisms will be studied — which reduces completeness.",
      "summary_chars": 2805,
      "original_text_chars": 8005,
      "evaluation_time_seconds": 108.991659
    },
    {
      "question_id": "sum_025",
      "query": "Sequence-to-Sequence (Seq2Seq) Model",
      "score": 0.7,
      "coverage_score": 0.7,
      "alignment_score": 0.8518518518518519,
      "success": true,
      "reason": "The score is 0.70 because the summary correctly conveys core Seq2Seq ideas but adds unsupported specifics (claims it is a “short, complete summary” of Seq2Seq; asserts the encoder’s final hidden state is passed as the decoder initial state; states each generated token/embedding is fed back as the next input; and even gives a specific decoded token sequence 'NE → SUI → PA → N(end)' not found in the source), while also omitting answerable details that the original includes (softmax for multi-class, Adam optimizer, ResNet50 as a pretrained extractor), so fidelity and completeness are only moderate.",
      "summary_chars": 3242,
      "original_text_chars": 8743,
      "evaluation_time_seconds": 84.78111100000001
    },
    {
      "question_id": "sum_026",
      "query": "Encoder-Decoder Architecture",
      "score": 0.5625,
      "coverage_score": 0.8,
      "alignment_score": 0.5625,
      "success": true,
      "reason": "The score is 0.56 because the summary mixes partly accurate points with several extra or overstated claims not present in the source (e.g., labeling self‑attention and the decoder as explicitly “central”; asserting the cross‑attention rule that queries come from the decoder and keys/values from the encoder as if directly stated; equating K/Q/V to static metadata rather than internal representations; presenting ‘‘advantages’’ as a listed claim; and rephrasing the search example in ways the source does not). The summary does correct a key/query confusion but still omits a clear procedural description of cross‑attention and fails to mention some specific source details that were present (references to CS431 - Chương 10 videos and multiple occurrences of the word “video”). These added, sometimes misleading details plus those omissions lower fidelity despite some correct material, justifying a middling score.",
      "summary_chars": 2385,
      "original_text_chars": 2284,
      "evaluation_time_seconds": 101.015952
    },
    {
      "question_id": "sum_027",
      "query": "RNN Handling of Variable Length Sequences",
      "score": 0.6190476190476191,
      "coverage_score": 0.9,
      "alignment_score": 0.6190476190476191,
      "success": true,
      "reason": "The score is 0.62 because the summary adds many unsupported details and omits at least one simple point the original does provide: it introduces specifics not in the source (per-step outputs ŷ_t, per-step loss L_t and output-size K; a named “Sequence” module and truncation detail; statements about batch-size homogenization and masking; explicit LSTM cell/gates and vanishing-gradient mitigation; listing tasks like language modelling/speech/time‑series; and claims about increased computation and necessity of LSTM/attention), which reduces faithfulness and inflates content, while it also fails to state that RNN stands for Recurrent Neural Network even though the original does.",
      "summary_chars": 2877,
      "original_text_chars": 8445,
      "evaluation_time_seconds": 97.13379600000002
    },
    {
      "question_id": "sum_028",
      "query": "Skip Connection (Residual Module)",
      "score": 0.8333333333333334,
      "coverage_score": 0.9,
      "alignment_score": 0.8333333333333334,
      "success": true,
      "reason": "The score is 0.83 because the summary is largely faithful and contains no contradictions, but it adds specific details not present in the original (explicit ResNet layer counts 20/32/44/56/110; mentioning super-resolution as an application; claiming attention ‘reduces the bottleneck’ or directly ‘improves decoding’; and asserting skip connections improve accuracy across many tasks). It also fails to answer a question the original could (whether ResNet has ~214,000 citations). Overall accurate and useful, but slightly overconfident by introducing unsupported specifics.",
      "summary_chars": 2589,
      "original_text_chars": 9430,
      "evaluation_time_seconds": 81.258569
    },
    {
      "question_id": "sum_029",
      "query": "Convolutional Neural Networks (CNN) Introduction",
      "score": 0.9,
      "coverage_score": 0.9,
      "alignment_score": 0.9583333333333334,
      "success": true,
      "reason": "The score is 0.90 because the summary is largely faithful and concise, with only a minor factual error—it incorrectly states the material does not explain how to use pretrained models when Lesson 4 explicitly covers that—and it omits a specific detail the original can answer (whether the example image has 3 RGB channels). Overall the summary remains accurate aside from that mistake and the missing detail.",
      "summary_chars": 3130,
      "original_text_chars": 9327,
      "evaluation_time_seconds": 94.53929100000002
    }
  ]
}