[
  {
    "chapter": "8",
    "question": "Quá trình lan truyền tuần tự trong Seq2Seq gây ra vấn đề gì đối với thông tin của những từ đầu tiên?",
    "options": "a) Thông tin được củng cố; b) Thông tin bị loãng/mất sau nhiều lần biến đổi; c) Thông tin bị lặp lại; d) Thông tin bị mã hóa nhị phân",
    "answer": "b) Thông tin bị loãng/mất sau nhiều lần biến đổi",
    "video_urls": ["https://youtu.be/ROIgZ5tyDFo"],
    "timestamps": ["00:00:00 - 00:10:00"]
  },
  {
    "chapter": "8",
    "question": "Mục tiêu của việc tính Attention Score là gì?",
    "options": "a) Tạo ra một vector input mới; b) Tính toán xem tại thời điểm decode, mô hình nên \"để tâm\" đến từ nào trong câu nguồn; c) Ánh xạ Query và Value về cùng không gian; d) Giảm số chiều của Value",
    "answer": "b) Tính toán xem tại thời điểm decode, mô hình nên \"để tâm\" đến từ nào trong câu nguồn",
    "video_urls": ["https://youtu.be/ROIgZ5tyDFo"],
    "timestamps": ["00:00:00 - 00:10:00"]
  },
  {
    "chapter": "8",
    "question": "Hàm nào được sử dụng để chuẩn hóa Attention Score (R) về không gian xác suất (Attention Distribution α)?",
    "options": "a) ReLU; b) Sigmoid; c) Tanh; d) Softmax",
    "answer": "d) Softmax",
    "video_urls": ["https://youtu.be/S8__bXkLSbM"],
    "timestamps": ["00:00:00 - 00:10:00"]
  },
  {
    "chapter": "8",
    "question": "Cơ chế Attention giải quyết vấn đề Vanishing Gradient bằng cách tạo ra các đường tắt (skip connections) tương tự như kiến trúc mạng CNN nào?",
    "options": "a) LeNet; b) AlexNet; c) ResNet; d) VGGNet",
    "answer": "c) ResNet",
    "video_urls": ["https://youtu.be/S8__bXkLSbM"],
    "timestamps": ["00:00:00 - 00:10:00"]
  },
  {
    "chapter": "8",
    "question": "Trong cơ chế Attention, trạng thái ẩn của Encoder (Si​) được gọi chung là gì?",
    "options": "a) Query (Q); b) Key (K); c) Value (V); d) Context (C)",
    "answer": "c) Value (V)",
    "video_urls": ["https://youtu.be/my3qRjVJ7VM"],
    "timestamps": ["00:00:00 - 00:10:00"]
  },
  {
    "chapter": "8",
    "question": "Vai trò của Encoder trong kiến trúc Seq2Seq là gì?",
    "options": null,
    "answer": "Đọc và hiểu thông tin input đầu vào",
    "video_urls": ["https://youtu.be/4EdX3Ga9YoM"],
    "timestamps": ["00:00:00 - 00:10:00"]
  },
  {
    "chapter": "8",
    "question": "Trong kiến trúc Seq2Seq, Decoder đóng vai trò giống như loại mô hình nào khi tạo ra câu văn đích?",
    "options": null,
    "answer": "Mô hình ngôn ngữ (Language Model)",
    "video_urls": ["https://youtu.be/4EdX3Ga9YoM"],
    "timestamps": ["00:00:00 - 00:10:00"]
  },
  {
    "chapter": "8",
    "question": "Kể tên một bài toán (ngoài dịch máy) có thể được giải quyết bằng mô hình Seq2Seq vì có Input và Output đều là dạng chuỗi.",
    "options": null,
    "answer": "Tóm tắt văn bản (Summarization) HOẶC Hội thoại (Chatbot/Dialog) HOẶC Tạo mã nguồn (Code Generation)",
    "video_urls": ["https://youtu.be/4EdX3Ga9YoM"],
    "timestamps": ["00:00:00 - 00:10:00"]
  },
  {
    "chapter": "8",
    "question": "Khi huấn luyện NMT, thuật toán nào được thực hiện để cập nhật các ma trận trọng số (U, V, W) dựa trên hàm Loss tổng hợp?",
    "options": null,
    "answer": "Thuật toán lan truyền ngược (Backpropagation)",
    "video_urls": ["https://youtu.be/--JpgsDEL40"],
    "timestamps": ["00:00:00 - 00:10:00"]
  },
  {
    "chapter": "8",
    "question": "Độ đo nào được sử dụng phổ biến hiện nay để đánh giá độ chính xác của mô hình dịch máy?",
    "options": null,
    "answer": "BLEU (Bilingual Evaluation Understudy)",
    "video_urls": ["https://youtu.be/--JpgsDEL40"],
    "timestamps": ["00:00:00 - 00:10:00"]
  },
  {
    "chapter": "8",
    "question": "Cơ chế Attention giải quyết được vấn đề nào của Seq2Seq truyền thống, liên quan đến việc dồn nén thông tin?",
    "options": null,
    "answer": "Vấn đề điểm nghẽn (Bottleneck) thông tin",
    "video_urls": ["https://youtu.be/ROIgZ5tyDFo"],
    "timestamps": ["00:00:00 - 00:10:00"]
  }
]
