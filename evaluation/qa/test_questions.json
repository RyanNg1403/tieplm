[
    {
        "Chương":2,
        "Nội dung câu hỏi":"Máy học (Machine Learning) có phải là một lĩnh vực con của Trí tuệ Nhân tạo không?",
        "Phương án (nếu có)":null,
        "Đáp án":"Yes",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Học có giám sát (Supervised Learning) học từ dữ liệu không được gán nhãn phải không?",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Học không giám sát (Unsupervised Learning) liên quan đến việc tìm kiếm các mẫu (patterns) trong dữ liệu đã được gán nhãn phải không?",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Học tăng cường (Reinforcement Learning) có liên quan đến một tác nhân (agent) học cách tương tác với môi trường không?",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Hồi quy (Regression) có phải là một tác vụ chính của Học có giám sát không?",
        "Phương án (nếu có)":null,
        "Đáp án":"Yes",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Phân loại (Classification) có phải là một tác vụ chính của Học không giám sát không?",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Học sâu (Deep Learning) có được định nghĩa là sử dụng mạng nơ-ron với nhiều lớp ẩn (hidden layers) không?",
        "Phương án (nếu có)":null,
        "Đáp án":"Yes",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Học máy (Machine Learning) có giống hệt như \"các chương trình thủ tục truyền thống\" không",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Mục tiêu của tác nhân trong Học tăng cường là để tối đa hóa \"phần thưởng\" (reward) phải không?",
        "Phương án (nếu có)":null,
        "Đáp án":"Yes",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Dữ liệu cho Học không giám sát (Unsupervised Learning) bắt buộc phải được gán nhãn trước khi học phải không?",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Học máy (Machine Learning) được định nghĩa là gì?",
        "Phương án (nếu có)":"A. Một lĩnh vực con của trí tuệ nhân tạo \nB. Một loại chương trình thủ tục truyền thống \nC. Chỉ bao gồm Học tăng cường \nD. Tên gọi khác của Mạng nơ-ron",
        "Đáp án":"A",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Loại hình học máy nào học từ \"dữ liệu đã được gán nhãn\"?",
        "Phương án (nếu có)":"A. Học không giám sát \nB. Học tăng cường \nC. Học có giám sát \nD. Học bán giám sát",
        "Đáp án":"C",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Mục tiêu chính của Học không giám sát (Unsupervised Learning) là gì?",
        "Phương án (nếu có)":"A. Tối đa hóa phần thưởng trong một môi trường \nB. Tìm kiếm các mẫu hoặc cấu trúc tiềm ẩn trong dữ liệu không được gán nhãn \nC. Dự đoán một giá trị liên tục dựa trên dữ liệu đã gán nhãn \nD. Phân loại dữ liệu vào các danh mục đã biết trước",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"\"Một tác nhân học thông qua sự tương tác với môi trường để tối đa hóa phần thưởng\" là mô tả của loại hình học nào?",
        "Phương án (nếu có)":"A. Học có giám sát \nB. Học tăng cường \nC. Học không giám sát \nD. Học sâu",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Hồi quy (Regression) và Phân loại (Classification) là hai loại vấn đề chính của loại hình học nào?",
        "Phương án (nếu có)":"A. Học có giám sát \nB. Học không giám sát \nC. Học tăng cường \nD. Tất cả các loại trên",
        "Đáp án":"A",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Học sâu (Deep Learning) được giới thiệu là một nhánh của học máy sử dụng... ",
        "Phương án (nếu có)":"A. Chỉ các thuật toán hồi quy \nB. Chỉ dữ liệu không được gán nhãn \nC. Mạng nơ-ron với nhiều lớp ẩn \nD. Một tác nhân và một môi trường",
        "Đáp án":"C",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Đâu KHÔNG phải là một trong ba hình thức học máy chính được phân biệt trong bài giảng?",
        "Phương án (nếu có)":"A. Học có giám sát (Supervised Learning) \nB. Học không giám sát (Unsupervised Learning) \nC. Học tăng cường (Reinforcement Learning) \nD. Học bán giám sát (Semi-supervised Learning)",
        "Đáp án":"D",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Học máy (Machine Learning) khác biệt với \"các chương trình thủ tục truyền thống\" ở điểm nào?",
        "Phương án (nếu có)":"A. Học máy không cần máy tính để chạy\nB. Học máy ngụ ý học từ dữ liệu thay vì được lập trình tường minh cho mọi tác vụ \nC. Học máy chỉ được sử dụng cho robot \nD. Học máy luôn luôn nhanh hơn các chương trình truyền thống",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Loại học máy nào phù hợp nhất để nhóm các khách hàng có đặc điểm tương tự nhau mà không biết trước các nhóm (ví dụ: phân cụm)?",
        "Phương án (nếu có)":"A. Học có giám sát \nB. Học không giám sát \nC. Học tăng cường \nD. Hồi quy",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Dự đoán giá nhà (một giá trị số liên tục) dựa trên các đặc điểm của ngôi nhà (dữ liệu gán nhãn) là một ví dụ của bài toán...",
        "Phương án (nếu có)":"A. Phân loại (Classification) \nB. Hồi quy (Regression) \nC. Phân cụm (Clustering) \nD. Học tăng cường",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Huấn luyện một chương trình chơi cờ vua bằng cách cho nó tự chơi nhiều ván và học từ thắng\/thua là một ví dụ của...",
        "Phương án (nếu có)":"A. Học có giám sát \nB. Học không giám sát \nC. Học tăng cường \nD. Phân loại",
        "Đáp án":"C",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"\"Hồi quy\" (Regression) là...",
        "Phương án (nếu có)":"A. Một tác vụ chính của Học không giám sát \nB. Một tác vụ chính của Học có giám sát \nC. Tên gọi khác của Học tăng cường \nD. Một loại mạng nơ-ron",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"\"Phân loại\" (Classification) là...",
        "Phương án (nếu có)":"A. Một tác vụ chính của Học không giám sát \nB. Một tác vụ chính của Học có giám sát \nC. Tên gọi khác của Học tăng cường \nD. Một loại mạng nơ-ron",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Học sâu (Deep Learning) là một nhánh của...",
        "Phương án (nếu có)":"A. Học máy (Machine Learning) \nB. Chỉ Học tăng cường \nC. Chỉ Học có giám sát \nD. Các chương trình thủ tục truyền thống",
        "Đáp án":"A",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Dữ liệu đầu vào cho Học có giám sát (Supervised Learning) thường bao gồm...",
        "Phương án (nếu có)":"A. Chỉ dữ liệu đầu vào, không có nhãn \nB. Chỉ nhãn (đầu ra), không có dữ liệu đầu vào \nC. Cả dữ liệu đầu vào và nhãn (đầu ra) tương ứng \nD. Một tác nhân và một môi trường",
        "Đáp án":"C",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Yếu tố phân biệt cốt lõi giữa Học có giám sát và Học không giám sát là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Dữ liệu: có giám sát dùng dữ liệu gán nhãn, không giám sát dùng dữ liệu không nhãn.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Sự khác biệt cơ bản trong loại đầu ra của Hồi quy (Regression) và Phân loại (Classification) là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Hồi quy dự đoán giá trị liên tục; Phân loại dự đoán nhãn rời rạc (categorical).",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Yếu tố nào thúc đẩy \"tác nhân\" (agent) trong Học tăng cường (Reinforcement Learning)?",
        "Phương án (nếu có)":null,
        "Đáp án":"Tác nhân học bằng cách tối đa hóa \"phần thưởng\" (reward) nhận được từ môi trường.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Thuật toán SVM (Support Vector Machine) thuộc loại hình học máy nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Học có giám sát (dùng cho Phân loại và Hồi quy).",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Thuật toán K-Means thuộc loại hình học máy nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Học không giám sát (dùng để Phân cụm - Clustering).",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Hiện tượng \"overfitting\" (học quá đà) trong Học có giám sát là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Mô hình hoạt động tốt trên dữ liệu huấn luyện nhưng kém trên dữ liệu mới (unseen data).",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Mục tiêu chính của thuật toán PCA (Phân tích thành phần chính) là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Giảm chiều dữ liệu trong khi giữ lại nhiều phương sai (variance) nhất.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"\"Kernel trick\" (thủ thuật hạt nhân) trong SVM dùng để làm gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Xử lý dữ liệu không thể phân chia tuyến tính bằng cách ánh xạ lên chiều không gian cao hơn.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Cây quyết định (Decision Tree) dùng cho loại bài toán Học có giám sát nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Cả Phân loại (Classification) và Hồi quy (Regression).",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"PCA và K-Means có điểm chung gì về loại hình học máy?",
        "Phương án (nếu có)":null,
        "Đáp án":"Cả hai đều là thuật toán Học không giám sát (Unsupervised Learning).",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Thuật toán nào tìm \"đường siêu phẳng\" (hyperplane) tối ưu để phân chia dữ liệu?",
        "Phương án (nếu có)":null,
        "Đáp án":"Máy vector hỗ trợ (Support Vector Machine - SVM).",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Trong thuật toán K-Means, \"K\" đại diện cho điều gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Số lượng cụm (cluster) mà người dùng xác định trước.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"PCA giải quyết vấn đề \"đa cộng tuyến\" (multicollinearity) bằng cách nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Biến đổi các đặc trưng tương quan thành các thành phần chính không tương quan.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Hồi quy Logistic (Logistic Regression) thực chất giải quyết bài toán nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Bài toán Phân loại (Classification), mặc dù tên gọi của nó là Hồi quy.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":2,
        "Nội dung câu hỏi":"Trong SVM, \"support vectors\" (vector hỗ trợ) là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Là các điểm dữ liệu nằm gần đường siêu phẳng nhất, quyết định vị trí của nó.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Ba loại tầng chính trong một CNN điển hình là Lớp Tích chập (Convolutional Layer), Lớp Gộp (Pooling Layer) và Lớp Kết nối Đầy đủ (Fully-connected Layer",
        "Phương án (nếu có)":null,
        "Đáp án":"Yes",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Lớp Gộp (Pooling Layer) có chức năng chính là làm tăng kích thước không gian (spatial dimensions) của bản đồ đặc trưng để thu thập thêm thông tin chi tiết.",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Hàm kích hoạt ReLU (Rectified Linear Unit) được thêm vào sau các lớp tích chập chủ yếu để giới thiệu tính phi tuyến tính (non-linearity) cho mô hình.",
        "Phương án (nếu có)":null,
        "Đáp án":"Yes",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Lớp Kết nối Đầy đủ (Fully-connected Layer) chịu trách nhiệm chính trong việc trích xuất các đặc trưng cục bộ (local features) từ hình ảnh đầu vào.",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Trong một Lớp Tích chập, cơ chế \"chia sẻ trọng số\" (weight sharing) có nghĩa là mỗi nơ-ron trong cùng một bản đồ đặc trưng sử dụng cùng một bộ lọc (filter) và trọng số, giúp giảm đáng kể số lượng tham số.",
        "Phương án (nếu có)":null,
        "Đáp án":"Yes",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Kỹ thuật \"Dropout\" được giới thiệu trong các mạng CNN chủ yếu để tăng tốc độ huấn luyện bằng cách bỏ qua các lớp không cần thiết.",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Kiến trúc VGGNet (ví dụ: VGG-16) nổi tiếng với việc sử dụng nhiều kích thước bộ lọc (như 1x1, 3x3, 5x5) trong cùng một mô-đun để thu thập đặc trưng đa tỷ lệ.",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Kiến trúc ResNet giới thiệu \"skip connections\" (kết nối tắt) để giải quyết vấn đề suy thoái (degradation), cho phép huấn luyện các mạng nơ-ron sâu hơn đáng kể.",
        "Phương án (nếu có)":null,
        "Đáp án":"Yes",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"\"Tính bất biến dịch chuyển\" (Translation Invariance) là một đặc tính mong muốn của CNN, có nghĩa là mô hình có thể nhận diện một đối tượng ngay cả khi vị trí của nó thay đổi trong ảnh.",
        "Phương án (nếu có)":null,
        "Đáp án":"Yes",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Hàm kích hoạt Softmax thường được sử dụng trong các Lớp Tích chập (Convolutional Layers) để chuẩn hóa các giá trị đặc trưng.",
        "Phương án (nếu có)":null,
        "Đáp án":"No",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Đâu là sự khác biệt chính giữa Max Pooling và Average Pooling?",
        "Phương án (nếu có)":"A. Max Pooling chọn giá trị lớn nhất trong vùng quét để giữ lại đặc trưng nổi bật nhất, trong khi Average Pooling tính trung bình tất cả các giá trị để tổng hợp thông tin. \nB. Max Pooling làm tăng kích thước ảnh, trong khi Average Pooling làm giảm kích thước. \nC. Max Pooling chỉ được sử dụng trong VGG, còn Average Pooling chỉ được sử dụng trong LeNet. \nD. Max Pooling là một kỹ thuật tuyến tính, trong khi Average Pooling là phi tuyến tính.",
        "Đáp án":"A",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Mục đích chính của việc sử dụng padding='same' trong một lớp tích chập là gì?",
        "Phương án (nếu có)":"A. Để đảm bảo bản đồ đặc trưng đầu ra có cùng kích thước không gian (chiều cao và chiều rộng) với bản đồ đặc trưng đầu vào. \nB. Để giảm số lượng tham số trong bộ lọc (filter). \nC. Để tăng tốc độ tính toán bằng cách bỏ qua các pixel ở biên. \nD. Để ngăn chặn hiện tượng overfitting bằng cách thêm nhiễu (noise) vào đầu vào.",
        "Đáp án":"A",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Nếu một lớp tích chập nhận đầu vào có kích thước 28x28x1, sử dụng 10 bộ lọc (filters) kích thước 5x5, với stride = 1 và padding = 'valid' (không đệm), kích thước của đầu ra (feature map) sẽ là gì?",
        "Phương án (nếu có)":"A. 24x24x10 \nB. 28x28x10 \nC. 24x24x1 \nD. 32x32x10",
        "Đáp án":"A",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Cơ chế 'chia sẻ trọng số' (weight sharing) trong các lớp tích chập mang lại lợi ích kép quan trọng nào? ",
        "Phương án (nếu có)":"A. Tăng tốc độ lan truyền ngược (backpropagation) và giảm kích thước bộ nhớ đệm (cache). \nB. Giảm đáng kể số lượng tham số cần huấn luyện và tạo ra tính bất biến với dịch chuyển (translation invariance) cho việc phát hiện đặc trưng. \nC. Chỉ cho phép các giá trị dương đi qua (giống ReLU) và chuẩn hóa đầu ra. \nD. Tăng độ sâu của mạng (deep) và giảm độ phức tạp tính toán của lớp gộp (pooling).",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Trong CNN, khái niệm 'trường tiếp nhận cục bộ' (local receptive field) có nghĩa là gì?",
        "Phương án (nếu có)":"A. Mỗi nơ-ron trong một lớp tích chập chỉ kết nối với một vùng nhỏ (cục bộ) của lớp đầu vào trước đó. \nB. Toàn bộ hình ảnh được thu nhỏ lại thành một trường tiếp nhận duy nhất. \nC. Chỉ các nơ-ron ở gần trung tâm hình ảnh mới được kích hoạt.\nD. Mạng chỉ có thể nhận diện các vật thể nhỏ (cục bộ).",
        "Đáp án":"A",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Tại sao hàm kích hoạt ReLU (Rectified Linear Unit) thường được ưu tiên hơn Sigmoid hoặc Tanh trong các lớp ẩn của CNN hiện đại (như AlexNet, VGG, ResNet)?",
        "Phương án (nếu có)":"A. Vì ReLU là một hàm tuyến tính hoàn toàn, giúp mô hình hội tụ nhanh hơn. \nB. Vì ReLU giúp giảm thiểu vấn đề \"biến mất gradient\" (vanishing gradient) và có hiệu quả tính toán cao (chỉ cần một phép so sánh). \nC. Vì ReLU chỉ hoạt động trên các giá trị âm, giúp loại bỏ nhiễu. \nD. Vì ReLU chuẩn hóa đầu ra về khoảng , giống như xác suất.",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Hàm kích hoạt Softmax thường được đặt ở đâu và với mục đích gì trong một CNN dùng cho phân loại (classification)? ",
        "Phương án (nếu có)":"A. Sau mỗi lớp tích chập, để quyết định đặc trưng nào được giữ lại. \nB. Ở lớp kết nối đầy đủ (Fully-connected) cuối cùng, để chuyển đổi các điểm số (logits) thành một phân phối xác suất trên các lớp. C. Ở lớp gộp (Pooling Layer), để quyết định giá trị nào được gộp. \nD. Ở lớp đầu vào, để chuẩn hóa các giá trị pixel của ảnh.",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Trong các video Nhóm 1, CNN là viết tắt của...",
        "Phương án (nếu có)":"A. Mạng thần kinh phân loại (Classification Neural Network) \nB. Mạng thần kinh máy tính (Computer Neural Network) \nC. Mạng thần kinh tích chập (Convolutional Neural Network) \nD. Mạng nơ-ron phức hợp (Complex Neural Network)",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Lĩnh vực ứng dụng nào được liệt kê cho Học sâu, nơi mà CNN thường được sử dụng rộng rãi?",
        "Phương án (nếu có)":"A. Thị giác máy tính (Computer Vision) \nB. Học tăng cường \nC. Lập trình thủ tục \nD. Chỉ Hồi quy",
        "Đáp án":"A",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Thuật toán nào sau đây thường được đề cập cùng với CNN như một thuật toán chính khác của Học sâu?",
        "Phương án (nếu có)":"A. Hồi quy Logistic \nB. Máy Vector hỗ trợ (SVM) \nC. Mạng thần kinh hồi quy (RNN) \nD. Phân cụm K-Means",
        "Đáp án":"B",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Tại sao các mạng nơ-ron sâu phải dùng hàm kích hoạt phi tuyến (non-linear)?",
        "Phương án (nếu có)":null,
        "Đáp án":"Vì nếu không, toàn bộ mạng sâu chỉ tương đương một lớp tuyến tính duy nhất.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Tại sao ReLU ưu việt hơn Sigmoid trong mạng CNN sâu?",
        "Phương án (nếu có)":null,
        "Đáp án":"Vì ReLU giải quyết vấn đề \"biến mất gradient\" (vanishing gradient) và nhanh hơn.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Lợi ích kép của \"chia sẻ trọng số\" (weight sharing) trong lớp tích chập là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Giảm mạnh số lượng tham số và tạo ra tính bất biến dịch chuyển.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"\"Tính bất biến dịch chuyển\" (Translation Invariance) nghĩa là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Khả năng nhận diện vật thể bất kể vị trí của nó thay đổi trong ảnh.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Chức năng kép của Lớp Gộp (Pooling Layer) là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Giảm kích thước không gian (downsampling) và kiểm soát overfitting.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Tích chập 1x1 (1x1 Convolution) trong ResNet hay GoogLeNet dùng để làm gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Để giảm (hoặc tăng) độ sâu (số kênh) nhằm giảm chi phí tính toán.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"ResNet giải quyết vấn đề \"suy thoái\" (degradation problem) bằng cơ chế nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Sử dụng \"kết nối tắt\" (skip connections) để học phần dư (residual).",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Đóng góp lý thuyết chính của kiến trúc VGG là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Chứng minh rằng chỉ riêng độ sâu (depth) với các filter 3x3 nhỏ đã rất hiệu quả.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Đổi mới nào của AlexNet (so với LeNet) giúp thắng ILSVRC 2012?",
        "Phương án (nếu có)":null,
        "Đáp án":"Sử dụng ReLU, huấn luyện trên GPU, và kỹ thuật Dropout.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Ý tưởng cốt lõi của mô-đun \"Inception\" (GoogLeNet) là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Thực hiện tích chập nhiều kích cỡ (1x1, 3x3, 5x5) song song rồi ghép (concatenate) lại.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Vai trò của Lớp Kết nối Đầy đủ (Fully-connected) trong CNN là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Tổng hợp các đặc trưng cấp cao đã trích xuất để thực hiện phân loại cuối cùng.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Kỹ thuật \"Dropout\" được dùng để giải quyết vấn đề gì? ",
        "Phương án (nếu có)":null,
        "Đáp án":"Giảm overfitting (học quá đà) bằng cách tắt ngẫu nhiên các nơ-ron khi huấn luyện.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Stride > 1 và Lớp Gộp (Pooling Layer) có điểm chung nào về chức năng?",
        "Phương án (nếu có)":null,
        "Đáp án":"Cả hai đều làm giảm kích thước không gian (chiều cao\/rộng) của bản đồ đặc trưng.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"Padding='same' trong lớp tích chập đảm bảo điều gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Đảm bảo kích thước không gian (chiều cao\/rộng) của đầu ra bằng đầu vào.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":3,
        "Nội dung câu hỏi":"\"Học chuyển giao\" (Transfer Learning) trong CNN nghĩa là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Tái sử dụng mô hình đã được huấn luyện trước (pre-trained model) cho một nhiệm vụ mới.",
        "Link Video":null,
        "Timestamps":null
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Sau khi dữ liệu đầu vào qua lớp Convolution và ReLU đầu tiên trong CNN, tensor tạo ra được gọi là gì?",
        "Phương án (nếu có)":"a) Vector; b) Feature Map; c) Output Logit; d) Trọng số",
        "Đáp án":"b) Feature Map",
        "Link Video":"https:\/\/www.youtube.com\/watch?v=PyC3pl_r8jw",
        "Timestamps":"00:00:40–00:01:20"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Khi thực hiện phép Pooling (với S=2) trên một Feature Map có kích thước W×H×D, kích thước độ sâu D của output sẽ thay đổi như thế nào?",
        "Phương án (nếu có)":"a) Giảm một nửa; b) Tăng gấp đôi; c) Giữ nguyên; d) Luôn giảm về 1",
        "Đáp án":"c) Giữ nguyên",
        "Link Video":"https:\/\/www.youtube.com\/watch?v=PyC3pl_r8jw",
        "Timestamps":"00:01:45–00:02:10"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Mục tiêu của lớp Softmax ở đầu ra của mạng CNN là gì?",
        "Phương án (nếu có)":"a) Đảm bảo tổng giá trị bằng 0; b) Chuyển đổi vector về dạng phân bố xác suất; c) Thực hiện phép biến đổi tuyến tính; d) Rút trích đặc trưng hình ảnh",
        "Đáp án":"b) Chuyển đổi vector về dạng phân bố xác suất",
        "Link Video":"https:\/\/www.youtube.com\/watch?v=PyC3pl_r8jw",
        "Timestamps":"00:02:30–00:03:00"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Bản chất của phép biến đổi Convolution (tích chập) trong mạng CNN là gì?",
        "Phương án (nếu có)":"a) Phép biến đổi phi tuyến; b) Phép biến đổi Logistic; c) Phép biến đổi tuyến tính; d) Phép nhân ma trận đơn thuần",
        "Đáp án":"c) Phép biến đổi tuyến tính",
        "Link Video":"https:\/\/www.youtube.com\/watch?v=PyC3pl_r8jw",
        "Timestamps":"00:03:10–00:03:40"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Trong một tầng Convolution, nếu input đầu vào có độ sâu là D, thì độ sâu của các Filter (bộ lọc) sử dụng trong tầng đó phải là bao nhiêu?",
        "Phương án (nếu có)":"a) Luôn bằng 1; b) Bằng D; c) Bằng số lượng Filter K; d) Bằng kích thước bề ngang",
        "Đáp án":"b) Bằng D",
        "Link Video":"https:\/\/www.youtube.com\/watch?v=PyC3pl_r8jw",
        "Timestamps":"00:04:30–00:05:00"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Hai cơ chế chính nào của phép biến đổi Convolution được xem là sự cải tiến lớn nhất trong kiến trúc LeNet so với Fully Connected (FC)?",
        "Phương án (nếu có)":"a) ReLU và Batch Normalization; b) Local Connectivity và Weight Sharing; c) Dropout và Tanh; d) Subsampling và Max Pooling",
        "Đáp án":"b) Local Connectivity và Weight Sharing",
        "Link Video":"https:\/\/www.youtube.com\/watch?v=PyC3pl_r8jw",
        "Timestamps":"00:08:00–00:08:30"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Mục tiêu của việc làm giảm số lượng tham số trong phép biến đổi Convolution (nhờ Weight Sharing) là gì?",
        "Phương án (nếu có)":"a) Tăng tốc độ hội tụ; b) Giảm hiện tượng Overfitting; c) Tăng độ chính xác trên tập Test; d) Đơn giản hóa kiến trúc mạng",
        "Đáp án":"b) Giảm hiện tượng Overfitting",
        "Link Video":"https:\/\/www.youtube.com\/watch?v=PyC3pl_r8jw",
        "Timestamps":"00:08:30–00:08:50"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Nếu phép Pooling giảm kích thước bề ngang và bề cao của Feature Map xuống một nửa (S=2), tổng số lượng phần tử trong tensor sẽ giảm đi bao nhiêu lần?",
        "Phương án (nếu có)":"a) 2 lần; b) 3 lần; c) 4 lần; d) Không đổi",
        "Đáp án":"c) 4 lần",
        "Link Video":"https:\/\/www.youtube.com\/watch?v=PyC3pl_r8jw",
        "Timestamps":"00:09:15–00:09:50"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Cải tiến chính đầu tiên của AlexNet so với các kiến trúc trước đây liên quan đến hàm kích hoạt là gì?",
        "Phương án (nếu có)":"a) Thay thế hàm kích hoạt ReLU bằng Sigmoid; b) Thay thế hàm kích hoạt Sigmoid bằng ReLU; c) Giới thiệu hàm Tangent Hyperbolic (tanh); d) Giữ nguyên hàm Sigmoid nhưng chuẩn hóa đầu vào.",
        "Đáp án":"b) Thay thế hàm kích hoạt Sigmoid bằng ReLU",
        "Link Video":"https:\/\/youtu.be\/KoBIBuqGb9A",
        "Timestamps":"00:00:30–00:00:50"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Mục đích của việc sử dụng hàm kích hoạt ReLU thay vì Sigmoid trong AlexNet là gì?",
        "Phương án (nếu có)":"a) Tăng độ sâu của mạng; b) Tăng số lượng tham số; c) Giảm\/tránh được hiện tượng Vanishing Gradient; d) Tăng tốc độ tính toán đạo hàm.",
        "Đáp án":"c) Giảm\/tránh được hiện tượng Vanishing Gradient",
        "Link Video":"https:\/\/youtu.be\/KoBIBuqGb9A",
        "Timestamps":"00:01:00–00:01:30"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Hiện tượng Vanishing Gradient xảy ra khi nào trong quá trình cập nhật tham số?",
        "Phương án (nếu có)":"a) Đạo hàm của hàm loss theo theta tiến về 0, làm bước nhảy cập nhật gần như không đổi; b) Đạo hàm của hàm loss tăng rất nhanh; c) Hàm activation luôn cho ra giá trị dương; d) Số lượng lớp mạng quá ít.",
        "Đáp án":"a) Đạo hàm của hàm loss theo theta tiến về 0, làm bước nhảy cập nhật gần như không đổi",
        "Link Video":"https:\/\/youtu.be\/KoBIBuqGb9A",
        "Timestamps":"00:01:40–00:02:10"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Tại sao hàm Sigmoid dễ dẫn đến hiện tượng Vanishing Gradient?",
        "Phương án (nếu có)":"a) Đạo hàm của nó luôn bằng 1; b) Nó rất dễ bị bảo hòa (độ dốc đạo hàm tiến về 0) khi giá trị đầu vào X chỉ đạt được những giá trị bé; c) Nó chỉ được định nghĩa cho các giá trị X dương; d) Nó làm tăng số lượng tham số không cần thiết.",
        "Đáp án":"b) Nó rất dễ bị bảo hòa (độ dốc đạo hàm tiến về 0) khi giá trị đầu vào X chỉ đạt được những giá trị bé",
        "Link Video":"https:\/\/youtu.be\/KoBIBuqGb9A",
        "Timestamps":"00:02:40–00:03:10"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Đối với hàm ReLU, đạo hàm của nó cho các giá trị x>0 là bao nhiêu, giúp giảm hiện tượng Vanishing Gradient?",
        "Phương án (nếu có)":"a) Bằng 0; b) Bằng x; c) Luôn là hằng số cố định bằng 1; d) Tiến về 0.",
        "Đáp án":"c) Luôn là hằng số cố định bằng 1",
        "Link Video":"https:\/\/youtu.be\/KoBIBuqGb9A",
        "Timestamps":"00:03:40–00:04:10"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Để tránh hiện tượng Overfitting khi tăng độ sâu mạng và số lượng tham số, AlexNet đã sử dụng phương pháp nào?",
        "Phương án (nếu có)":"a) Giảm số lượng lớp Convolution; b) Chỉ sử dụng GPU; c) Tăng cường dữ liệu bằng Data Augmentation; d) Chỉ sử dụng các filter kích thước 1x1.",
        "Đáp án":"c) Tăng cường dữ liệu bằng Data Augmentation",
        "Link Video":"https:\/\/youtu.be\/KoBIBuqGb9A",
        "Timestamps":"00:04:40–00:05:10"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Cải tiến chính trong kiến trúc VGG là gì?",
        "Phương án (nếu có)":"a) Sử dụng hàm kích hoạt Sigmoid; b) Thay thế các filter kích thước lớn (5x5, 7x7) bằng các filter 3x3 liên tiếp nhau; c) Giới thiệu lớp Pooling toàn cục; d) Giảm độ sâu của mạng.",
        "Đáp án":"b) Thay thế các filter kích thước lớn (5x5, 7x7) bằng các filter 3x3 liên tiếp nhau",
        "Link Video":"https:\/\/youtu.be\/KoBIBuqGb9A",
        "Timestamps":"00:07:30–00:08:00"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Việc sử dụng hai phép Convolution 3x3 liên tiếp thay cho một phép 5x5 trong VGG mang lại lợi ích về mặt hiệu suất nào?",
        "Phương án (nếu có)":"a) Giảm Receptive Field; b) Tăng tốc độ huấn luyện gấp 50 lần; c) Giảm số lượng tham số (khoảng 30%) so với 5x5, giúp giảm overfitting; d) Tăng số lượng kênh đầu ra.",
        "Đáp án":"c) Giảm số lượng tham số (khoảng 30%) so với 5x5, giúp giảm overfitting",
        "Link Video":"https:\/\/youtu.be\/KoBIBuqGb9A",
        "Timestamps":"00:10:50–00:11:30"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Mục đích chính của việc sử dụng lớp bottleneck (1×1 convolution) trong Google LeNet là gì?",
        "Phương án (nếu có)":"a) Tăng độ chính xác nhận diện; b) Tăng kích thước độ sâu của đặc trưng; c) Giảm số chiều đặc trưng và giảm số lượng tính toán; d) Thực hiện phép Max Pooling.",
        "Đáp án":"c) Giảm số chiều đặc trưng và giảm số lượng tính toán",
        "Link Video":"https:\/\/youtu.be\/tMKUb4k5nZw",
        "Timestamps":"00:00:10–00:00:45"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Google LeNet sử dụng module nào để kết hợp các kết quả convolution từ các filter có kích thước khác nhau (1×1,3×3,5×5)?",
        "Phương án (nếu có)":"a) Residual Block; b) Bottleneck Layer; c) Inception Module; d) Skip Connection.",
        "Đáp án":"c) Inception Module",
        "Link Video":"https:\/\/youtu.be\/tMKUb4k5nZw",
        "Timestamps":"00:00:45–00:01:05"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Khi sử dụng module Inception, các feature map thu được từ các nhánh song song (với kích thước filter khác nhau) được xử lý như thế nào để tạo thành output cuối cùng?",
        "Phương án (nếu có)":"a) Cộng (Sum) chúng lại; b) Nhân (Multiply) chúng lại; c) Nối đặc trưng (Concat) lại; d) Max Pooling trên chúng.",
        "Đáp án":"c) Nối đặc trưng (Concat) lại",
        "Link Video":"https:\/\/youtu.be\/tMKUb4k5nZw",
        "Timestamps":"00:05:40–00:06:10"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"So với AlexNet (8 layer) và VGG (19 layer), Google LeNet có tổng cộng bao nhiêu lớp (layer)?",
        "Phương án (nếu có)":"a) 12 layer; b) 15 layer; c) 22 layer; d) 30 layer.",
        "Đáp án":"c) 22 layer",
        "Link Video":"https:\/\/youtu.be\/tMKUb4k5nZw",
        "Timestamps":"00:07:00–00:07:30"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Khi số lượng layer của mạng (ví dụ lớn hơn 20) được tăng lên mà không có các cải tiến đặc biệt, điều gì đã được quan sát về độ lỗi (error)?",
        "Phương án (nếu có)":"a) Độ lỗi tiếp tục giảm mạnh; b) Độ lỗi tăng lên (hiệu suất tệ đi); c) Độ lỗi không thay đổi; d) Mạng bị Exploding Gradient.",
        "Đáp án":"b) Độ lỗi tăng lên (hiệu suất tệ đi)",
        "Link Video":"https:\/\/youtu.be\/tMKUb4k5nZw",
        "Timestamps":"00:08:50–00:09:20"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Cải tiến lớn nhất và đơn giản nhất giúp mạng ResNet (Residual Network) giải quyết vấn đề của mạng sâu là gì?",
        "Phương án (nếu có)":"a) Sử dụng 1×1 convolution; b) Tăng tốc độ học (learning rate); c) Skip Connection (hoặc Residual module); d) Áp dụng Dropout.",
        "Đáp án":"c) Skip Connection (hoặc Residual module)",
        "Link Video":"https:\/\/youtu.be\/tMKUb4k5nZw",
        "Timestamps":"00:09:50–00:10:20"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Công thức của hàm biến đổi trong một Residual Block của ResNet là gì, khi F(x) là kết quả của phép biến đổi convolution thông thường và x là đầu vào ban đầu?",
        "Phương án (nếu có)":"a) H(x)=F(x)⋅x; b) H(x)=F(x)−x; c) H(x)=F(x)+x; d) H(x)=F(x).",
        "Đáp án":"c) H(x)=F(x)+x",
        "Link Video":"https:\/\/youtu.be\/tMKUb4k5nZw",
        "Timestamps":"00:10:30–00:10:50"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Hiện tượng nào mà việc sử dụng Skip Connection trong ResNet giúp chống lại hiệu quả?",
        "Phương án (nếu có)":"a) Overfitting; b) Exploding Gradient; c) Vanishing Gradient; d) Dead ReLU.",
        "Đáp án":"c) Vanishing Gradient",
        "Link Video":"https:\/\/youtu.be\/tMKUb4k5nZw",
        "Timestamps":"00:11:00–00:11:25"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Về mặt đạo hàm, việc cộng thêm thành phần x (identity mapping) vào F(x) trong ResNet có tác dụng gì?",
        "Phương án (nếu có)":"a) Làm cho đạo hàm tiến về 0 nhanh hơn; b) Đảm bảo đạo hàm của H(x) luôn lớn hơn hoặc bằng 1; c) Làm cho đạo hàm luôn bằng 0; d) Chỉ là một thao tác tăng tính phi tuyến.",
        "Đáp án":"b) Đảm bảo đạo hàm của H(x) luôn lớn hơn hoặc bằng 1",
        "Link Video":"https:\/\/youtu.be\/tMKUb4k5nZw",
        "Timestamps":"00:12:00–00:12:35"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"ResNet đã cho thấy hiệu quả như thế nào khi áp dụng Skip Connection so với các kiến trúc trước đó?",
        "Phương án (nếu có)":"a) Có thể xây dựng mạng sâu hơn nhiều (ví dụ 110 layer) mà vẫn có độ lỗi thấp; b) Giảm số lượng tham số xuống mức tối thiểu; c) Chỉ giành chiến thắng vào năm 2012; d) Chỉ hoạt động tốt với mạng nông.",
        "Đáp án":"a) Có thể xây dựng mạng sâu hơn nhiều (ví dụ 110 layer) mà vẫn có độ lỗi thấp",
        "Link Video":"https:\/\/youtu.be\/tMKUb4k5nZw",
        "Timestamps":"00:14:10–00:15:00"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Mục tiêu chính khi kiến trúc MobileNet ra đời vào khoảng năm 2018 là gì?",
        "Phương án (nếu có)":"a) Tăng độ chính xác (accuracy); b) Giảm khối lượng tính toán; c) Khắc phục hiện tượng Vanishing Gradient; d) Đa dạng hóa kích thước filter",
        "Đáp án":"b) Giảm khối lượng tính toán",
        "Link Video":"https:\/\/youtu.be\/MNHY9TA4fZs",
        "Timestamps":"00:00:00–00:00:27"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"MobileNet đã thay thế phép Convolution bình thường bằng phép toán nào để đạt được mục tiêu giảm tính toán?",
        "Phương án (nếu có)":"a) Pointwise Convolution; b) Depthwise Convolution; c) Depthwise Separable Convolution (DSC); d) Convolution 1x1",
        "Đáp án":"c) Depthwise Separable Convolution (DSC)",
        "Link Video":"https:\/\/youtu.be\/MNHY9TA4fZs",
        "Timestamps":"00:00:27–00:00:40"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Phép Depthwise Separable Convolution (DSC) được thực hiện qua mấy bước chính?",
        "Phương án (nếu có)":"a) 1 bước: 3x3 Convolution; b) 2 bước: Depthwise Convolution và Pointwise Convolution; c) 3 bước: 1x1, 3x3, và 5x5 Convolution; d) 2 bước: Pooling và Convolution",
        "Đáp án":"b) 2 bước: Depthwise Convolution và Pointwise Convolution",
        "Link Video":"https:\/\/youtu.be\/MNHY9TA4fZs",
        "Timestamps":"00:00:30–00:01:05"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Theo bài giảng, khi sử dụng DSC, số lượng tham số của MobileNet giảm xấp xỉ bao nhiêu lần so với phép Convolution thông thường?",
        "Phương án (nếu có)":"a) 1\/2 lần; b) 1\/9 lần; c) 1\/32 lần; d) 8\/9 lần",
        "Đáp án":"b) 1\/9 lần",
        "Link Video":"https:\/\/youtu.be\/MNHY9TA4fZs",
        "Timestamps":"00:03:00–00:03:30"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Hai cải tiến lớn nhất của kiến trúc LeNet là gì, theo bài giảng?",
        "Phương án (nếu có)":"a) Sử dụng GPU và Skip Connection; b) Phép Convolution và phép Pooling; c) Sử dụng ReLU và Data Augmentation; d) Bottleneck 1x1 và Inception Module",
        "Đáp án":"b) Phép Convolution và phép Pooling",
        "Link Video":"https:\/\/youtu.be\/MNHY9TA4fZs",
        "Timestamps":"00:04:10–00:04:35"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Cải tiến lớn nhất của AlexNet là việc thay thế hàm kích hoạt Smo bằng ReLU, điều này giúp giải quyết vấn đề nào?",
        "Phương án (nếu có)":"a) Giảm số lượng tham số; b) Giảm hiện tượng Vanishing Gradient; c) Giảm khối lượng tính toán; d) Tăng cường khả năng trích xuất đặc trưng góc",
        "Đáp án":"b) Giảm hiện tượng Vanishing Gradient",
        "Link Video":"https:\/\/youtu.be\/MNHY9TA4fZs",
        "Timestamps":"00:04:45–00:05:05"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Kiến trúc VGG đã thực hiện cải tiến đơn giản nhưng hiệu quả nào để giảm số lượng tham số?",
        "Phương án (nếu có)":"a) Sử dụng filter 1x1 bottleneck; b) Thay thế filter lớn (5x5, 7x7) bằng các filter 3x3 liên tiếp; c) Chỉ sử dụng Depthwise Convolution; d) Áp dụng Skip Connection",
        "Đáp án":"b) Thay thế filter lớn (5x5, 7x7) bằng các filter 3x3 liên tiếp",
        "Link Video":"https:\/\/youtu.be\/MNHY9TA4fZs",
        "Timestamps":"00:05:25–00:05:55"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Thành phần nào trong GoogleNet giúp tận dụng được các đặc trưng từ nhiều loại filter có kích thước khác nhau (ví dụ: 1x1, 3x3, 5x5)?",
        "Phương án (nếu có)":"a) Depthwise Convolution; b) Skip Connection; c) Inception Module; d) Lớp Fully Connected",
        "Đáp án":"c) Inception Module",
        "Link Video":"https:\/\/youtu.be\/MNHY9TA4fZs",
        "Timestamps":"00:06:25–00:06:50"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Kỹ thuật cốt lõi nào trong ResNet được biểu diễn qua công thức h(x)=convolution(x)+x?",
        "Phương án (nếu có)":"a) Depthwise Separable Convolution; b) Batch Normalization; c) Skip Connection; d) Attention Mechanism",
        "Đáp án":"c) Skip Connection",
        "Link Video":"https:\/\/youtu.be\/MNHY9TA4fZs",
        "Timestamps":"00:07:05–00:07:35"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Theo nội dung tóm tắt, hai vấn đề lớn nhất mà hầu hết các kiến trúc mạng Deep Learning tập trung giải quyết là gì?",
        "Phương án (nếu có)":"a) Mạng quá nông và dữ liệu thiếu; b) Overfitting và Vanishing Gradient; c) Tốc độ tính toán chậm và thiếu GPU; d) Thiếu tham số và thiếu hàm kích hoạt",
        "Đáp án":"b) Overfitting và Vanishing Gradient",
        "Link Video":"https:\/\/youtu.be\/MNHY9TA4fZs",
        "Timestamps":"00:08:10–00:08:40"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Lý do chính khiến các kỹ thuật sử dụng mô hình huấn luyện sẵn (pre-trained model) trở nên cần thiết là gì?",
        "Phương án (nếu có)":"a) Tăng độ phức tạp thuật toán; b) Giảm thời gian và tài nguyên tính toán cho việc huấn luyện mạng CNN trên tập dữ liệu lớn; c) Đảm bảo độ chính xác luôn đạt 100%; d) Chỉ áp dụng cho các bài toán phân loại nhị phân",
        "Đáp án":"b) Giảm thời gian và tài nguyên tính toán cho việc huấn luyện mạng CNN trên tập dữ liệu lớn",
        "Link Video":"https:\/\/youtu.be\/0I8uw0ELYj4",
        "Timestamps":"00:00:15–00:00:45"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Cách tiếp cận \"sử dụng trực tiếp\" mô hình huấn luyện sẵn (Cách 1) phù hợp nhất trong trường hợp nào?",
        "Phương án (nếu có)":"a) Tập dữ liệu mới hoàn toàn khác biệt; b) Các đối tượng\/nhãn của tập dữ liệu mới trùng khớp với các đối tượng trong tập dữ liệu huấn luyện trước đó; c) Chỉ khi dữ liệu mới rất nhỏ; d) Khi cần tinh chỉnh lại toàn bộ mạng",
        "Đáp án":"b) Các đối tượng\/nhãn của tập dữ liệu mới trùng khớp với các đối tượng trong tập dữ liệu huấn luyện trước đó",
        "Link Video":"https:\/\/youtu.be\/0I8uw0ELYj4",
        "Timestamps":"00:00:50–00:01:20"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Khi sử dụng mô hình huấn luyện sẵn như một bộ rút trích đặc trưng (Cách 2), thành phần nào của mạng CNN huấn luyện sẵn bị loại bỏ?",
        "Phương án (nếu có)":"a) Lớp Fully Connected (FC) cuối cùng (lớp phân lớp); b) Toàn bộ các lớp rút trích đặc trưng; c) Lớp Convolution đầu tiên; d) Tất cả các lớp",
        "Đáp án":"a) Lớp Fully Connected (FC) cuối cùng (lớp phân lớp)",
        "Link Video":"https:\/\/youtu.be\/0I8uw0ELYj4",
        "Timestamps":"00:02:10–00:02:40"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Các nhà khoa học phát hiện ra rằng các đặc trưng được rút trích từ mạng huấn luyện trên tập dữ liệu lớn có tính chất như thế nào?",
        "Phương án (nếu có)":"a) Cụ thể hóa cao, chỉ dùng cho dữ liệu cũ; b) Khá là tổng quát, có khả năng tái sử dụng cho các đối tượng khác; c) Cần phải đóng băng hoàn toàn; d) Chỉ tương thích với thuật toán SVM",
        "Đáp án":"b) Khá là tổng quát, có khả năng tái sử dụng cho các đối tượng khác",
        "Link Video":"https:\/\/youtu.be\/0I8uw0ELYj4",
        "Timestamps":"00:02:40–00:03:00"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Trong cách sử dụng mạng CNN như bộ rút trích đặc trưng (Cách 2), các đặc trưng rút trích có thể được kết hợp với những bộ phân lớp máy học nào đã được đề cập trong bài giảng?",
        "Phương án (nếu có)":"a) K-Means và Naive Bayes; b) K-Nearest Neighbor (KNN) và Support Vector Machine (SVM); c) Linear Regression và Decision Tree; d) Random Forest và Logistic Regression",
        "Đáp án":"b) K-Nearest Neighbor (KNN) và Support Vector Machine (SVM)",
        "Link Video":"https:\/\/youtu.be\/0I8uw0ELYj4",
        "Timestamps":"00:03:25–00:03:55"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Khi thực hiện học chuyển tiếp (Transfer Learning), kích thước của lớp đầu ra (Output FC) cuối cùng cần được điều chỉnh như thế nào?",
        "Phương án (nếu có)":"a) Luôn giữ nguyên kích thước 1000 chiều; b) Phải phụ thuộc vào số lượng lớp (nhãn) của tập dữ liệu mới; c) Phụ thuộc vào kích thước ảnh đầu vào; d) Luôn đặt bằng 3 chiều",
        "Đáp án":"b) Phải phụ thuộc vào số lượng lớp (nhãn) của tập dữ liệu mới",
        "Link Video":"https:\/\/youtu.be\/0I8uw0ELYj4",
        "Timestamps":"00:04:55–00:05:25"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Kỹ thuật đóng băng (Freezing) các lớp rút trích đặc trưng và chỉ huấn luyện các lớp phân lớp mới (Cách 3.1) được gọi là gì?",
        "Phương án (nếu có)":"a) Huấn luyện toàn bộ mạng; b) Tinh chỉnh (Fine-tuning) phần cuối; c) Sử dụng trực tiếp; d) Phân loại SVM",
        "Đáp án":"b) Tinh chỉnh (Fine-tuning) phần cuối",
        "Link Video":"https:\/\/youtu.be\/0I8uw0ELYj4",
        "Timestamps":"00:05:30–00:06:00"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Kỹ thuật \"Tinh chỉnh phần cuối\" (Cách 3.1) trong Transfer Learning phù hợp nhất cho trường hợp nào?",
        "Phương án (nếu có)":"a) Tập dữ liệu mới rất lớn; b) Tập dữ liệu mới nhỏ; c) Khi cần phân loại nhị phân; d) Khi các đối tượng trùng khớp với dữ liệu gốc",
        "Đáp án":"b) Tập dữ liệu mới nhỏ",
        "Link Video":"https:\/\/youtu.be\/0I8uw0ELYj4",
        "Timestamps":"00:06:10–00:06:35"
    },
    {
        "Chương":4,
        "Nội dung câu hỏi":"Khi tập dữ liệu mới (data mới) rất lớn, phương pháp học chuyển tiếp nào được đề xuất (Cách 3.2)?",
        "Phương án (nếu có)":"a) Đóng băng toàn bộ các lớp; b) Huấn luyện (tinh chỉnh) toàn bộ mạng, bao gồm cả phần rút trích đặc trưng và phần phân lớp; c) Chỉ sử dụng SVM; d) Chỉ huấn luyện lớp cuối cùng",
        "Đáp án":"b) Huấn luyện (tinh chỉnh) toàn bộ mạng, bao gồm cả phần rút trích đặc trưng và phần phân lớp",
        "Link Video":"https:\/\/youtu.be\/0I8uw0ELYj4",
        "Timestamps":"00:06:40–00:07:10"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Kiến trúc căn bản của mạng CNN cho bài toán phân loại đối tượng bao gồm những thành phần chính nào?",
        "Phương án (nếu có)":"a) Convolution và Pooling; b) Fully Connected và Softmax; c) Học rút trích đặc trưng và Phân loại đặc trưng; d) Cả a và b",
        "Đáp án":"c) Học rút trích đặc trưng và Phân loại đặc trưng",
        "Link Video":"https:\/\/youtu.be\/RVFApjx4KKI",
        "Timestamps":"00:00:30–00:00:55"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Bài toán phân loại đối tượng dạng \"mịn\" (Fine-Grained Object Classification) đề cập đến việc phân loại ở cấp độ nào",
        "Phương án (nếu có)":"a) Phân biệt giữa các loài vật cơ bản (chó, mèo, cây); b) Phân loại các đối tượng có cùng đặc điểm tổng thể nhưng khác nhau ở chi tiết nhỏ, ví dụ: các giống hoa hồng hoặc các dòng xe; c) Phân loại ảnh trắng đen; d) Phân loại chỉ áp dụng cho khuôn mặt",
        "Đáp án":"b) Phân loại các đối tượng có cùng đặc điểm tổng thể nhưng khác nhau ở chi tiết nhỏ, ví dụ: các giống hoa hồng hoặc các dòng xe",
        "Link Video":"https:\/\/youtu.be\/RVFApjx4KKI",
        "Timestamps":"00:01:45–00:02:15"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Điều gì tạo nên độ khó cho bài toán nhận diện gương mặt (Face Recognition) dạng Fine-Grained?",
        "Phương án (nếu có)":"a) Gương mặt không có mắt, mũi, miệng; b) Các đối tượng có đặc điểm tổng thể giống nhau nhưng khác nhau ở những chi tiết rất nhỏ (tỷ lệ, màu da); c) Ảnh gương mặt luôn bị che khuất; d) Dataset luôn nhỏ",
        "Đáp án":"b) Các đối tượng có đặc điểm tổng thể giống nhau nhưng khác nhau ở những chi tiết rất nhỏ (tỷ lệ, màu da",
        "Link Video":"https:\/\/youtu.be\/RVFApjx4KKI",
        "Timestamps":"00:04:15–00:04:50"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Hướng tiếp cận tiên tiến nhất hiện nay cho bài toán nhận diện gương mặt (Face Recognition) tập trung vào cải tiến điều gì?",
        "Phương án (nếu có)":"a) Cấu trúc mạng CNN (ví dụ: tăng số lớp Convolution); b) Hàm loss (Loss Function); c) Hàm kích hoạt (Activation Function); d) Kỹ thuật Pooling",
        "Đáp án":"b) Hàm loss (Loss Function)",
        "Link Video":"https:\/\/youtu.be\/RVFApjx4KKI",
        "Timestamps":"00:06:50–00:07:15"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Các mô hình tiên tiến như FaceNet, SphereFace thường sử dụng loại độ đo hàm loss nào để tách biệt các gương mặt tương tự nhau ra xa trong không gian đặc trưng?",
        "Phương án (nếu có)":"a) Cross-Entropy Loss; b) Mean Squared Error (MSE); c) Angular Margine Loss; d) Hàm Sigmoid",
        "Đáp án":"c) Angular Margine Loss",
        "Link Video":"https:\/\/youtu.be\/RVFApjx4KKI",
        "Timestamps":"00:07:30–00:07:50"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Trong lĩnh vực y tế, tính năng nào của hệ thống AI được xem là cực kỳ quan trọng, bên cạnh độ chính xác cao?",
        "Phương án (nếu có)":"a) Tốc độ huấn luyện mô hình; b) Tính giải thích được (Explainability) của mô hình; c) Khả năng tái sử dụng đặc trưng từ các domain khác; d) Sử dụng ít tài nguyên tính toán",
        "Đáp án":"b) Tính giải thích được (Explainability) của mô hình",
        "Link Video":"https:\/\/youtu.be\/RVFApjx4KKI",
        "Timestamps":"00:09:40–00:10:10"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Ý tưởng chính của bài toán Truy vấn Hình ảnh (Image Retrieval) là gì?",
        "Phương án (nếu có)":"a) Dự đoán đối tượng nào sẽ xuất hiện trong ảnh tiếp theo; b) Cho trước một ảnh truy vấn (query), xác định và sắp xếp các ảnh trong database theo mức độ tương đồng giảm dần; c) Phân đoạn ngữ nghĩa (Semantic Segmentation); d) Tạo ảnh mới từ các đặc trưng rút trích",
        "Đáp án":"b) Cho trước một ảnh truy vấn (query), xác định và sắp xếp các ảnh trong database theo mức độ tương đồng giảm dần",
        "Link Video":"https:\/\/youtu.be\/RVFApjx4KKI",
        "Timestamps":"00:11:00–00:11:30"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Hai tính chất của feature map trong mạng CNN được ứng dụng để giải quyết bài toán phát hiện đối tượng là gì?",
        "Phương án (nếu có)":"a) Tính bất biến về màu sắc và độ tương phản; b) Tính bất biến về trình tự không gian và tính bất biến về tỷ lệ; c) Tính tuyến tính và tính cục bộ; d) Tính bất biến về thời gian và tính ngẫu nhiên",
        "Đáp án":"b) Tính bất biến về trình tự không gian và tính bất biến về tỷ lệ",
        "Link Video":"https:\/\/youtu.be\/Til9AdPO7JE",
        "Timestamps":"00:00:45–00:01:05"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Nhiệm vụ chính của bài toán phát hiện đối tượng (Object Detection) là gì?",
        "Phương án (nếu có)":"a) Chỉ phân loại đối tượng trong ảnh; b) Xác định vùng hình hộp (bounding box) nếu có sự xuất hiện của một hoặc nhiều đối tượng; c) Phân đoạn ngữ nghĩa (Semantic Segmentation); d) Tăng cường độ phân giải của hình ảnh",
        "Đáp án":"b) Xác định vùng hình hộp (bounding box) nếu có sự xuất hiện của một hoặc nhiều đối tượng",
        "Link Video":"https:\/\/youtu.be\/Til9AdPO7JE",
        "Timestamps":"00:03:30–00:03:55"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Chức năng của mạng Region Proposal Network (RPN) trong thuật toán Faster R-CNN là gì?",
        "Phương án (nếu có)":"a) Phân loại chính xác đối tượng; b) Tinh chỉnh bounding box cuối cùng; c) Xác định những khu vực có khả năng có đối tượng; d) Trích xuất các đặc trưng cấp cao",
        "Đáp án":"c) Xác định những khu vực có khả năng có đối tượng",
        "Link Video":"https:\/\/youtu.be\/Til9AdPO7JE",
        "Timestamps":"00:05:30–00:05:50"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Điểm khác biệt cốt lõi của hướng tiếp cận phát hiện đối tượng một giai đoạn (ví dụ YOLO) so với hai giai đoạn là gì?",
        "Phương án (nếu có)":"a) Chỉ sử dụng mạng neural network thuần túy; b) Loại bỏ hoàn toàn bước dò tìm vùng đối tượng (RPN) và thực thi end-to-end; c) Luôn đạt độ chính xác cao hơn; d) Bắt buộc phải chia ảnh thành các ô lưới 7x7",
        "Đáp án":"b) Loại bỏ hoàn toàn bước dò tìm vùng đối tượng (RPN) và thực thi end-to-end",
        "Link Video":"https:\/\/youtu.be\/Til9AdPO7JE",
        "Timestamps":"00:07:20–00:07:45"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Trong bài toán phát hiện đối tượng, nếu ưu tiên độ chính xác cao hơn tốc độ thời gian thực (real-time), nên chọn hướng tiếp cận nào?",
        "Phương án (nếu có)":"a) Hướng tiếp cận một giai đoạn (ví dụ YOLO); b) Hướng tiếp cận hai giai đoạn (ví dụ Faster R-CNN); c) Hướng tiếp cận SSD; d) Cả a và c",
        "Đáp án":"b) Hướng tiếp cận hai giai đoạn (ví dụ Faster R-CNN)",
        "Link Video":"https:\/\/youtu.be\/Til9AdPO7JE",
        "Timestamps":"00:12:00–00:12:35"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Điểm khác biệt cơ bản giữa bài toán Phân đoạn Ngữ nghĩa đối tượng (Semantic Segmentation) và Phát hiện Đối tượng (Object Detection) là gì?",
        "Phương án (nếu có)":"a) Phát hiện đối tượng chỉ xác định đối tượng cần quan tâm; b) Phân đoạn ngữ nghĩa xác định vị trí đối tượng chính xác đến cấp độ điểm ảnh (pixel); c) Phát hiện đối tượng xác định vị trí đến cấp độ pixel; d) Phân đoạn ngữ nghĩa sử dụng bounding box.",
        "Đáp án":"b) Phân đoạn ngữ nghĩa xác định vị trí đối tượng chính xác đến cấp độ điểm ảnh (pixel)",
        "Link Video":"https:\/\/youtu.be\/4p0L74qD7Lg",
        "Timestamps":"00:00:00–00:00:40"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Khi thực hiện quá trình up-sampling (tái tạo lại feature map) từ không gian ít thông tin, vấn đề thường xảy ra là gì?",
        "Phương án (nếu có)":"a) Tăng độ phân giải và độ sắc nét; b) Mất thông tin và đường nét không còn sắc nét; c) Tốc độ huấn luyện giảm đáng kể; d) Hiện tượng Vanishing Gradient.",
        "Đáp án":"b) Mất thông tin và đường nét không còn sắc nét",
        "Link Video":"https:\/\/youtu.be\/4p0L74qD7Lg",
        "Timestamps":"00:02:15–00:02:45"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Phép toán nào thực hiện công việc ngược lại với Convolution, tức là lan truyền thông tin từ một pixel đến một vùng lớn hơn (ví dụ 1x1 sang 3x3)?",
        "Phương án (nếu có)":"a) Max Pooling; b) Deconvolution (Transposed Convolution); c) Softmax; d) Normalization.",
        "Đáp án":"b) Deconvolution (Transposed Convolution)",
        "Link Video":"https:\/\/youtu.be\/4p0L74qD7Lg",
        "Timestamps":"00:05:35–00:06:05"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Ý tưởng chính của kiến trúc DeepLab v3 dựa trên phép tính toán nào?",
        "Phương án (nếu có)":"a) Bilinear Up-sampling; b) Deconvolution; c) Address Convolution (Dilated Convolution); d) Residual Block.",
        "Đáp án":"c) Address Convolution (Dilated Convolution)",
        "Link Video":"https:\/\/youtu.be\/4p0L74qD7Lg",
        "Timestamps":"00:06:15–00:06:40"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Address Convolution (Dilated Convolution) được thiết kế để giải quyết hạn chế gì của Convolution truyền thống?",
        "Phương án (nếu có)":"a) Không tổng hợp được thông tin ở những vùng có kích thước lớn hơn một cách hiệu quả; b) Tăng chi phí tính toán; c) Chỉ hoạt động với kernel 3x3; d) Gây ra hiện tượng Overfitting.",
        "Đáp án":"a) Không tổng hợp được thông tin ở những vùng có kích thước lớn hơn một cách hiệu quả",
        "Link Video":"https:\/\/youtu.be\/4p0L74qD7Lg",
        "Timestamps":"00:06:45–00:07:30"
    },
    {
        "Chương":5,
        "Nội dung câu hỏi":"Tham số Rate (Ray) trong Dilated Convolution đại diện cho điều gì?",
        "Phương án (nếu có)":"a) Kích thước kernel; b) Khoảng cách skip (nhảy cóc) giữa các ô được lấy mẫu để tổng hợp thông tin; c) Số lượng feature map; d) Tỷ lệ học (Learning Rate).",
        "Đáp án":"b) Khoảng cách skip (nhảy cóc) giữa các ô được lấy mẫu để tổng hợp thông tin",
        "Link Video":"https:\/\/youtu.be\/4p0L74qD7Lg",
        "Timestamps":"00:07:45–00:08:20"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Work2Vec là phương pháp được giới thiệu trong bài học để làm gì?",
        "Phương án (nếu có)":"a) Phân loại cảm xúc văn bản; b) Biểu diễn một từ dưới dạng một vector; c) Xử lý dữ liệu ảnh; d) Tóm tắt nội dung văn bản.",
        "Đáp án":"b) Biểu diễn một từ dưới dạng một vector",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:00:23-00:00:33"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Lĩnh vực Xử lý Ngôn ngữ Tự nhiên (NLP) là lĩnh vực nghiên cứu giao thoa của những ngành nào?",
        "Phương án (nếu có)":"a) Khoa học máy tính, Toán học và Ngôn ngữ học; b) Trí tuệ nhân tạo, Ngôn ngữ học và Xã hội học; c) Khoa học máy tính, Trí tuệ nhân tạo và Ngôn ngữ học; d) Khoa học máy tính, Kỹ thuật phần mềm và Ngôn ngữ học.",
        "Đáp án":"c) Khoa học máy tính, Trí tuệ nhân tạo và Ngôn ngữ học",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:01:21-00:01:35"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Khả năng ngôn ngữ của máy tính bao gồm hai giai đoạn chính là gì?",
        "Phương án (nếu có)":"a) Nhập liệu (Input) và Xuất liệu (Output); b) Hiểu ngôn ngữ (Understanding) và Tạo sinh ngôn ngữ (Generation); c) Văn bản và Âm thanh; d) Phân tích và Phản hồi.",
        "Đáp án":"b) Hiểu ngôn ngữ (Understanding) và Tạo sinh ngôn ngữ (Generation)",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:02:15-00:02:40"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Trong ngữ cảnh của bài học, cụm từ NLU (Natural Language Understanding) bắt nguồn từ chữ nào?",
        "Phương án (nếu có)":"a) Navigate; b) Network; c) Normalization; d) Understanding.",
        "Đáp án":"d) Understanding",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:03:07-00:03:15"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Một trong những vấn đề gây ra tính nhập nhằng của ngôn ngữ được đề cập cụ thể trong ví dụ \"tốc độ truyền thông tin\" là gì?",
        "Phương án (nếu có)":"a) Vấn đề về ngữ cảnh thực tế; b) Vấn đề về ngữ pháp câu; c) Vấn đề về tách từ; d) Vấn đề về kiến thức chuyên môn.",
        "Đáp án":"c) Vấn đề về tách từ",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:06:03-00:06:30"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Ý nghĩa của thành ngữ \"làm ra ngô ra khoai\" là gì?",
        "Phương án (nếu có)":"a) Tạo ra các sản phẩm nông nghiệp; b) Làm việc đến nơi đến chốn, làm việc triệt để; c) Thể hiện sự không liên quan giữa chữ và nghĩa; d) Khả năng hiểu ngôn ngữ của con người.",
        "Đáp án":"b) Làm việc đến nơi đến chốn, làm việc triệt để",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:08:00-00:08:18"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Bài toán NER (Named Entity Recognition) nhằm mục đích gì?",
        "Phương án (nếu có)":"a) Phân loại câu là tích cực hay tiêu cực; b) Gắn nhãn từ loại cho mỗi từ; c) Xác định tên riêng cho người, tổ chức hoặc địa điểm; d) Tìm kiếm từ khóa đồng nghĩa.",
        "Đáp án":"c) Xác định tên riêng cho người, tổ chức hoặc địa điểm",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:10:11-00:10:50"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Bài toán Sentiment Analysis còn có tên gọi khác là gì?",
        "Phương án (nếu có)":"a) Text Summarization; b) Opinion Mining; c) Coreference Resolution; d) Machine Translation.",
        "Đáp án":"b) Opinion Mining",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:11:47-00:12:06"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Ứng dụng hiện đại nào được xem là điển hình cho khả năng tích hợp Question Answering và Paraphrasing trong NLP?",
        "Phương án (nếu có)":"a) Hệ thống dịch máy; b) Hệ thống rút trích thông tin; c) Chat GPT; d) Spam Detection.",
        "Đáp án":"c) Chat GPT",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:13:20-00:14:00"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Học sâu (Deep Learning) là một nhánh của lĩnh vực nào?",
        "Phương án (nếu có)":"a) Machine Vision; b) Classic Machine Learning; c) Representation Learning; d) Reinforcement Learning.",
        "Đáp án":"c) Representation Learning",
        "Link Video":"https:\/\/youtu.be\/utOha-d0prc",
        "Timestamps":"00:00:05-00:00:15"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Trong học sâu, dữ liệu đầu vào không cần phải có tri thức chuyên gia để rút trích ra đặc trưng, thay vào đó là sử dụng loại dữ liệu nào?",
        "Phương án (nếu có)":"a) Dữ liệu đã được tiền xử lý; b) Dữ liệu thô (nguyên bản); c) Dữ liệu ảnh; d) Dữ liệu vector.",
        "Đáp án":"b) Dữ liệu thô (nguyên bản)",
        "Link Video":"https:\/\/youtu.be\/utOha-d0prc",
        "Timestamps":"00:00:20-00:01:00"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Yếu tố nào đã góp phần tạo ra kho dữ liệu lớn, thúc đẩy sự phát triển của học sâu và NLP?",
        "Phương án (nếu có)":"a) Sức mạnh tính toán của CPU; b) Sự phủ sóng Internet và việc tạo nội dung qua mạng xã hội; c) Sự ra đời của mô hình Transformer; d) Phát minh ra thuật toán Backpropagation.",
        "Đáp án":"b) Sự phủ sóng Internet và việc tạo nội dung qua mạng xã hội",
        "Link Video":"https:\/\/youtu.be\/utOha-d0prc",
        "Timestamps":"00:01:21-00:02:20"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Nền tảng nào được đề cập là nguồn cung cấp dữ liệu dịch thuật đáng kể nhờ các tình nguyện viên phiên dịch lời thoại (caption)?",
        "Phương án (nếu có)":"a) Facebook; b) Stack Overflow; c) YouTube; d) Reddit.",
        "Đáp án":"c) YouTube",
        "Link Video":"https:\/\/youtu.be\/utOha-d0prc",
        "Timestamps":"00:03:00-00:03:40"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Sức mạnh tính toán ngày càng tăng, đặc biệt là sự phát triển của loại phần cứng nào, đã thúc đẩy sự tiến bộ của học sâu?",
        "Phương án (nếu có)":"a) CPU; b) SSD; c) GPU; d) RAM.",
        "Đáp án":"c) GPU",
        "Link Video":"https:\/\/youtu.be\/utOha-d0prc",
        "Timestamps":"00:04:16-00:04:45"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Trong kiến trúc Transformer, chữ 'T' trong GPT-4 và ChatGPT là viết tắt của từ gì?",
        "Phương án (nếu có)":"a) Tokenizer; b) Transformation; c) Training; d) Transformer.",
        "Đáp án":"d) Transformer",
        "Link Video":"https:\/\/youtu.be\/utOha-d0prc",
        "Timestamps":"00:07:07-00:07:25"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Lý do cốt lõi khiến các mô hình máy học cần biểu diễn từ dưới dạng vector là gì?",
        "Phương án (nếu có)":"a) Để tăng tốc độ truy xuất dữ liệu; b) Các mô hình máy học phải xử lý tính toán dưới dạng các con số (vector\/ma trận); c) Giảm thiểu lỗi chính tả; d) Tiết kiệm bộ nhớ lưu trữ.",
        "Đáp án":"b) Các mô hình máy học phải xử lý tính toán dưới dạng các con số (vector\/ma trận)",
        "Link Video":"https:\/\/youtu.be\/O57P9YHZOE0",
        "Timestamps":"00:00:15-00:00:50"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Tên tiếng Việt của \"One-hot vector\" là gì?",
        "Phương án (nếu có)":"a) Vector ngữ nghĩa; b) Vector đơn trội; c) Vector nhị phân; d) Vector tần suất.",
        "Đáp án":"b) Vector đơn trội",
        "Link Video":"https:\/\/youtu.be\/O57P9YHZOE0",
        "Timestamps":"00:02:40-00:02:50"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Nhược điểm chính của cách biểu diễn One-hot vector khi so sánh hai từ đồng nghĩa (ví dụ: hotel và motel)?",
        "Phương án (nếu có)":"a) Tốn quá nhiều bộ nhớ cho từ điển lớn; b) Sự tương đồng giữa hai vector bằng 0 (tính chất trực giao); c) Chỉ có thể biểu diễn danh từ; d) Không thể áp dụng cho ngôn ngữ có dấu.",
        "Đáp án":"b) Sự tương đồng giữa hai vector bằng 0 (tính chất trực giao)",
        "Link Video":"https:\/\/youtu.be\/O57P9YHZOE0",
        "Timestamps":"00:05:10-00:06:00"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Phương pháp toán học nào được sử dụng để đo sự tương đồng (tích vô hướng) giữa hai vector từ?",
        "Phương án (nếu có)":"a) Cosine; b) Softmax; c) Dot Product (Tích vô hướng); d) Sigmoid.",
        "Đáp án":"c) Dot Product (Tích vô hướng)",
        "Link Video":"https:\/\/youtu.be\/O57P9YHZOE0",
        "Timestamps":"00:08:00-00:08:15"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Trong không gian embedding, các từ có cùng ngữ cảnh (ví dụ: you, him, her trong câu \"I love ___ so much\") sẽ được biểu diễn như thế nào?",
        "Phương án (nếu có)":"a) Cách xa nhau; b) Tương đồng nhau, nằm gần nhau; c) Biểu diễn bằng One-hot vector; d) Luôn luôn trực giao với nhau.",
        "Đáp án":"b) Tương đồng nhau, nằm gần nhau",
        "Link Video":"https:\/\/youtu.be\/O57P9YHZOE0",
        "Timestamps":"00:07:20-00:08:00"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Mô hình Word2Vec được giới thiệu bởi Thomas Mikolov và cộng sự vào năm nào?",
        "Phương án (nếu có)":"a) 2007; b) 2013; c) 2017; d) 2020.",
        "Đáp án":"b) 2013",
        "Link Video":"https:\/\/youtu.be\/UJNyIptbcNM",
        "Timestamps":"00:00:17-00:00:30"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Mô hình Word2Vec bao gồm hai phương pháp con nào?",
        "Phương án (nếu có)":"a) N-gram và Continuous Bag-of-Words; b) Skip-Gram và Continuous Bag-of-Words (CBOW); c) Transformer và N-gram; d) LSTM và Skip-Gram.",
        "Đáp án":"b) Skip-Gram và Continuous Bag-of-Words (CBOW)",
        "Link Video":"https:\/\/youtu.be\/UJNyIptbcNM",
        "Timestamps":"00:00:30-00:00:50"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Ý tưởng chính của mô hình Skip-Gram là gì?",
        "Phương án (nếu có)":"a) Dự đoán từ ở giữa khi cho trước các từ xung quanh; b) Dự đoán các từ xung quanh khi có một từ ở giữa; c) Tính toán xác suất của từ hiện tại; d) Xây dựng ma trận tần suất từ.",
        "Đáp án":"b) Dự đoán các từ xung quanh khi có một từ ở giữa",
        "Link Video":"https:\/\/youtu.be\/UJNyIptbcNM",
        "Timestamps":"00:00:50-00:01:30"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Trong mô hình Continuous Bag-of-Words (CBOW), đầu vào được tính toán để tạo ra vector ẩn (H) như thế nào?",
        "Phương án (nếu có)":"a) Lấy tích vô hướng của các vector đầu vào; b) Chỉ sử dụng vector đầu vào gần nhất; c) Lấy tổng hoặc trung bình cộng của các vector tương ứng từ ngữ cảnh; d) Sử dụng ma trận W'.",
        "Đáp án":"c) Lấy tổng hoặc trung bình cộng của các vector tương ứng từ ngữ cảnh",
        "Link Video":"https:\/\/youtu.be\/AkHEcgasvkw",
        "Timestamps":"00:01:25-00:02:10"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Khi thực hiện phép toán vector X=vector(woman)−vector(man)+vector(king), từ gần nhất với vector X là từ nào?",
        "Phương án (nếu có)":"a) Prince; b) Queen; c) Princess; d) Boy.",
        "Đáp án":"b) Queen",
        "Link Video":"https:\/\/youtu.be\/AkHEcgasvkw",
        "Timestamps":"00:09:05-00:10:10"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Xử lý ngôn ngữ tự nhiên (NLP) là lĩnh vực nghiên cứu giao thoa giữa những lĩnh vực nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"NLP là một lĩnh vực nghiên cứu thuộc khoa học máy tính, trí tuệ nhân tạo và ngôn ngữ học.",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:01:25 - 00:01:43"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Phương pháp hiệu quả được đề cập để biểu diễn một từ dưới dạng một vector là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Phương pháp rất hiệu quả được sử dụng là Word2Vec.",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:00:23 - 00:00:30"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Mục tiêu cuối cùng của lĩnh vực xử lý ngôn ngữ tự nhiên là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Mục tiêu là làm sao cho máy tính có khả năng ngôn ngữ giống như con người.",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:01:46 - 00:01:54"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Hai giai đoạn tương ứng với việc hiểu ngôn ngữ và tạo sinh ngôn ngữ trong NLP là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Hai giai đoạn đó là Natural Language Understanding (NLU) và Natural Language Generation (NLG).",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:02:59 - 00:03:10"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Vấn đề nào là một trong những nguyên nhân chính gây ra sự nhập nhằng (ambiguity) trong ngôn ngữ đối với máy tính?",
        "Phương án (nếu có)":null,
        "Đáp án":"Một trong những vấn đề gây ra sự nhập nhằng đó chính là vấn đề về tách từ.",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:04:53 - 00:05:01"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Thành ngữ \"ra ngô ra khoai\" trong NLP được dùng để minh họa cho vấn đề gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Thành ngữ này minh họa vấn đề ngữ nghĩa của câu không liên quan trực tiếp đến mặt chữ của nó.",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:06:55 - 00:07:35"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Ứng dụng kinh điển nào của NLP đã có từ rất lâu đời?",
        "Phương án (nếu có)":null,
        "Đáp án":"Một ứng dụng kinh điển của NLP là kiểm tra lỗi chính tả.",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:08:44 - 00:08:55"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Tên tiếng Anh của bài toán nhận dạng thực thể có tên riêng (tên người, tổ chức, địa điểm) là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Tên tiếng Anh của bài toán này là Named Entity Recognition (NER).",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:09:40 - 00:10:04"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Phân tích cảm xúc (Sentiment Analysis) còn được gọi bằng thuật ngữ nào khác?",
        "Phương án (nếu có)":null,
        "Đáp án":"Phân tích cảm xúc còn được gọi là opinion mining.",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:10:37 - 00:10:39"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Ba khả năng tiêu biểu nào được tích hợp trong ứng dụng ChatGPT?",
        "Phương án (nếu có)":null,
        "Đáp án":"ChatGPT có khả năng trả lời câu hỏi (question answering), viết lại văn bản (paraphrase), và sửa lỗi chính tả.",
        "Link Video":"https:\/\/youtu.be\/30kCjQ0BdUc",
        "Timestamps":"00:12:35 - 00:13:30"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Yếu tố nào giúp các mô hình học sâu có sức mạnh tính toán ngày càng tăng so với CPU truyền thống?",
        "Phương án (nếu có)":null,
        "Đáp án":"Sức mạnh tính toán tăng là nhờ GPU, thiết bị cho phép tính toán song song rất nhiều phép toán tương tự và độc lập.",
        "Link Video":"https:\/\/youtu.be\/utOha-d0prc",
        "Timestamps":"00:03:20 - 00:04:10"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Trong mô hình học sâu, dữ liệu đầu vào đơn giản (simple feature) là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Dữ liệu đầu vào trong deep learning có thể là dữ liệu thô nguyên bản.",
        "Link Video":"https:\/\/youtu.be\/utOha-d0prc",
        "Timestamps":"00:05:54 - 00:06:21"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Vai trò của việc biểu diễn từ dưới dạng vector trong các mô hình máy học là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Việc biểu diễn từ dưới dạng vector là nhu cầu bất thiết vì các mô hình máy học phải xử lý tính toán dưới dạng các con số.",
        "Link Video":"https:\/\/youtu.be\/O57P9YHZOE0",
        "Timestamps":"00:00:10 - 00:00:54"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":" Vector đơn trội (One-hot vector) trong biểu diễn từ là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Vector đơn trội là vector chỉ có duy nhất một con số 1 (ở vị trí của từ trong từ điển) và phần còn lại là số 0.",
        "Link Video":"https:\/\/youtu.be\/O57P9YHZOE0",
        "Timestamps":"00:01:45 - 00:02:26"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Hạn chế lớn nhất của cách biểu diễn One-Hot Vector đối với các từ đồng nghĩa như \"hotel\" và \"motel\" là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Cả hai vector này có tính chất trực giao (sự tương đồng bằng 0), làm mô hình không nhận biết được ý nghĩa tương tự của chúng.",
        "Link Video":"https:\/\/youtu.be\/O57P9YHZOE0",
        "Timestamps":"00:02:40 - 00:04:15"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Theo Firth (1957), muốn hiểu được một từ thì cần dựa vào đâu?",
        "Phương án (nếu có)":null,
        "Đáp án":"Theo Firth, bạn sẽ biết được một cái từ bằng cách là những cái từ xung quanh nó (ngữ cảnh).",
        "Link Video":"https:\/\/youtu.be\/O57P9YHZOE0",
        "Timestamps":"00:04:32 - 00:05:00"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Để đo sự tương đồng của hai vector từ (word vector), công thức nào thường được sử dụng?",
        "Phương án (nếu có)":null,
        "Đáp án":"Chúng ta sẽ sử dụng công thức tích vô hướng (dot product).",
        "Link Video":"https:\/\/youtu.be\/O57P9YHZOE0",
        "Timestamps":"00:06:20 - 00:06:50"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Mô hình Word2Vec được giới thiệu vào năm nào và bởi ai?",
        "Phương án (nếu có)":null,
        "Đáp án":"Mô hình Word2Vec được Thomas Mikolov và cộng sự giới thiệu vào năm 2013.",
        "Link Video":"https:\/\/youtu.be\/UJNyIptbcNM",
        "Timestamps":"00:00:30 - 00:00:46"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Mô hình Skip-Gram trong Word2Vec hoạt động dựa trên ý tưởng nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Ý tưởng của Skip-Gram là dự đoán các từ xung quanh (ngữ cảnh) khi cho trước một từ ở giữa.",
        "Link Video":"https:\/\/youtu.be\/UJNyIptbcNM",
        "Timestamps":"00:01:10 - 00:01:30"
    },
    {
        "Chương":6,
        "Nội dung câu hỏi":"Phép toán vector X=women−man+king trong mô hình Word2Vec cho ra kết quả gần nhất là từ nào và thể hiện mối quan hệ ngữ nghĩa gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Kết quả gần nhất là từ \"queen\" (nữ hoàng), thể hiện mối quan hệ về mặt giới tính.",
        "Link Video":"https:\/\/youtu.be\/AkHEcgasvkw",
        "Timestamps":"00:07:05 - 00:07:45"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Mô hình học sâu nào rất phổ biến và nổi tiếng trong giai đoạn đầu của deep learning trong lĩnh vực Xử lý Ngôn ngữ Tự nhiên (NLP)?",
        "Phương án (nếu có)":"a) Mạng Convolutional Neural Network (CNN); b) Mạng Neuro Network (NN); c) Mạng Recurrent Neural Network (RNN); d) Mạng Transformer",
        "Đáp án":"c) Mạng Recurrent Neural Network (RNN)",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:00:00 - 00:00:30"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Yếu tố nào là quan trọng nhất cần chú ý đối với dữ liệu dạng chuỗi (ví dụ: văn bản, âm thanh, giá chứng khoán)?",
        "Phương án (nếu có)":"a) Màu sắc; b) Kích thước ma trận; c) Trình tự xuất hiện; d) Tính độc lập của các phần tử",
        "Đáp án":"c) Trình tự xuất hiện",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:04:15 - 00:04:30"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Cách biểu diễn phổ biến nhất đối với dữ liệu dạng chuỗi (văn bản) là gì?",
        "Phương án (nếu có)":"a) Ma trận hai chiều; b) Tensor ba chiều; c) Véc-tơ cố định; d) Danh sách các từ (String) hoặc mảng các ký tự",
        "Đáp án":"d) Danh sách các từ (String) hoặc mảng các ký tự",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:03:05 - 00:03:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Đặc điểm của độ dài (T) của văn bản trong dữ liệu dạng chuỗi là gì?",
        "Phương án (nếu có)":"a) Luôn cố định bằng 100; b) Luôn cố định bằng kích thước từ điển (V); c) Có thể thay đổi; d) Phải luôn nhỏ hơn 20",
        "Đáp án":"c) Có thể thay đổi",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:04:00 - 00:04:15"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"So với dữ liệu chuỗi và hình ảnh, dữ liệu đặc trưng (feature data) của một đối tượng có tính chất gì về mối quan hệ giữa các phần tử?",
        "Phương án (nếu có)":"a) Phụ thuộc theo chiều thời gian; b) Phụ thuộc theo chiều không gian; c) Các phần tử độc lập nhau; d) Chỉ phụ thuộc lẫn nhau nếu là điểm số",
        "Đáp án":"c) Các phần tử độc lập nhau",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:04:45 - 00:05:30"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Khó khăn cơ bản khi áp dụng mạng Neuro Network (NN) thông thường cho dữ liệu dạng chuỗi là gì?",
        "Phương án (nếu có)":"a) Dữ liệu chuỗi quá nhiều nhiễu; b) NN không hỗ trợ hàm Softmax; c) Văn bản có độ dài không cố định trong khi đầu vào của NN cố định; d) Tốc độ tính toán quá chậm",
        "Đáp án":"c) Văn bản có độ dài không cố định trong khi đầu vào của NN cố định",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:05:40 - 00:06:10"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Vấn đề của mô hình Bag-of-Words (BoW) khi được dùng để biểu diễn văn bản là gì?",
        "Phương án (nếu có)":"a) Nó không thể cố định số chiều; b) Nó cần quá nhiều bộ nhớ; c) Nó không đảm bảo được yếu tố về mặt trình tự; d) Nó chỉ dùng được cho tiếng Anh",
        "Đáp án":"c) Nó không đảm bảo được yếu tố về mặt trình tự",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:06:40 - 00:07:30"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Cơ chế nào trong mạng RNN giúp mã hóa yếu tố về mặt trình tự của các từ?",
        "Phương án (nếu có)":"a) Cơ chế Attention; b) Cơ chế Convolution; c) Cơ chế Max-Pooling; d) Cơ chế hồi quy (Recurrent)",
        "Đáp án":"d) Cơ chế hồi quy (Recurrent)",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:07:50 - 00:08:15"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Giá trị trạng thái ẩn St​ trong RNN đóng vai trò gì?",
        "Phương án (nếu có)":"a) Luôn luôn là đầu ra cuối cùng; b) Chỉ chứa thông tin của từ hiện tại Xt​; c) Tổng hợp thông tin của quá khứ (St−1​) và thông tin của thời điểm hiện tại (Xt​); d) Chỉ là một giá trị ngẫu nhiên",
        "Đáp án":"c) Tổng hợp thông tin của quá khứ (St−1​) và thông tin của thời điểm hiện tại (Xt​)",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:08:40 - 00:09:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Đặc điểm quan trọng của các bộ tham số U,V,W (trọng số) trong mạng RNN là gì?",
        "Phương án (nếu có)":"a) Chúng được khởi tạo lại ở mỗi bước tính toán; b) Kích thước của U,V,W luôn thay đổi; c) Được dùng chung (chia sẻ) cho mỗi bước tính toán; d) Chỉ có V được dùng chung",
        "Đáp án":"c) Được dùng chung (chia sẻ) cho mỗi bước tính toán",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:09:40 - 00:10:00"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Các hàm kích hoạt nào thường được sử dụng trong công thức tính trạng thái ẩn St​?",
        "Phương án (nếu có)":"a) ReLU hoặc Softmax; b) Sigmoid hoặc Tanh; c) Leaky ReLU hoặc PReLU; d) Linear",
        "Đáp án":"b) Sigmoid hoặc Tanh",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:10:20 - 00:10:50"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Nếu Xt​ có 8000 chiều và St​ có 100 chiều, ma trận tham số U sẽ có kích thước là bao nhiêu?",
        "Phương án (nếu có)":"a) 8000 x 100; b) 100 x 100; c) 100 x 8000; d) 8000 x 8000",
        "Đáp án":"c) 100 x 8000",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:12:00 - 00:12:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Nếu St−1​ và St​ đều có 100 chiều, ma trận tham số W sẽ có kích thước là bao nhiêu?",
        "Phương án (nếu có)":"a) 1 x 100; b) 100 x 1; c) 100 x 8000; d) 100 x 100",
        "Đáp án":"d) 100 x 100",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:12:40 - 00:13:10"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Nếu Yt~​ (giá trị dự đoán) có 8000 chiều và St​ có 100 chiều, ma trận tham số V sẽ có kích thước là bao nhiêu?",
        "Phương án (nếu có)":"a) 100 x 100; b) 100 x 8000; c) 8000 x 100; d) 1 x 100",
        "Đáp án":"c) 8000 x 100",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:13:10 - 00:13:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Hàm chi phí (hàm độ lỗi) tổng thể L của RNN được tính bằng cách nào?",
        "Phương án (nếu có)":"a) Bằng tổng của các Lt​ thành phần; b) Bằng phép nhân của các Lt​ thành phần; c) Bằng giá trị Lt​ cuối cùng; d) Bằng trung bình cộng của các Lt​ thành phần",
        "Đáp án":"d) Bằng trung bình cộng của các Lt​ thành phần",
        "Link Video":"https:\/\/youtu.be\/ptwSPTt2XnM",
        "Timestamps":"00:14:40 - 00:15:30"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Tình huống sử dụng nào của RNN có đầu vào là một từ và đầu ra là một chuỗi (ví dụ: tạo thơ từ một chủ đề)?",
        "Phương án (nếu có)":"a) One to One; b) Many to One; c) Many to Many Dạng 1; d) One to Many",
        "Đáp án":"d) One to Many",
        "Link Video":"https:\/\/youtu.be\/ptwSPTt2XnM",
        "Timestamps":"00:16:10 - 00:16:30"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Bài toán Phân tích cảm xúc (Sentiment Analysis) hoặc Phát hiện thư rác (Spam Detection) thường sử dụng dạng kiến trúc RNN nào?",
        "Phương án (nếu có)":"a) One to One; b) One to Many; c) Many to One; d) Many to Many Dạng 2",
        "Đáp án":"c) Many to One",
        "Link Video":"https:\/\/youtu.be\/ptwSPTt2XnM",
        "Timestamps":"00:16:30 - 00:17:10"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Dạng kiến trúc Many to Many Dạng 1 (ví dụ: Dịch máy) yêu cầu gì trước khi đưa ra phán đoán\/dự đoán?",
        "Phương án (nếu có)":"a) Đưa ra dự đoán ngay lập tức sau mỗi từ đầu vào; b) Phán đoán chỉ dựa vào từ đầu tiên; c) Đọc xong hết toàn bộ nội dung đầu vào; d) Đọc ngược từ cuối câu lên đầu câu",
        "Đáp án":"c) Đọc xong hết toàn bộ nội dung đầu vào",
        "Link Video":"https:\/\/youtu.be\/ptwSPTt2XnM",
        "Timestamps":"00:17:30 - 00:18:10"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Hiện tượng Vanishing Gradient (Đạo hàm tiêu biến) xảy ra khi nào, đặc biệt trong các mô hình học sâu có chuỗi hàm hợp dài?",
        "Phương án (nếu có)":"a) Các đạo hàm thành phần đều có giá trị tuyệt đối lớn hơn 1; b) Các đạo hàm thành phần đa số có giá trị tuyệt đối nhỏ hơn 1; c) Khi độ dài văn bản (T) rất ngắn; d) Khi sử dụng hàm ReLU",
        "Đáp án":"b) Các đạo hàm thành phần đa số có giá trị tuyệt đối nhỏ hơn 1",
        "Link Video":"https:\/\/youtu.be\/8-3xv_NElG0",
        "Timestamps":"00:24:40 - 00:25:30"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Điều nào sau đây là nguyên nhân chính khiến cho các đạo hàm thành phần trong RNN thường có giá trị tuyệt đối nhỏ hơn 1?",
        "Phương án (nếu có)":"a) Kích thước ma trận U quá lớn; b) Hàm kích hoạt Sigmoid có giá trị đạo hàm nằm trong khoảng từ 0 đến 1; c) Mạng RNN không sử dụng hàm Softmax; d) Ma trận W được khởi tạo bằng ma trận đơn vị",
        "Đáp án":"b) Hàm kích hoạt Sigmoid có giá trị đạo hàm nằm trong khoảng từ 0 đến 1",
        "Link Video":"https:\/\/youtu.be\/8-3xv_NElG0",
        "Timestamps":"00:25:30 - 00:26:00"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Vấn đề \"Sự phụ thuộc dài\" (Long Term Dependency) trong RNN truyền thống mô tả điều gì?",
        "Phương án (nếu có)":"a) Mô hình cần quá nhiều thời gian để hội tụ; b) Mô hình không thể tính toán được các văn bản quá dài; c) Mô hình không có cơ chế để nắm bắt sự phụ thuộc của từ cần dự đoán vào các từ ở rất xa trước đó; d) Mô hình chỉ có thể xử lý các câu tiếng Pháp",
        "Đáp án":"c) Mô hình không có cơ chế để nắm bắt sự phụ thuộc của từ cần dự đoán vào các từ ở rất xa trước đó",
        "Link Video":"https:\/\/youtu.be\/IKD0O35NOUI",
        "Timestamps":"00:22:40 - 00:23:50"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Giải pháp thay thế hàm kích hoạt nào giúp ngăn ngừa hiện tượng Vanishing Gradient trong RNN?",
        "Phương án (nếu có)":"a) Thay Sigmoid bằng Softmax; b) Thay Tanh bằng Sigmoid; c) Thay Sigmoid hoặc Tanh bằng ReLU; d) Thay ReLU bằng Sigmoid",
        "Đáp án":"c) Thay Sigmoid hoặc Tanh bằng ReLU",
        "Link Video":"https:\/\/youtu.be\/IKD0O35NOUI",
        "Timestamps":"00:26:00 - 00:27:00"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Kỹ thuật nào được sử dụng để chống lại hiện tượng Exploding Gradient (Đạo hàm bùng nổ)?",
        "Phương án (nếu có)":"a) Sử dụng hàm Tanh; b) Khởi tạo ma trận W bằng ma trận đơn vị; c) Sử dụng Clipping (chặt đạo hàm); d) Áp dụng Dropout",
        "Đáp án":"c) Sử dụng Clipping (chặt đạo hàm)",
        "Link Video":"https:\/\/youtu.be\/IKD0O35NOUI",
        "Timestamps":"00:27:00 - 00:27:50"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Trong biến thể LSTM, cổng (gate) nào quyết định việc giữ lại hay quên đi thông tin của quá khứ (Ct−1​) trong Context Cell?",
        "Phương án (nếu có)":"a) Input Gate; b) Output Gate; c) Forget Gate; d) Context Gate",
        "Đáp án":"c) Forget Gate",
        "Link Video":"https:\/\/youtu.be\/qJj_LY1r91U\nhttps:\/\/youtu.be\/_Km_A2iRUds",
        "Timestamps":"00:29:10 - 00:29:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Mục đích chính của Bidirectional RNN (Bi-RNN) là gì?",
        "Phương án (nếu có)":"a) Giảm chi phí tính toán; b) Giải quyết vấn đề Vanishing Gradient; c) Giúp mô hình chỉ học đặc trưng cấp thấp; d) Tổng hợp thông tin ngữ cảnh từ cả hai phía (trái sang phải và phải sang trái)",
        "Đáp án":"d) Tổng hợp thông tin ngữ cảnh từ cả hai phía (trái sang phải và phải sang trái)",
        "Link Video":"https:\/\/youtu.be\/_Cu7kGoRaE0",
        "Timestamps":"00:36:20 - 00:37:30"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"RNN là viết tắt của thuật ngữ gì trong học sâu?",
        "Phương án (nếu có)":null,
        "Đáp án":"RNN là tên viết tắt của mạng Recurrent Neural Network.",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:00:10 - 00:00:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Yếu tố nào là rất quan trọng cần phải chú ý trong dữ liệu dạng chuỗi?",
        "Phương án (nếu có)":null,
        "Đáp án":"Yếu tố trình tự xuất hiện của các giá trị đầu vào là rất quan trọng đối với dữ liệu dạng chuỗi.",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:02:18 - 00:03:00"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Dữ liệu hình ảnh thường được biểu diễn phổ biến dưới dạng nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Dữ liệu hình ảnh được biểu diễn dưới dạng ma trận hai chiều (ảnh không màu) hoặc tensor ba chiều (ảnh màu).",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:04:30 - 00:05:10"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Tính chất phụ thuộc của các phần tử trong dữ liệu dạng chuỗi được gọi là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Các phần tử trong dữ liệu dạng chuỗi phụ thuộc lẫn nhau theo một chiều thời gian.",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:06:50 - 00:07:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Khó khăn lớn nhất khi áp dụng trực tiếp dữ liệu dạng chuỗi vào mạng Neuro Network (NN) thông thường là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Khó khăn là văn bản có độ dài không cố định trong khi đầu vào của mạng NN lại cố định.",
        "Link Video":"https:\/\/youtu.be\/_KvZN8-SyvQ",
        "Timestamps":"00:08:15 - 00:08:45"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Yếu tố nào trong kiến trúc RNN giúp mã hóa được trình tự của các từ?",
        "Phương án (nếu có)":null,
        "Đáp án":"Cơ chế hồi quy (recurrent) là yếu tố giúp mạng RNN mã hóa được trình tự của các từ.",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:00:30 - 00:01:00, 00:04:15 - 00:04:30"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Trong kiến trúc RNN, trạng thái ẩn ST​ tổng hợp thông tin từ những nguồn nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"ST​ tổng hợp thông tin của quá khứ (ST−1​) và thông tin của thời điểm hiện tại (XT​).",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:01:40 - 00:02:20"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Các bộ tham số (ma trận trọng số) U, W, V trong RNN có đặc điểm chung gì khi tính toán qua các bước thời gian?",
        "Phương án (nếu có)":null,
        "Đáp án":"Các bộ tham số U, W, V được dùng chung (share) cho mỗi bước tính toán (time step).",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:03:30 - 00:04:00"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Kích thước của ma trận tham số V (dự đoán đầu ra) được tính như thế nào nếu ST​ là vecơ 100 chiều và YT~​ là vecơ 8000 chiều?",
        "Phương án (nếu có)":null,
        "Đáp án":"Ma trận V sẽ có kích thước là 8000×100.",
        "Link Video":"https:\/\/youtu.be\/TqKBlC-zyKY",
        "Timestamps":"00:10:40 - 00:11:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Hàm độ lỗi (loss function) tổng thể của mạng RNN được tính bằng cách nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Hàm loss tổng thể là trung bình cộng của các hàm loss thành phần tại mỗi time step t.",
        "Link Video":"https:\/\/youtu.be\/ptwSPTt2XnM",
        "Timestamps":"00:02:40 - 00:03:10"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Bài toán tạo ra một bài thơ từ một chủ đề cho trước thuộc dạng tình huống sử dụng RNN nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Đây là dạng One to Many, tức là đầu vào là một từ và đầu ra là nhiều từ (chuỗi output).",
        "Link Video":"https:\/\/youtu.be\/ptwSPTt2XnM",
        "Timestamps":"00:05:00 - 00:05:50"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Bài toán tóm tắt văn bản thuộc dạng Many to Many nào và tại sao?",
        "Phương án (nếu có)":null,
        "Đáp án":"Bài toán tóm tắt văn bản thuộc dạng Many to Many dạng 1, vì cần đọc xong hết toàn bộ văn bản đầu vào rồi mới đưa ra bản tóm tắt.",
        "Link Video":"https:\/\/youtu.be\/ptwSPTt2XnM",
        "Timestamps":"00:07:00 - 00:07:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"\"Sự phụ thuộc dài\" (long term dependency) là vấn đề gì trong RNN?",
        "Phương án (nếu có)":null,
        "Đáp án":"Đây là vấn đề RNN không có cơ chế để nắm bắt sự phụ thuộc của từ cần dự đoán vào những từ ở rất xa trước đó.",
        "Link Video":"https:\/\/youtu.be\/IKD0O35NOUI",
        "Timestamps":"00:01:20 - 00:02:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Hiện tượng Vanishing Gradient trong RNN là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Là hiện tượng đạo hàm của hàm hợp tiến đến 0 khi văn bản quá dài, do tích của các đạo hàm thành phần (có giá trị tuyệt đối nhỏ hơn 1) tiến về 0.",
        "Link Video":"https:\/\/youtu.be\/8-3xv_NElG0",
        "Timestamps":"00:07:00 - 00:07:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Giải pháp thay thế hàm kích hoạt Sigmoid\/Tanh bằng ReLU có tác dụng gì đối với hiện tượng vanishing gradient?",
        "Phương án (nếu có)":null,
        "Đáp án":"Hàm ReLU (với đạo hàm bằng 1 khi x > 0) giúp ngăn ngừa đạo hàm bị tiêu biến dần.",
        "Link Video":"https:\/\/youtu.be\/IKD0O35NOUI",
        "Timestamps":"00:07:00 - 00:08:10"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Kỹ thuật nào được sử dụng để chống lại hiện tượng Exploding Gradient (gradient bùng nổ)?",
        "Phương án (nếu có)":null,
        "Đáp án":"Kỹ thuật Clipping (cắt\/chặt) được sử dụng để chống lại hiện tượng exploding gradient bằng cách giới hạn mức trần của gradient.",
        "Link Video":"https:\/\/youtu.be\/IKD0O35NOUI",
        "Timestamps":"00:09:00 - 00:09:40"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Mục đích chính của Bidirectional RNN (Bi-RNN) là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Bi-RNN tổng hợp thông tin ngữ cảnh từ cả hai phía (trái sang phải và phải sang trái) để có được thông tin toàn diện hơn.",
        "Link Video":"https:\/\/youtu.be\/_Cu7kGoRaE0",
        "Timestamps":"00:04:30 - 00:04:50,\n00:07:40 - 00:08:30"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Kiến trúc Deep Stacked RNN (Multi-layer RNN) giúp tăng độ sâu của mô hình theo chiều nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Nó giúp tăng độ sâu theo chiều dọc, cho phép mô hình học được các đặc trưng ở nhiều cấp độ (thấp, giữa, cao).",
        "Link Video":"https:\/\/youtu.be\/KjPEqyGCtUs",
        "Timestamps":"00:01:50 - 00:02:40,\n00:05:40 - 00:06:10"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Cơ chế cốt lõi của LSTM (Long Short-Term Memory) là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Cơ chế cốt lõi của LSTM là điều tiết thông tin thông qua các cổng (forget, input, output gate) để \"nhớ cái cần nhớ và quên cái cần quên\".",
        "Link Video":"https:\/\/youtu.be\/IKD0O35NOUI,\nhttps:\/\/youtu.be\/qJj_LY1r91U",
        "Timestamps":"00:10:00 - 00:10:30,\n00:06:20 - 00:07:00"
    },
    {
        "Chương":7,
        "Nội dung câu hỏi":"Trong LSTM, cổng Forget Gate (FT​) sử dụng hàm kích hoạt nào để quyết định quên hay giữ lại thông tin?",
        "Phương án (nếu có)":null,
        "Đáp án":"Forget Gate sử dụng hàm Sigmoid, có miền giá trị từ 0 đến 1, để điều hướng thông tin cần quên hay giữ lại từ quá khứ (CT−1​).",
        "Link Video":"https:\/\/youtu.be\/_Km_A2iRUds",
        "Timestamps":"00:02:00 - 00:04:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Để hạn chế thí nghiệm thực hiện trong thời gian ngắn, kích thước từ điển (vocabulary size) được giới hạn là bao nhiêu từ?",
        "Phương án (nếu có)":"a) 100.000 từ; b) 5.000 từ; c) 500 từ; d) 1.000.000 từ",
        "Đáp án":"b) 5.000 từ",
        "Link Video":"https:\/\/youtu.be\/0DGe4fjr1aw",
        "Timestamps":"00:04:50–00:05:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Bộ dữ liệu IMDb được sử dụng trong bài hướng dẫn lập trình này chứa loại thông tin gì?",
        "Phương án (nếu có)":"a) Hình ảnh phim; b) Bình luận\/review phim; c) Âm thanh; d) Dữ liệu tài chính",
        "Đáp án":"b) Bình luận\/review phim",
        "Link Video":"https:\/\/youtu.be\/0DGe4fjr1aw",
        "Timestamps":"00:03:00–00:03:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Dữ liệu đầu vào X (chuỗi ký tự) được lưu trữ dưới dạng nào trong ví dụ lập trình RNN\/LSTM?",
        "Phương án (nếu có)":"a) Dạng văn bản thô (raw text); b) Chỉ số (index) vị trí của từ trong từ điển; c) Dạng vector nhị phân; d) Dạng biểu diễn Word Embedding",
        "Đáp án":"b) Chỉ số (index) vị trí của từ trong từ điển",
        "Link Video":"https:\/\/youtu.be\/0DGe4fjr1aw",
        "Timestamps":"00:06:50–00:07:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Kích thước tối đa của một review (max review lens) trong ví dụ RNN\/LSTM được quy định là bao nhiêu chữ?",
        "Phương án (nếu có)":"a) 300 chữ; b) 500 chữ; c) 1000 chữ; d) 50 chữ",
        "Đáp án":"b) 500 chữ",
        "Link Video":"https:\/\/youtu.be\/0DGe4fjr1aw",
        "Timestamps":"00:08:15–00:08:45"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Thao tác padding (chèn thêm giá trị 0) được thực hiện ở đầu chuỗi (prefix padding) nhằm mục đích gì?",
        "Phương án (nếu có)":"a) Giảm kích thước dữ liệu; b) Đảm bảo thông tin quan trọng (từ cuối) được xử lý sau cùng; c) Tăng tốc độ lan truyền ngược; d) Tái sử dụng trọng số",
        "Đáp án":"b) Đảm bảo thông tin quan trọng (từ cuối) được xử lý sau cùng",
        "Link Video":"https:\/\/youtu.be\/0DGe4fjr1aw",
        "Timestamps":"00:08:30–00:10:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Lớp Embedding được thiết lập trainable=False trong ví dụ lập trình RNN\/LSTM có ý nghĩa gì?",
        "Phương án (nếu có)":"a) Huấn luyện ma trận Embedding từ đầu; b) Tái sử dụng trọng số Word2Vec đã học và không huấn luyện lại; c) Bỏ qua lớp Embedding; d) Buộc mô hình học các đặc trưng cấp cao",
        "Đáp án":"b) Tái sử dụng trọng số Word2Vec đã học và không huấn luyện lại",
        "Link Video":"https:\/\/youtu.be\/wKMBVF_bJdw",
        "Timestamps":"00:00:10–00:00:40"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Kích thước chiều Embedding (embedding lane) được xác định là bao nhiêu khi sử dụng mô hình Word2Vec đã được huấn luyện trước?",
        "Phương án (nếu có)":"a) 64; b) 500; c) 300; d) 5000",
        "Đáp án":"c) 300",
        "Link Video":"https:\/\/youtu.be\/wKMBVF_bJdw",
        "Timestamps":"00:03:00–00:03:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Kích thước (số chiều) của vector trạng thái ẩn (St",
        "Phương án (nếu có)":"a) 32 chiều; b) 500 chiều; c) 64 chiều; d) 300 chiều",
        "Đáp án":"c) 64 chiều",
        "Link Video":"https:\/\/youtu.be\/wKMBVF_bJdw",
        "Timestamps":"00:01:30–00:02:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Hàm kích hoạt (activation function) cho lớp Dense đầu ra trong bài toán phân loại nhị phân (positive\/negative) là gì?",
        "Phương án (nếu có)":"a) ReLU; b) Softmax; c) Sigmoid; d) Tanh",
        "Đáp án":"c) Sigmoid",
        "Link Video":"https:\/\/youtu.be\/wKMBVF_bJdw",
        "Timestamps":"00:02:00–00:02:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Hàm Loss được sử dụng để huấn luyện mô hình RNN\/LSTM cho bài toán phân loại nhị phân là gì?",
        "Phương án (nếu có)":"a) Categorical Cross Entropy; b) Binary Cross Entropy; c) Mean Squared Error; d) Hinge Loss",
        "Đáp án":"b) Binary Cross Entropy",
        "Link Video":"https:\/\/youtu.be\/wKMBVF_bJdw",
        "Timestamps":"00:02:30–00:03:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Mạng RNN có tốc độ tính toán chậm là do đặc điểm kiến trúc nào?",
        "Phương án (nếu có)":"a) Số lượng layer quá lớn; b) Các bước tính toán đều thực hiện tuần tự (sequential); c) Thiếu bộ nhớ LSTM; d) Sử dụng hàm Sigmoid",
        "Đáp án":"b) Các bước tính toán đều thực hiện tuần tự (sequential)",
        "Link Video":"https:\/\/youtu.be\/wKMBVF_bJdw",
        "Timestamps":"00:04:00–00:04:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Phiên bản nào của RNN cho kết quả chính xác cao hơn trong ví dụ lập trình: Simple RNN hay LSTM?",
        "Phương án (nếu có)":"a) Simple RNN; b) LSTM; c) Kết quả ngang bằng; d) Không thể so sánh",
        "Đáp án":"b) LSTM",
        "Link Video":"https:\/\/youtu.be\/wKMBVF_bJdw",
        "Timestamps":"00:08:30–00:09:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Trạng thái ẩn trong mạng RNN tổng hợp thông tin từ những yếu tố nào?",
        "Phương án (nếu có)":"a) Thông tin của tương lai; b) Thông tin của quá khứ và thông tin của hiện tại; c) Chỉ thông tin của quá khứ; d) Chỉ thông tin của hiện tại",
        "Đáp án":"b) Thông tin của quá khứ và thông tin của hiện tại",
        "Link Video":"https:\/\/youtu.be\/4EdX3Ga9YoM",
        "Timestamps":"00:01:00–00:01:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Bài toán dịch máy có tính tổng quát cao vì nó biến đổi từ dạng nào sang dạng nào?",
        "Phương án (nếu có)":"a) Vector sang Vector; b) Chuỗi sang Vector; c) Chuỗi sang Chuỗi; d) Ảnh sang Chuỗi",
        "Đáp án":"c) Chuỗi sang Chuỗi",
        "Link Video":"https:\/\/youtu.be\/4EdX3Ga9YoM",
        "Timestamps":"00:03:30–00:04:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Kiến trúc Seq2Seq (Six to Six) bao gồm hai thành phần chính nào?",
        "Phương án (nếu có)":"a) Input và Output; b) Query và Key; c) Encoder và Decoder; d) Word2Vec và FastText",
        "Đáp án":"c) Encoder và Decoder",
        "Link Video":"https:\/\/youtu.be\/4EdX3Ga9YoM",
        "Timestamps":"00:05:40–00:06:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Trong kiến trúc Seq2Seq, Decoder đóng vai trò chính là gì?",
        "Phương án (nếu có)":"a) Đọc và hiểu thông tin input; b) Tạo sinh ra kết quả trả về; c) Chuẩn hóa các Attention Score; d) Tính toán trọng số",
        "Đáp án":"b) Tạo sinh ra kết quả trả về",
        "Link Video":"https:\/\/youtu.be\/4EdX3Ga9YoM",
        "Timestamps":"00:06:00–00:06:20"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Mục đích của việc sử dụng ký tự đặc biệt (ví dụ: START) trong Decoder là gì?",
        "Phương án (nếu có)":"a) Đánh dấu quá trình Encoder; b) Đánh dấu quá trình Decode bắt đầu; c) Thêm nhiễu vào mô hình; d) Giảm chiều dữ liệu",
        "Đáp án":"b) Đánh dấu quá trình Decode bắt đầu",
        "Link Video":"https:\/\/youtu.be\/4EdX3Ga9YoM",
        "Timestamps":"00:07:00–00:08:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Kiến trúc Deep Stacked Encoder được sử dụng nhằm mục đích gì trong NMT?",
        "Phương án (nếu có)":"a) Giảm thiểu Vanishing Gradient; b) Học được các đặc trưng cấp cao hơn; c) Đảm bảo tính tuần tự; d) Chỉ dùng cho bài toán tóm tắt",
        "Đáp án":"b) Học được các đặc trưng cấp cao hơn",
        "Link Video":"https:\/\/youtu.be\/--JpgsDEL40",
        "Timestamps":"00:04:30–00:05:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Độ đo BLEU được viết tắt từ cụm từ nào?",
        "Phương án (nếu có)":"a) Bidirectional Language Evaluation Utility; b) Bilingual Evaluation Understudy; c) Binary Language Estimation Understudy; d) Best Linguistic Error Utilization",
        "Đáp án":"b) Bilingual Evaluation Understudy",
        "Link Video":"https:\/\/youtu.be\/--JpgsDEL40",
        "Timestamps":"00:07:30–00:08:10"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Vấn đề cố hữu (bottleneck) của kiến trúc Seq2Seq truyền thống là gì?",
        "Phương án (nếu có)":"a) Quá trình huấn luyện quá nhanh; b) Toàn bộ thông tin câu nguồn bị dồn vào một vector ngữ cảnh duy nhất; c) Chỉ sử dụng được cho câu ngắn; d) Thiếu tham số huấn luyện",
        "Đáp án":"b) Toàn bộ thông tin câu nguồn bị dồn vào một vector ngữ cảnh duy nhất",
        "Link Video":"https:\/\/youtu.be\/ROIgZ5tyDFo",
        "Timestamps":"00:01:30–00:02:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Quá trình lan truyền tuần tự trong Seq2Seq gây ra vấn đề gì đối với thông tin của những từ đầu tiên?",
        "Phương án (nếu có)":"a) Thông tin được củng cố; b) Thông tin bị loãng\/mất sau nhiều lần biến đổi; c) Thông tin bị lặp lại; d) Thông tin bị mã hóa nhị phân",
        "Đáp án":"b) Thông tin bị loãng\/mất sau nhiều lần biến đổi",
        "Link Video":"https:\/\/youtu.be\/ROIgZ5tyDFo",
        "Timestamps":"00:02:40–00:03:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Mục tiêu của việc tính Attention Score là gì?",
        "Phương án (nếu có)":"a) Tạo ra một vector input mới; b) Tính toán xem tại thời điểm decode, mô hình nên \"để tâm\" đến từ nào trong câu nguồn; c) Ánh xạ Query và Value về cùng không gian; d) Giảm số chiều của Value",
        "Đáp án":"b) Tính toán xem tại thời điểm decode, mô hình nên \"để tâm\" đến từ nào trong câu nguồn",
        "Link Video":"https:\/\/youtu.be\/ROIgZ5tyDFo",
        "Timestamps":"00:03:30–00:04:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Hàm nào được sử dụng để chuẩn hóa Attention Score (R) về không gian xác suất (Attention Distribution α)?",
        "Phương án (nếu có)":"a) ReLU; b) Sigmoid; c) Tanh; d) Softmax",
        "Đáp án":"d) Softmax",
        "Link Video":"https:\/\/youtu.be\/S8__bXkLSbM",
        "Timestamps":"00:01:40–00:02:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Cơ chế Attention giải quyết vấn đề Vanishing Gradient bằng cách tạo ra các đường tắt (skip connections) tương tự như kiến trúc mạng CNN nào?",
        "Phương án (nếu có)":"a) LeNet; b) AlexNet; c) ResNet; d) VGGNet",
        "Đáp án":"c) ResNet",
        "Link Video":"https:\/\/youtu.be\/S8__bXkLSbM",
        "Timestamps":"00:06:50–00:07:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Trong cơ chế Attention, trạng thái ẩn của Encoder (Si​) được gọi chung là gì?",
        "Phương án (nếu có)":"a) Query (Q); b) Key (K); c) Value (V); d) Context (C)",
        "Đáp án":"c) Value (V)",
        "Link Video":"https:\/\/youtu.be\/my3qRjVJ7VM",
        "Timestamps":"00:00:30–00:01:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Vai trò của Encoder trong kiến trúc Seq2Seq là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Đọc và hiểu thông tin input đầu vào",
        "Link Video":"https:\/\/youtu.be\/4EdX3Ga9YoM",
        "Timestamps":"00:06:00–00:06:20"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Trong kiến trúc Seq2Seq, Decoder đóng vai trò giống như loại mô hình nào khi tạo ra câu văn đích?",
        "Phương án (nếu có)":null,
        "Đáp án":"Mô hình ngôn ngữ (Language Model)",
        "Link Video":"https:\/\/youtu.be\/4EdX3Ga9YoM",
        "Timestamps":"00:09:50–00:10:20"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Kể tên một bài toán (ngoài dịch máy) có thể được giải quyết bằng mô hình Seq2Seq vì có Input và Output đều là dạng chuỗi.",
        "Phương án (nếu có)":null,
        "Đáp án":"Tóm tắt văn bản (Summarization) HOẶC Hội thoại (Chatbot\/Dialog) HOẶC Tạo mã nguồn (Code Generation)",
        "Link Video":"https:\/\/youtu.be\/4EdX3Ga9YoM",
        "Timestamps":"00:11:30–00:13:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Khi huấn luyện NMT, thuật toán nào được thực hiện để cập nhật các ma trận trọng số (U, V, W) dựa trên hàm Loss tổng hợp?",
        "Phương án (nếu có)":null,
        "Đáp án":"Thuật toán lan truyền ngược (Backpropagation)",
        "Link Video":"https:\/\/youtu.be\/--JpgsDEL40",
        "Timestamps":"00:03:00–00:04:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Độ đo nào được sử dụng phổ biến hiện nay để đánh giá độ chính xác của mô hình dịch máy?",
        "Phương án (nếu có)":null,
        "Đáp án":"BLEU (Bilingual Evaluation Understudy)",
        "Link Video":"https:\/\/youtu.be\/--JpgsDEL40",
        "Timestamps":"00:07:30–00:08:10"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Cơ chế Attention giải quyết được vấn đề nào của Seq2Seq truyền thống, liên quan đến việc dồn nén thông tin?",
        "Phương án (nếu có)":null,
        "Đáp án":"Vấn đề điểm nghẽn (Bottleneck) thông tin",
        "Link Video":"https:\/\/youtu.be\/ROIgZ5tyDFo",
        "Timestamps":"00:01:30–00:02:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Attention Distribution (α) là kết quả của bước tính toán nào trong cơ chế Attention?",
        "Phương án (nếu có)":null,
        "Đáp án":"Chuẩn hóa Attention Score (R) bằng hàm Softmax",
        "Link Video":"https:\/\/youtu.be\/S8__bXkLSbM",
        "Timestamps":"00:02:00–00:03:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Vector tổng hợp thông tin từ Encoder dựa trên trọng số Attention (α) được ký hiệu bằng chữ cái nào, và nó còn có ý nghĩa là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"C (Context\/Ngữ cảnh)",
        "Link Video":"https:\/\/youtu.be\/S8__bXkLSbM",
        "Timestamps":"00:03:00–00:03:40"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Nếu vector Context (Ct",
        "Phương án (nếu có)":null,
        "Đáp án":"2D",
        "Link Video":"https:\/\/youtu.be\/S8__bXkLSbM",
        "Timestamps":"00:05:40–00:06:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Trong mô hình Attention, trạng thái ẩn của Decoder (H) được gọi là Query (Q). Vậy vai trò của Query là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Truy vấn\/So sánh để xác định các Value (S) nào cần được quan tâm",
        "Link Video":"https:\/\/youtu.be\/my3qRjVJ7VM",
        "Timestamps":"00:00:30–00:01:00"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Tên gọi khác của biến thể Attention sử dụng ma trận trọng số W để ánh xạ các vector có số chiều khác nhau (D1",
        "Phương án (nếu có)":null,
        "Đáp án":"Bilinear Attention (Attention song tuyến)",
        "Link Video":"https:\/\/youtu.be\/my3qRjVJ7VM",
        "Timestamps":"00:04:00–00:04:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Biến thể Attention nào được sử dụng trong kiến trúc Transformer về sau do khả năng giảm tham số và tính tổng quát cao?",
        "Phương án (nếu có)":null,
        "Đáp án":"Attention với nhân ma trận giảm bậc (Low-Rank Matrix Multiplication Attention)",
        "Link Video":"https:\/\/youtu.be\/my3qRjVJ7VM",
        "Timestamps":"00:10:30–00:11:30"
    },
    {
        "Chương":8,
        "Nội dung câu hỏi":"Ngoài NLP, cơ chế Attention còn được áp dụng rộng rãi trong lĩnh vực Deep Learning nào khác?",
        "Phương án (nếu có)":null,
        "Đáp án":"Xử lý ảnh\/Thị giác máy tính (Computer Vision)",
        "Link Video":"https:\/\/youtu.be\/my3qRjVJ7VM",
        "Timestamps":"00:11:30–00:12:30"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Trong kiến trúc Attention, các trạng thái ẩn (S1",
        "Phương án (nếu có)":"a) Query; b) Key; c) Value; d) State",
        "Đáp án":"c) Value",
        "Link Video":"https:\/\/youtu.be\/1tCmeHf1Xk0",
        "Timestamps":"00:00:40–00:01:20"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Trong các mô hình hồi quy (Recurrent Models) truyền thống cho NLP, kiến trúc sale nào thường được sử dụng?",
        "Phương án (nếu có)":"a) ReLU; b) Softmax; c) LSTM; d) CNN",
        "Đáp án":"c) LSTM",
        "Link Video":"https:\/\/youtu.be\/1tCmeHf1Xk0",
        "Timestamps":"00:01:45–00:02:10"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Trong mô hình hồi quy, bước Encoder cần được thực hiện theo chiều nào để thu thập đầy đủ ngữ cảnh của từ?",
        "Phương án (nếu có)":"a) Một chiều; b) Hai chiều (Bidirectional); c) Theo thứ tự ngược lại; d) Song song",
        "Đáp án":"b) Hai chiều (Bidirectional)",
        "Link Video":"https:\/\/youtu.be\/1tCmeHf1Xk0",
        "Timestamps":"00:01:20–00:02:45"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Lợi ích chính của cơ chế Attention là cho phép linh hoạt truy xuất bộ nhớ bằng cách nào?",
        "Phương án (nếu có)":"a) Tăng chi phí tính toán; b) Tăng độ dài chuỗi; c) Giảm số bước di chuyển\/biến đổi tuần tự; d) Chỉ tương tác với các từ gần nhất",
        "Đáp án":"c) Giảm số bước di chuyển\/biến đổi tuần tự",
        "Link Video":"https:\/\/youtu.be\/1tCmeHf1Xk0",
        "Timestamps":"00:03:00–00:05:00"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Động lực lớn nhất để đề xuất kiến trúc Transformer là tối đa hóa thao tác nào trong quá trình huấn luyện Deep Learning?",
        "Phương án (nếu có)":"a) Tuần tự; b) Hồi quy; c) Song song; d) Truy vấn",
        "Đáp án":"c) Song song",
        "Link Video":"https:\/\/youtu.be\/5DE5HXG8FWk",
        "Timestamps":"00:01:35–00:03:00"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Vấn đề nào xuất hiện khi các mô hình tuần tự có sự phụ thuộc dài giữa các từ, làm giảm hiệu quả huấn luyện?",
        "Phương án (nếu có)":"a) Exploding Gradient; b) Overfitting; c) Vanishing Gradient; d) Dead Neuron",
        "Đáp án":"c) Vanishing Gradient",
        "Link Video":"https:\/\/youtu.be\/5DE5HXG8FWk",
        "Timestamps":"00:02:30–00:03:30"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Self-Attention là cơ chế chú ý trên tập giá trị nào?",
        "Phương án (nếu có)":"a) Giữa Decoder và Encoder; b) Giữa Encoder và Decoder; c) Giữa các từ trong cùng một chuỗi (Encode-Encode hoặc Decode-Decode); d) Giữa các Layer khác nhau",
        "Đáp án":"c) Giữa các từ trong cùng một chuỗi (Encode-Encode hoặc Decode-Decode)",
        "Link Video":"https:\/\/youtu.be\/NsWX_5oV8bY",
        "Timestamps":"00:01:25–00:02:30"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Ưu điểm nào của Transformer, nhờ cơ chế Self-Attention, giúp nó khai thác được sức mạnh của GPU?",
        "Phương án (nếu có)":"a) Chỉ sử dụng phép cộng ma trận; b) Các node trên cùng một layer được tính toán độc lập\/song song; c) Không cần Positional Embedding; d) Lan truyền thông tin tuần tự",
        "Đáp án":"b) Các node trên cùng một layer được tính toán độc lập\/song song",
        "Link Video":"https:\/\/youtu.be\/UXxELgk5Vws",
        "Timestamps":"00:00:50–00:01:40"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Trong cơ chế truy vấn (query system) của Attention, Query (Q) được dùng để làm gì?",
        "Phương án (nếu có)":"a) Biểu diễn nội dung cần lấy về (Value); b) Biểu diễn từ khóa tìm kiếm (Keyword); c) So khớp với các Value; d) Tính toán Embedding",
        "Đáp án":"b) Biểu diễn từ khóa tìm kiếm (Keyword)",
        "Link Video":"https:\/\/youtu.be\/UXxELgk5Vws",
        "Timestamps":"00:02:40–00:03:10"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Bước đầu tiên để tính Self-Attention cho một từ đầu vào (Xi",
        "Phương án (nếu có)":"a) Ánh xạ Xi",
        "Đáp án":"a) Ánh xạ Xi",
        "Link Video":"https:\/\/youtu.be\/UXxELgk5Vws",
        "Timestamps":"00:05:00–00:05:50"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Công thức tính Attention Score ở dạng vector hóa (trên ma trận X) là gì?",
        "Phương án (nếu có)":"a) XQ×(XK)T; b) Softmax(XQ×XKT); c) XQ×XV; d) XK×(XQ)T",
        "Đáp án":"a) XQ×(XK)T",
        "Link Video":"https:\/\/youtu.be\/UXxELgk5Vws",
        "Timestamps":"00:06:00–00:07:30"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Chức năng chính của Feed Forward Network (FFN) trong Encoder là gì, ngoài việc Attention chỉ thực hiện trung bình có trọng số?",
        "Phương án (nếu có)":"a) Tính toán đạo hàm; b) Ánh xạ về không gian xác suất; c) Biến đổi đặc trưng sang dạng phi tuyến tính; d) Tính Positional Embedding",
        "Đáp án":"c) Biến đổi đặc trưng sang dạng phi tuyến tính",
        "Link Video":"https:\/\/youtu.be\/JGxo_olUl2U",
        "Timestamps":"00:00:00–00:00:55"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Việc trồng nhiều lớp (stacking layers) giúp Deep Learning tạo ra các đặc trưng theo cấp độ nào?",
        "Phương án (nếu có)":"a) Mid-level; b) Low-level; c) High-level; d) Cả ba cấp độ trên",
        "Đáp án":"d) Cả ba cấp độ trên",
        "Link Video":"https:\/\/youtu.be\/JGxo_olUl2U",
        "Timestamps":"00:01:50–00:02:30"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Kỹ thuật Residual Connect (đường màu đỏ trong sơ đồ) giúp cải thiện quá trình huấn luyện bằng cách nào?",
        "Phương án (nếu có)":"a) Đảm bảo tính tuần tự; b) Giảm hiện tượng Vanishing Gradient và huấn luyện mạng rất sâu; c) Chỉ áp dụng cho Decoder; d) Giảm độ phức tạp O(T2)",
        "Đáp án":"b) Giảm hiện tượng Vanishing Gradient và huấn luyện mạng rất sâu",
        "Link Video":"https:\/\/youtu.be\/JGxo_olUl2U",
        "Timestamps":"00:02:30–00:03:30"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Layer Normalization được thực hiện nhằm giải quyết vấn đề gì?",
        "Phương án (nếu có)":"a) Tăng sự biến động của dữ liệu đầu vào; b) Khó huấn luyện do đầu vào biến động liên tục; c) Cần tăng chi phí tính toán; d) Chỉ áp dụng cho Encoder",
        "Đáp án":"b) Khó huấn luyện do đầu vào biến động liên tục",
        "Link Video":"https:\/\/youtu.be\/JGxo_olUl2U",
        "Timestamps":"00:03:30–00:04:45"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Trong kiến trúc Attention (Scaled Dot Product Attention), phép chia cho Dk",
        "Phương án (nếu có)":"a) Đưa output về phân bố chuẩn; b) Tăng giá trị tích vô hướng; c) Mã hóa vị trí tuyệt đối; d) Ngăn chặn việc tính toán song song",
        "Đáp án":"a) Đưa output về phân bố chuẩn",
        "Link Video":"https:\/\/youtu.be\/JGxo_olUl2U",
        "Timestamps":"00:06:20–00:07:00"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Tại sao Self-Attention cần Positional Embedding?",
        "Phương án (nếu có)":"a) Để có thể tính toán tuần tự; b) Để khắc phục việc nó không quan tâm đến thứ tự của các từ; c) Để tăng chi phí tính toán; d) Để giảm số chiều của vector",
        "Đáp án":"b) Để khắc phục việc nó không quan tâm đến thứ tự của các từ",
        "Link Video":"https:\/\/youtu.be\/JGxo_olUl2U",
        "Timestamps":"00:07:00–00:08:00"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Để vẫn có thể tính toán song song trong Transformer Decoder mà không vi phạm quy tắc không được thấy từ tương lai, cơ chế nào được sử dụng?",
        "Phương án (nếu có)":"a) Standard Self-Attention; b) Cross Attention; c) Masked Multi-Head Self-Attention; d) Bi-directional Attention",
        "Đáp án":"c) Masked Multi-Head Self-Attention",
        "Link Video":"https:\/\/youtu.be\/jKnjyvvXzXI",
        "Timestamps":"00:03:00–00:04:15"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Trong Masked Attention, việc gán attention score của các từ tương lai bằng −∞ có tác dụng gì sau khi qua hàm Softmax?",
        "Phương án (nếu có)":"a) Biến thành 1; b) Biến thành 0; c) Tăng trọng số; d) Vẫn giữ nguyên là −∞",
        "Đáp án":"b) Biến thành 0",
        "Link Video":"https:\/\/youtu.be\/jKnjyvvXzXI",
        "Timestamps":"00:05:30–00:06:20"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Trong Cross Attention, thành phần Query (Q) được lấy từ bộ phận nào của Transformer?",
        "Phương án (nếu có)":"a) Input đầu vào của Decoder; b) Output của Encoder; c) Positional Embedding; d) Output của Softmax",
        "Đáp án":"a) Input đầu vào của Decoder",
        "Link Video":"https:\/\/youtu.be\/jKnjyvvXzXI",
        "Timestamps":"00:07:15–00:07:55"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Chi phí tính toán của Self-Attention theo độ dài chuỗi T là O(T2). Điều này xuất phát từ thao tác nào?",
        "Phương án (nếu có)":"a) Phải tính trên tất cả các cặp tương tác (T×T); b) Tính toán song song; c) Phép chia cho Dk",
        "Đáp án":"a) Phải tính trên tất cả các cặp tương tác (T×T)",
        "Link Video":"https:\/\/youtu.be\/fEGw6eEre2I",
        "Timestamps":"00:00:00–00:00:55"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Theo nhận xét trong bài giảng, yếu tố vị trí nào được coi là quan trọng trong Attention hơn vị trí tuyệt đối (Absolute Position)?",
        "Phương án (nếu có)":"a) Vị trí ngữ pháp; b) Vị trí tương đối (Relative Position); c) Vị trí cố định; d) Vị trí ngẫu nhiên",
        "Đáp án":"b) Vị trí tương đối (Relative Position)",
        "Link Video":"https:\/\/youtu.be\/fEGw6eEre2I",
        "Timestamps":"00:01:30–00:02:40"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Mô hình nền tảng GPT (Generative Pre-trained Transformer) dựa trên thành phần nào của Transformer?",
        "Phương án (nếu có)":"a) Toàn bộ kiến trúc; b) Chỉ Encoder; c) Chỉ Decoder; d) Chỉ Positional Encoding",
        "Đáp án":"c) Chỉ Decoder",
        "Link Video":"https:\/\/youtu.be\/iMfkIHkU6NM",
        "Timestamps":"00:00:00–00:00:30"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Phương pháp Fine-Tuning khác biệt cơ bản với Prompting ở điểm nào?",
        "Phương án (nếu có)":"a) Fine-Tuning không làm thay đổi tham số mô hình; b) Fine-Tuning cần dữ liệu không gán nhãn; c) Fine-Tuning phải thay đổi\/huấn luyện lại tham số mô hình; d) Prompting có chi phí tính toán cao hơn",
        "Đáp án":"c) Fine-Tuning phải thay đổi\/huấn luyện lại tham số mô hình",
        "Link Video":"https:\/\/youtu.be\/iMfkIHkU6NM",
        "Timestamps":"00:03:00–00:04:00"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Multi-Head Attention thực hiện thao tác nào sau khi tính toán Scaled Dot Product Attention trên từng head?",
        "Phương án (nếu có)":"a) Phép cộng; b) Phép nhân; c) Nối (Concat); d) Hàm Softmax",
        "Đáp án":"c) Nối (Concat)",
        "Link Video":"https:\/\/youtu.be\/7AZr_li6ZtA",
        "Timestamps":"00:04:45–00:05:30"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Trong cơ chế Attention cơ bản, các vector truy vấn (H) được gọi là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Query",
        "Link Video":"https:\/\/youtu.be\/1tCmeHf1Xk0",
        "Timestamps":"00:00:40–00:01:20"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Quá trình tính toán ở bước output (Decoder) của mô hình hồi quy chỉ đi theo chiều nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Một chiều (One-directional)",
        "Link Video":"https:\/\/youtu.be\/1tCmeHf1Xk0",
        "Timestamps":"00:02:45–00:03:20"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Điểm yếu chính của Recurrent Neural Network (RNN) mà Transformer giải quyết là gì, liên quan đến việc xử lý thông tin?",
        "Phương án (nếu có)":null,
        "Đáp án":"Lan truyền thông tin tuần tự (Sequential propagation\/computation)",
        "Link Video":"https:\/\/youtu.be\/UXxELgk5Vws",
        "Timestamps":"00:00:00–00:00:45"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Kiến trúc Transformer kinh điển bao gồm hai thành phần chính nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Encoder và Decoder",
        "Link Video":"https:\/\/youtu.be\/UXxELgk5Vws",
        "Timestamps":"00:01:40–00:02:40"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Sau khi tính toán Output của Self-Attention, bước tiếp theo trong Encoder là gì để cung cấp biến đổi phi tuyến tính?",
        "Phương án (nếu có)":null,
        "Đáp án":"Mạng Feed Forward (Feed Forward Network - FFN)",
        "Link Video":"https:\/\/youtu.be\/JGxo_olUl2U",
        "Timestamps":"00:00:00–00:00:55"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Trong kiến trúc Transformer kinh điển, tổng số layer (lặp lại module Encoder và Decoder) thường là bao nhiêu lần?",
        "Phương án (nếu có)":null,
        "Đáp án":"6 lần",
        "Link Video":"https:\/\/youtu.be\/JGxo_olUl2U",
        "Timestamps":"00:02:15–00:02:30"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Positional Embedding được sử dụng để mã hóa thông tin nào bị Self-Attention bỏ qua?",
        "Phương án (nếu có)":null,
        "Đáp án":"Vị trí hoặc Thứ tự (Index\/Order)",
        "Link Video":"https:\/\/youtu.be\/JGxo_olUl2U",
        "Timestamps":"00:07:50–00:09:00"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Khi Decoder thực hiện Masked Multi-Head Self-Attention, nó chỉ được phép thấy những từ nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Từ hiện tại và các từ trong quá khứ (từ đã dự đoán trước đó)",
        "Link Video":"https:\/\/youtu.be\/jKnjyvvXzXI",
        "Timestamps":"00:02:15–00:03:00"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Cơ chế ánh xạ thông tin giữa Encoder và Decoder trong kiến trúc Transformer được gọi là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Cross Attention (hoặc Encoder-Decoder Attention)",
        "Link Video":"https:\/\/youtu.be\/jKnjyvvXzXI",
        "Timestamps":"00:06:25–00:06:55"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Vấn đề lớn nhất liên quan đến chi phí tính toán của Self-Attention là gì?",
        "Phương án (nếu có)":null,
        "Đáp án":"Chi phí tăng theo hàm bậc hai của độ dài chuỗi (O(T2))",
        "Link Video":"https:\/\/youtu.be\/fEGw6eEre2I",
        "Timestamps":"00:00:00–00:00:55"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Linformer giải quyết chi phí O(T2) bằng cách chiếu không gian T chiều về không gian K chiều, trong đó K là gì so với T?",
        "Phương án (nếu có)":null,
        "Đáp án":"K là con số nhỏ hơn T rất nhiều (thường là cố định)",
        "Link Video":"https:\/\/youtu.be\/fEGw6eEre2I",
        "Timestamps":"00:03:50–00:04:40"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Mô hình nền tảng BERT được huấn luyện cho nhiệm vụ chính là gì (Masked Language Model)?",
        "Phương án (nếu có)":null,
        "Đáp án":"Dự đoán từ bị che (Masked Word Prediction)",
        "Link Video":"https:\/\/youtu.be\/iMfkIHkU6NM",
        "Timestamps":"00:01:50–00:02:15"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Khái niệm Downstream Tasks (Nhiệm vụ hạ nguồn) dùng để chỉ các nhiệm vụ gì đối với BERT\/GPT?",
        "Phương án (nếu có)":null,
        "Đáp án":"Các nhiệm vụ phụ (như phân loại, dịch máy) mà mô hình không được huấn luyện trực tiếp ban đầu",
        "Link Video":"https:\/\/youtu.be\/iMfkIHkU6NM",
        "Timestamps":"00:01:25–00:02:50"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Phương pháp Fine-Tuning nào giúp tiết kiệm chi phí tính toán bằng cách chỉ tinh chỉnh một module nhỏ được thêm vào mô hình ngôn ngữ?",
        "Phương án (nếu có)":null,
        "Đáp án":"Adapter (ví dụ: LoRA, Prefix Tuning)",
        "Link Video":"https:\/\/youtu.be\/iMfkIHkU6NM",
        "Timestamps":"00:04:50–00:05:45"
    },
    {
        "Chương":9,
        "Nội dung câu hỏi":"Các vectơ Positional Embedding trong Transformer đời đầu được tạo ra bằng tổ hợp của các hàm toán học nào?",
        "Phương án (nếu có)":null,
        "Đáp án":"Hàm Sin và Cos (Hàm tuần hoàn)",
        "Link Video":"https:\/\/youtu.be\/7AZr_li6ZtA",
        "Timestamps":"00:00:00–00:01:00"
    }
]