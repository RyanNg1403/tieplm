# =============================================================================
# API Keys
# =============================================================================
OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# Database Configuration
# =============================================================================

# PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=tieplm
POSTGRES_USER=user
POSTGRES_PASSWORD=password

# Qdrant Vector Database
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=cs431_course_transcripts

# =============================================================================
# Embedding Configuration
# =============================================================================

# Embedding Model
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL_NAME=text-embedding-3-small
EMBEDDING_DIMENSION=1536

# Embedding Batch Processing
EMBEDDING_BATCH_SIZE=100

# =============================================================================
# LLM Configuration (for contextual chunking and other tasks)
# =============================================================================

# Model Settings
MODEL_PROVIDER=openai
MODEL_NAME=gpt-5-mini
# API Settings
LLM_MAX_RETRIES=3
LLM_TIMEOUT=60
LLM_TEMPERATURE=1.0  # gpt-5-mini only supports temperature=1.0 (default)

# =============================================================================
# Chunking Configuration
# =============================================================================

# Time-Window Chunking
TIME_WINDOW=60
CHUNK_OVERLAP=10

# Contextual Enrichment
CONTEXT_TOKEN_LIMIT=300  # Initial limit; retries with +100 tokens (up to 3 attempts: 300->400->500)
ENABLE_CONTEXTUAL_CHUNKING=true

# =============================================================================
# Pipeline Configuration
# =============================================================================

# Logging
LOG_LEVEL=INFO
LOG_DIR=logs

# Processing
MAX_WORKERS=4
ENABLE_PROGRESS_BAR=true

# =============================================================================
# Retrieval Configuration (for future RAG implementation)
# =============================================================================

# Search Parameters
RETRIEVAL_TOP_K=20
RETRIEVAL_SCORE_THRESHOLD=0.7

# Reranking (optional - for future use)
ENABLE_RERANKING=false
RERANKER_MODEL=cohere
RERANKER_TOP_K=5

