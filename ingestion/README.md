# Ingestion Module

Process YouTube videos: download â†’ transcribe â†’ embed â†’ store in databases.

## ğŸ“ Structure

```
ingestion/
â”œâ”€â”€ videos/        # Downloaded videos
â”œâ”€â”€ transcripts/   # JSON transcripts
â””â”€â”€ pipeline/      # Processing scripts
    â”œâ”€â”€ download.py           # Download from YouTube
    â”œâ”€â”€ transcribe_videos.py  # Transcribe with Whisper
    â”œâ”€â”€ embeddings.py         # Generate embeddings
    â”œâ”€â”€ keyframes.py          # Extract video frames
    â””â”€â”€ storage.py            # Store in databases
```

## âœ… Implemented

- âœ… Download script (`download.py`)
- âœ… Transcription with Whisper (`transcribe_videos.py`)
- âœ… Support for all Whisper models (tiny â†’ large-v3)
- âœ… Batch processing with progress bars
- âœ… Resume capability (skips completed)
- âœ… Word-level timestamps

## âŒ TODO

- âŒ Embedding generation (`embeddings.py`)
- âŒ Keyframe extraction (`keyframes.py`)
- âŒ Database storage (`storage.py`)
- âŒ Chunking strategy (time-based)
- âŒ Integration with vector DB (Qdrant)
- âŒ Integration with PostgreSQL

## ğŸš€ Quick Start

```bash
cd ingestion/pipeline

# 1. Download videos
python download.py --all

# 2. Transcribe (choose model based on speed/quality trade-off)
python transcribe_videos.py --all --model medium  # Recommended
# or
python transcribe_videos.py --all --model large-v3  # Best quality

# 3. Generate embeddings (TODO)
# python embeddings.py --all
```

## âš™ï¸ Whisper Models

| Model | Speed | Quality | Time (62 videos) |
|-------|-------|---------|------------------|
| tiny | Very Fast | Basic | ~10 min |
| small | Fast | Good | ~30 min |
| **medium** | Medium | Very Good | **~1 hour** â­ |
| large-v3 | Slow | Best | ~3-4 hours |

**Recommendation**: Use `medium` for balance of speed/quality.

## ğŸ“Š Output

Each video â†’ JSON file with:
- Full transcript text
- Language detected
- Segments with timestamps
- Word-level timestamps

**Next Step**: Generate embeddings from transcripts.
